{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Mouse Pathing\n",
    "#### Garrett Lappe - garrett.l.lappe@gmail.com\n",
    "#### MSDS - Data Science Practicum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from scipy import misc, ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('data\\\\imgs\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52153"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\imgs\\\\path_0_Garrett.jpg',\n",
       " 'data\\\\imgs\\\\path_10000_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10001_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10002_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10003_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10004_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10005_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10006_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10007_Jennifer.jpg',\n",
       " 'data\\\\imgs\\\\path_10008_Jennifer.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['img_path'] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>data\\imgs\\path_0_Garrett.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>data\\imgs\\path_10000_Jennifer.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>data\\imgs\\path_10001_Jennifer.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>data\\imgs\\path_10002_Jennifer.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>data\\imgs\\path_10003_Jennifer.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            img_path\n",
       "0       data\\imgs\\path_0_Garrett.jpg\n",
       "1  data\\imgs\\path_10000_Jennifer.jpg\n",
       "2  data\\imgs\\path_10001_Jennifer.jpg\n",
       "3  data\\imgs\\path_10002_Jennifer.jpg\n",
       "4  data\\imgs\\path_10003_Jennifer.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>data\\imgs\\path_0_Garrett.jpg</td>\n",
       "      <td>Garrett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>data\\imgs\\path_10000_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>data\\imgs\\path_10001_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>data\\imgs\\path_10002_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>data\\imgs\\path_10003_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            img_path      user\n",
       "0       data\\imgs\\path_0_Garrett.jpg   Garrett\n",
       "1  data\\imgs\\path_10000_Jennifer.jpg  Jennifer\n",
       "2  data\\imgs\\path_10001_Jennifer.jpg  Jennifer\n",
       "3  data\\imgs\\path_10002_Jennifer.jpg  Jennifer\n",
       "4  data\\imgs\\path_10003_Jennifer.jpg  Jennifer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user'] = df['img_path'].apply(lambda x: x[x.rindex('_')+1:len(x)-4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>user</th>\n",
       "      <th>path_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>data\\imgs\\path_0_Garrett.jpg</td>\n",
       "      <td>Garrett</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>data\\imgs\\path_10000_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>data\\imgs\\path_10001_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>data\\imgs\\path_10002_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>data\\imgs\\path_10003_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            img_path      user path_id\n",
       "0       data\\imgs\\path_0_Garrett.jpg   Garrett       0\n",
       "1  data\\imgs\\path_10000_Jennifer.jpg  Jennifer   10000\n",
       "2  data\\imgs\\path_10001_Jennifer.jpg  Jennifer   10001\n",
       "3  data\\imgs\\path_10002_Jennifer.jpg  Jennifer   10002\n",
       "4  data\\imgs\\path_10003_Jennifer.jpg  Jennifer   10003"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['path_id'] = df['img_path'].apply(lambda x: x[x.index('_')+1:x.rindex('_')])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "img_path    object\n",
       "user        object\n",
       "path_id     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_threshold_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img = cv2.resize(img, (100, 50), cv2.INTER_NEAREST)\n",
    "    ret, img = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY)  # very harsh threshold -- any non-white -> black pixel\n",
    "    img_array = np.array(img)\n",
    "    #img_array = np.uint8(img_array/255)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'data\\imgs\\path_10000_Jennifer.jpg'\n",
    "img = load_threshold_img(p)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAyCAAAAACPXiFiAAAAVklEQVR4nO3VsQoAIAhF0Wf0/79sW0g0CFJE3CZt8GQFmuv8ahcMEBAQEJD/kV4tYJKHWAr53C9ORlvybblyJ5lDVt8kdRH//C4QEBAQEBAQEBCQB5EBi88HY7nwwpEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x50 at 0x2AA001C2BC8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small change: limit pixel value range between 0 and 1 for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_threshold_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img = cv2.resize(img, (100, 50), cv2.INTER_NEAREST)\n",
    "    ret, img = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY)  # very harsh threshold -- any non-white -> black pixel\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.uint8(img_array/255)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['img'] = df['img_path'].apply(load_threshold_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>user</th>\n",
       "      <th>path_id</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>data\\imgs\\path_0_Garrett.jpg</td>\n",
       "      <td>Garrett</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>data\\imgs\\path_10000_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10000</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>data\\imgs\\path_10001_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10001</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>data\\imgs\\path_10002_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10002</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>data\\imgs\\path_10003_Jennifer.jpg</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>10003</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            img_path      user path_id  \\\n",
       "0       data\\imgs\\path_0_Garrett.jpg   Garrett       0   \n",
       "1  data\\imgs\\path_10000_Jennifer.jpg  Jennifer   10000   \n",
       "2  data\\imgs\\path_10001_Jennifer.jpg  Jennifer   10001   \n",
       "3  data\\imgs\\path_10002_Jennifer.jpg  Jennifer   10002   \n",
       "4  data\\imgs\\path_10003_Jennifer.jpg  Jennifer   10003   \n",
       "\n",
       "                                                 img  \n",
       "0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "1  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "2  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "3  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "4  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Reshape, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape = df.loc[0, 'img'].shape\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows, cols = img_shape\n",
    "channels = 1  # grayscale = 1, bgr / rgb = 3\n",
    "\n",
    "shape = (rows, cols, channels)\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df['img'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array(img) for img in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52153, 50, 100, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISCRIMINATOR\n",
      "Input shape: (50, 100)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 50, 100, 8)        80        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50, 100, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 100, 8)        584       \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 51, 101, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 51, 101, 8)        32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 51, 101, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 51, 101, 8)        584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 51, 101, 8)        32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 51, 101, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 51, 101, 8)        584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 51, 101, 8)        32        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 51, 101, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 41208)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 41209     \n",
      "=================================================================\n",
      "Total params: 43,137\n",
      "Trainable params: 43,089\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "GENERATOR\n",
      "Input shape: 100\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5000)              505000    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 50, 100, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 100, 12)       120       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50, 100, 12)       48        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50, 100, 12)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 100, 4)        436       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50, 100, 4)        16        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50, 100, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 100, 1)        37        \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50, 100, 1)        4         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 50, 100, 1)        0         \n",
      "=================================================================\n",
      "Total params: 505,661\n",
      "Trainable params: 505,627\n",
      "Non-trainable params: 34\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "class MousePathGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 50\n",
    "        self.img_cols = 100\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        self.latent_dim = 100\n",
    "        \n",
    "        optimizer = Adam(0.0001, 0.1)\n",
    "        # optimizer = 'adam'\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)  # classify the fake img\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(50*100*1, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((50, 100, 1)))\n",
    "        model.add(Conv2D(12, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(4, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        #model.add(Conv2D(4, kernel_size=3, padding=\"same\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(Activation(\"relu\"))\n",
    "        #model.add(Conv2D(4, kernel_size=3, padding=\"same\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        print('GENERATOR')\n",
    "        print('Input shape:', self.latent_dim)\n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(8, kernel_size=3, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(8, kernel_size=3, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.95))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(8, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.95))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(8, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.95))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        print('DISCRIMINATOR')\n",
    "        print('Input shape:', img_shape)\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def get_threshold_img(self, gen_img):\n",
    "        gen_img = gen_img * 255\n",
    "        \n",
    "        ret, img = cv2.threshold(gen_img, 1, 255, cv2.THRESH_BINARY)  # very harsh threshold -- any non-white -> black pixel\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        img_array = np.expand_dims(img_array, -1)\n",
    "        \n",
    "        #img_array = img_array.reshape((1, 50, 100, 1))\n",
    "        return img_array\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train = X\n",
    "        print('X_train shape:', X_train.shape)\n",
    "\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            gen_imgs = np.array([self.get_threshold_img(g_img) for g_img in gen_imgs])\n",
    "\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "                \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 2, 2\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        print(gen_imgs[0])\n",
    "        # Rescale images\n",
    "        #gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        gen_imgs = np.array([self.get_threshold_img(gen_img) for gen_img in gen_imgs])\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"data/generated/path_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "gan = MousePathGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206514"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (52153, 50, 100, 1)\n",
      "0 [D loss: 1.215265, acc.: 50.00%] [G loss: 0.727919]\n",
      "[[[ 0.00025588]\n",
      "  [ 0.0007617 ]\n",
      "  [-0.00773939]\n",
      "  ...\n",
      "  [-0.00163852]\n",
      "  [ 0.01006053]\n",
      "  [ 0.00910735]]\n",
      "\n",
      " [[-0.00241256]\n",
      "  [-0.00392103]\n",
      "  [-0.0083947 ]\n",
      "  ...\n",
      "  [ 0.00843751]\n",
      "  [ 0.02210529]\n",
      "  [ 0.01887649]]\n",
      "\n",
      " [[ 0.00554868]\n",
      "  [ 0.01367358]\n",
      "  [ 0.00012744]\n",
      "  ...\n",
      "  [ 0.01917583]\n",
      "  [ 0.0458033 ]\n",
      "  [ 0.01155503]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.00386917]\n",
      "  [ 0.03126585]\n",
      "  [ 0.05080916]\n",
      "  ...\n",
      "  [ 0.03150599]\n",
      "  [ 0.02321679]\n",
      "  [ 0.02538209]]\n",
      "\n",
      " [[ 0.01095153]\n",
      "  [ 0.05356419]\n",
      "  [ 0.04042678]\n",
      "  ...\n",
      "  [ 0.05343612]\n",
      "  [ 0.02881392]\n",
      "  [ 0.00610703]]\n",
      "\n",
      " [[ 0.00132166]\n",
      "  [ 0.0308971 ]\n",
      "  [ 0.02730754]\n",
      "  ...\n",
      "  [ 0.01359878]\n",
      "  [ 0.01012102]\n",
      "  [ 0.02505683]]]\n",
      "1 [D loss: 0.680967, acc.: 50.00%] [G loss: 0.923339]\n",
      "2 [D loss: 0.348752, acc.: 100.00%] [G loss: 1.108229]\n",
      "3 [D loss: 0.109578, acc.: 100.00%] [G loss: 1.130256]\n",
      "4 [D loss: 0.083389, acc.: 100.00%] [G loss: 1.109506]\n",
      "5 [D loss: 0.066139, acc.: 100.00%] [G loss: 1.085182]\n",
      "6 [D loss: 0.067650, acc.: 100.00%] [G loss: 1.063130]\n",
      "7 [D loss: 0.091427, acc.: 100.00%] [G loss: 1.143895]\n",
      "8 [D loss: 0.053443, acc.: 100.00%] [G loss: 1.151275]\n",
      "9 [D loss: 0.039740, acc.: 100.00%] [G loss: 1.194653]\n",
      "10 [D loss: 0.011880, acc.: 100.00%] [G loss: 1.182194]\n",
      "11 [D loss: 0.016698, acc.: 100.00%] [G loss: 1.147664]\n",
      "12 [D loss: 0.019560, acc.: 100.00%] [G loss: 1.135307]\n",
      "13 [D loss: 0.041702, acc.: 100.00%] [G loss: 1.129264]\n",
      "14 [D loss: 0.025239, acc.: 100.00%] [G loss: 1.123350]\n",
      "15 [D loss: 0.016167, acc.: 100.00%] [G loss: 1.157269]\n",
      "16 [D loss: 0.017154, acc.: 100.00%] [G loss: 1.174207]\n",
      "17 [D loss: 0.013853, acc.: 100.00%] [G loss: 1.217536]\n",
      "18 [D loss: 0.018504, acc.: 100.00%] [G loss: 1.244364]\n",
      "19 [D loss: 0.010454, acc.: 100.00%] [G loss: 1.294074]\n",
      "20 [D loss: 0.012550, acc.: 100.00%] [G loss: 1.341606]\n",
      "21 [D loss: 0.007068, acc.: 100.00%] [G loss: 1.383780]\n",
      "22 [D loss: 0.009947, acc.: 100.00%] [G loss: 1.396182]\n",
      "23 [D loss: 0.004667, acc.: 100.00%] [G loss: 1.415524]\n",
      "24 [D loss: 0.005690, acc.: 100.00%] [G loss: 1.451448]\n",
      "25 [D loss: 0.004395, acc.: 100.00%] [G loss: 1.472677]\n",
      "26 [D loss: 0.003328, acc.: 100.00%] [G loss: 1.488039]\n",
      "27 [D loss: 0.005140, acc.: 100.00%] [G loss: 1.507384]\n",
      "28 [D loss: 0.013773, acc.: 100.00%] [G loss: 1.539350]\n",
      "29 [D loss: 0.004799, acc.: 100.00%] [G loss: 1.537544]\n",
      "30 [D loss: 0.007581, acc.: 100.00%] [G loss: 1.569948]\n",
      "31 [D loss: 0.008206, acc.: 100.00%] [G loss: 1.579831]\n",
      "32 [D loss: 0.008620, acc.: 100.00%] [G loss: 1.624504]\n",
      "33 [D loss: 0.012638, acc.: 100.00%] [G loss: 1.709900]\n",
      "34 [D loss: 0.008943, acc.: 100.00%] [G loss: 1.713794]\n",
      "35 [D loss: 0.004302, acc.: 100.00%] [G loss: 1.737283]\n",
      "36 [D loss: 0.008321, acc.: 100.00%] [G loss: 1.737737]\n",
      "37 [D loss: 0.006367, acc.: 100.00%] [G loss: 1.729829]\n",
      "38 [D loss: 0.004210, acc.: 100.00%] [G loss: 1.746504]\n",
      "39 [D loss: 0.012024, acc.: 100.00%] [G loss: 1.809535]\n",
      "40 [D loss: 0.003854, acc.: 100.00%] [G loss: 1.847352]\n",
      "41 [D loss: 0.008337, acc.: 100.00%] [G loss: 1.829223]\n",
      "42 [D loss: 0.011989, acc.: 100.00%] [G loss: 1.859032]\n",
      "43 [D loss: 0.000915, acc.: 100.00%] [G loss: 1.877795]\n",
      "44 [D loss: 0.017919, acc.: 100.00%] [G loss: 1.890643]\n",
      "45 [D loss: 0.012908, acc.: 100.00%] [G loss: 1.933883]\n",
      "46 [D loss: 0.012763, acc.: 100.00%] [G loss: 2.005689]\n",
      "47 [D loss: 0.032841, acc.: 100.00%] [G loss: 2.146849]\n",
      "48 [D loss: 0.003575, acc.: 100.00%] [G loss: 2.137953]\n",
      "49 [D loss: 0.002917, acc.: 100.00%] [G loss: 2.130964]\n",
      "50 [D loss: 0.002630, acc.: 100.00%] [G loss: 2.127846]\n",
      "51 [D loss: 0.002545, acc.: 100.00%] [G loss: 2.152145]\n",
      "52 [D loss: 0.014079, acc.: 100.00%] [G loss: 2.213368]\n",
      "53 [D loss: 0.003339, acc.: 100.00%] [G loss: 2.233124]\n",
      "54 [D loss: 0.006263, acc.: 100.00%] [G loss: 2.213562]\n",
      "55 [D loss: 0.002121, acc.: 100.00%] [G loss: 2.187538]\n",
      "56 [D loss: 0.009166, acc.: 100.00%] [G loss: 2.208560]\n",
      "57 [D loss: 0.012683, acc.: 100.00%] [G loss: 2.216045]\n",
      "58 [D loss: 0.008774, acc.: 100.00%] [G loss: 2.191808]\n",
      "59 [D loss: 0.003136, acc.: 100.00%] [G loss: 2.177236]\n",
      "60 [D loss: 0.003455, acc.: 100.00%] [G loss: 2.140604]\n",
      "61 [D loss: 0.007170, acc.: 100.00%] [G loss: 2.155067]\n",
      "62 [D loss: 0.009993, acc.: 100.00%] [G loss: 2.168662]\n",
      "63 [D loss: 0.004928, acc.: 100.00%] [G loss: 2.184989]\n",
      "64 [D loss: 0.002561, acc.: 100.00%] [G loss: 2.184375]\n",
      "65 [D loss: 0.005680, acc.: 100.00%] [G loss: 2.170047]\n",
      "66 [D loss: 0.015222, acc.: 100.00%] [G loss: 2.213629]\n",
      "67 [D loss: 0.014470, acc.: 100.00%] [G loss: 2.244778]\n",
      "68 [D loss: 0.012806, acc.: 100.00%] [G loss: 2.249693]\n",
      "69 [D loss: 0.030493, acc.: 100.00%] [G loss: 2.340233]\n",
      "70 [D loss: 0.003323, acc.: 100.00%] [G loss: 2.277263]\n",
      "71 [D loss: 0.004724, acc.: 100.00%] [G loss: 2.277091]\n",
      "72 [D loss: 0.007040, acc.: 100.00%] [G loss: 2.291785]\n",
      "73 [D loss: 0.023935, acc.: 100.00%] [G loss: 2.357794]\n",
      "74 [D loss: 0.003229, acc.: 100.00%] [G loss: 2.332691]\n",
      "75 [D loss: 0.021957, acc.: 100.00%] [G loss: 2.350884]\n",
      "76 [D loss: 0.004406, acc.: 100.00%] [G loss: 2.282912]\n",
      "77 [D loss: 0.006673, acc.: 100.00%] [G loss: 2.331739]\n",
      "78 [D loss: 0.113583, acc.: 100.00%] [G loss: 2.383303]\n",
      "79 [D loss: 0.001949, acc.: 100.00%] [G loss: 2.441349]\n",
      "80 [D loss: 0.004159, acc.: 100.00%] [G loss: 2.442898]\n",
      "81 [D loss: 0.005872, acc.: 100.00%] [G loss: 2.408454]\n",
      "82 [D loss: 0.004413, acc.: 100.00%] [G loss: 2.530017]\n",
      "83 [D loss: 0.001141, acc.: 100.00%] [G loss: 2.586363]\n",
      "84 [D loss: 0.013245, acc.: 100.00%] [G loss: 2.598058]\n",
      "85 [D loss: 0.002760, acc.: 100.00%] [G loss: 2.652894]\n",
      "86 [D loss: 0.002064, acc.: 100.00%] [G loss: 2.622981]\n",
      "87 [D loss: 0.004538, acc.: 100.00%] [G loss: 2.587623]\n",
      "88 [D loss: 0.003823, acc.: 100.00%] [G loss: 2.559607]\n",
      "89 [D loss: 0.003008, acc.: 100.00%] [G loss: 2.587897]\n",
      "90 [D loss: 0.004139, acc.: 100.00%] [G loss: 2.674445]\n",
      "91 [D loss: 0.010337, acc.: 100.00%] [G loss: 2.634295]\n",
      "92 [D loss: 0.004454, acc.: 100.00%] [G loss: 2.675532]\n",
      "93 [D loss: 0.009607, acc.: 100.00%] [G loss: 2.592681]\n",
      "94 [D loss: 0.004170, acc.: 100.00%] [G loss: 2.672963]\n",
      "95 [D loss: 0.007626, acc.: 100.00%] [G loss: 2.771502]\n",
      "96 [D loss: 0.002279, acc.: 100.00%] [G loss: 2.837780]\n",
      "97 [D loss: 0.003839, acc.: 100.00%] [G loss: 2.821915]\n",
      "98 [D loss: 0.001759, acc.: 100.00%] [G loss: 2.868906]\n",
      "99 [D loss: 0.011983, acc.: 100.00%] [G loss: 2.788570]\n",
      "100 [D loss: 0.003357, acc.: 100.00%] [G loss: 2.858872]\n",
      "[[[-0.46490002]\n",
      "  [-0.17200182]\n",
      "  [-0.2399141 ]\n",
      "  ...\n",
      "  [-0.18560834]\n",
      "  [-0.20600605]\n",
      "  [ 0.04131556]]\n",
      "\n",
      " [[-0.3820337 ]\n",
      "  [-0.23356661]\n",
      "  [-0.22728513]\n",
      "  ...\n",
      "  [-0.17709935]\n",
      "  [-0.27638   ]\n",
      "  [-0.0500601 ]]\n",
      "\n",
      " [[-0.3673811 ]\n",
      "  [-0.25980815]\n",
      "  [-0.2418844 ]\n",
      "  ...\n",
      "  [-0.21898155]\n",
      "  [-0.27600068]\n",
      "  [-0.09990215]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.43410686]\n",
      "  [-0.19366214]\n",
      "  [-0.29119813]\n",
      "  ...\n",
      "  [-0.07983279]\n",
      "  [-0.4043696 ]\n",
      "  [-0.16129115]]\n",
      "\n",
      " [[-0.42884463]\n",
      "  [-0.2465358 ]\n",
      "  [-0.15329349]\n",
      "  ...\n",
      "  [-0.1095719 ]\n",
      "  [-0.23481238]\n",
      "  [-0.23926443]]\n",
      "\n",
      " [[-0.36362553]\n",
      "  [-0.24749805]\n",
      "  [-0.17937587]\n",
      "  ...\n",
      "  [-0.21781427]\n",
      "  [-0.22549045]\n",
      "  [-0.25294268]]]\n",
      "101 [D loss: 0.031284, acc.: 100.00%] [G loss: 2.965068]\n",
      "102 [D loss: 0.007868, acc.: 100.00%] [G loss: 2.984084]\n",
      "103 [D loss: 0.007498, acc.: 100.00%] [G loss: 2.988232]\n",
      "104 [D loss: 0.000765, acc.: 100.00%] [G loss: 3.037013]\n",
      "105 [D loss: 0.023821, acc.: 100.00%] [G loss: 3.147697]\n",
      "106 [D loss: 0.000735, acc.: 100.00%] [G loss: 3.197316]\n",
      "107 [D loss: 0.008669, acc.: 100.00%] [G loss: 3.179268]\n",
      "108 [D loss: 0.002620, acc.: 100.00%] [G loss: 3.193091]\n",
      "109 [D loss: 0.000697, acc.: 100.00%] [G loss: 3.304924]\n",
      "110 [D loss: 0.001015, acc.: 100.00%] [G loss: 3.398999]\n",
      "111 [D loss: 0.013491, acc.: 100.00%] [G loss: 3.344858]\n",
      "112 [D loss: 0.001308, acc.: 100.00%] [G loss: 3.286875]\n",
      "113 [D loss: 0.000407, acc.: 100.00%] [G loss: 3.241197]\n",
      "114 [D loss: 0.000571, acc.: 100.00%] [G loss: 3.283561]\n",
      "115 [D loss: 0.000857, acc.: 100.00%] [G loss: 3.357657]\n",
      "116 [D loss: 0.001526, acc.: 100.00%] [G loss: 3.396300]\n",
      "117 [D loss: 0.001998, acc.: 100.00%] [G loss: 3.381741]\n",
      "118 [D loss: 0.001363, acc.: 100.00%] [G loss: 3.419218]\n",
      "119 [D loss: 0.003667, acc.: 100.00%] [G loss: 3.393735]\n",
      "120 [D loss: 0.001570, acc.: 100.00%] [G loss: 3.531605]\n",
      "121 [D loss: 0.000796, acc.: 100.00%] [G loss: 3.505600]\n",
      "122 [D loss: 0.001371, acc.: 100.00%] [G loss: 3.462332]\n",
      "123 [D loss: 0.000222, acc.: 100.00%] [G loss: 3.613104]\n",
      "124 [D loss: 0.000814, acc.: 100.00%] [G loss: 3.656057]\n",
      "125 [D loss: 0.000114, acc.: 100.00%] [G loss: 3.648698]\n",
      "126 [D loss: 0.000270, acc.: 100.00%] [G loss: 3.701831]\n",
      "127 [D loss: 0.000806, acc.: 100.00%] [G loss: 3.733878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 [D loss: 0.001798, acc.: 100.00%] [G loss: 3.787220]\n",
      "129 [D loss: 0.000183, acc.: 100.00%] [G loss: 3.839506]\n",
      "130 [D loss: 0.000279, acc.: 100.00%] [G loss: 3.815092]\n",
      "131 [D loss: 0.001412, acc.: 100.00%] [G loss: 3.860221]\n",
      "132 [D loss: 0.000326, acc.: 100.00%] [G loss: 3.860605]\n",
      "133 [D loss: 0.000131, acc.: 100.00%] [G loss: 3.871491]\n",
      "134 [D loss: 0.000202, acc.: 100.00%] [G loss: 3.920363]\n",
      "135 [D loss: 0.001667, acc.: 100.00%] [G loss: 3.932206]\n",
      "136 [D loss: 0.000373, acc.: 100.00%] [G loss: 3.972391]\n",
      "137 [D loss: 0.000177, acc.: 100.00%] [G loss: 3.929375]\n",
      "138 [D loss: 0.000176, acc.: 100.00%] [G loss: 4.007370]\n",
      "139 [D loss: 0.000135, acc.: 100.00%] [G loss: 4.083447]\n",
      "140 [D loss: 0.001761, acc.: 100.00%] [G loss: 4.013240]\n",
      "141 [D loss: 0.000232, acc.: 100.00%] [G loss: 4.055328]\n",
      "142 [D loss: 0.000085, acc.: 100.00%] [G loss: 4.062747]\n",
      "143 [D loss: 0.000158, acc.: 100.00%] [G loss: 3.995350]\n",
      "144 [D loss: 0.000386, acc.: 100.00%] [G loss: 4.090196]\n",
      "145 [D loss: 0.000282, acc.: 100.00%] [G loss: 4.072291]\n",
      "146 [D loss: 0.000094, acc.: 100.00%] [G loss: 4.130659]\n",
      "147 [D loss: 0.000188, acc.: 100.00%] [G loss: 4.129497]\n",
      "148 [D loss: 0.000673, acc.: 100.00%] [G loss: 4.235472]\n",
      "149 [D loss: 0.000274, acc.: 100.00%] [G loss: 4.296257]\n",
      "150 [D loss: 0.000335, acc.: 100.00%] [G loss: 4.290607]\n",
      "151 [D loss: 0.000107, acc.: 100.00%] [G loss: 4.255696]\n",
      "152 [D loss: 0.000089, acc.: 100.00%] [G loss: 4.286038]\n",
      "153 [D loss: 0.000240, acc.: 100.00%] [G loss: 4.293489]\n",
      "154 [D loss: 0.000248, acc.: 100.00%] [G loss: 4.353769]\n",
      "155 [D loss: 0.000169, acc.: 100.00%] [G loss: 4.357264]\n",
      "156 [D loss: 0.000141, acc.: 100.00%] [G loss: 4.402854]\n",
      "157 [D loss: 0.000913, acc.: 100.00%] [G loss: 4.406922]\n",
      "158 [D loss: 0.000106, acc.: 100.00%] [G loss: 4.379607]\n",
      "159 [D loss: 0.000163, acc.: 100.00%] [G loss: 4.421037]\n",
      "160 [D loss: 0.000786, acc.: 100.00%] [G loss: 4.461778]\n",
      "161 [D loss: 0.000113, acc.: 100.00%] [G loss: 4.447653]\n",
      "162 [D loss: 0.000295, acc.: 100.00%] [G loss: 4.480802]\n",
      "163 [D loss: 0.000493, acc.: 100.00%] [G loss: 4.482418]\n",
      "164 [D loss: 0.000282, acc.: 100.00%] [G loss: 4.474779]\n",
      "165 [D loss: 0.000205, acc.: 100.00%] [G loss: 4.479841]\n",
      "166 [D loss: 0.000266, acc.: 100.00%] [G loss: 4.485980]\n",
      "167 [D loss: 0.000139, acc.: 100.00%] [G loss: 4.499638]\n",
      "168 [D loss: 0.000161, acc.: 100.00%] [G loss: 4.541500]\n",
      "169 [D loss: 0.000068, acc.: 100.00%] [G loss: 4.552929]\n",
      "170 [D loss: 0.000211, acc.: 100.00%] [G loss: 4.549459]\n",
      "171 [D loss: 0.000127, acc.: 100.00%] [G loss: 4.563250]\n",
      "172 [D loss: 0.000129, acc.: 100.00%] [G loss: 4.604980]\n",
      "173 [D loss: 0.000180, acc.: 100.00%] [G loss: 4.599708]\n",
      "174 [D loss: 0.000221, acc.: 100.00%] [G loss: 4.613833]\n",
      "175 [D loss: 0.000196, acc.: 100.00%] [G loss: 4.629744]\n",
      "176 [D loss: 0.000109, acc.: 100.00%] [G loss: 4.664288]\n",
      "177 [D loss: 0.000144, acc.: 100.00%] [G loss: 4.640510]\n",
      "178 [D loss: 0.000205, acc.: 100.00%] [G loss: 4.650470]\n",
      "179 [D loss: 0.000035, acc.: 100.00%] [G loss: 4.650995]\n",
      "180 [D loss: 0.000492, acc.: 100.00%] [G loss: 4.638636]\n",
      "181 [D loss: 0.000064, acc.: 100.00%] [G loss: 4.655169]\n",
      "182 [D loss: 0.000390, acc.: 100.00%] [G loss: 4.647689]\n",
      "183 [D loss: 0.000331, acc.: 100.00%] [G loss: 4.667139]\n",
      "184 [D loss: 0.000161, acc.: 100.00%] [G loss: 4.666076]\n",
      "185 [D loss: 0.000458, acc.: 100.00%] [G loss: 4.699173]\n",
      "186 [D loss: 0.000057, acc.: 100.00%] [G loss: 4.663852]\n",
      "187 [D loss: 0.000250, acc.: 100.00%] [G loss: 4.660765]\n",
      "188 [D loss: 0.000119, acc.: 100.00%] [G loss: 4.657960]\n",
      "189 [D loss: 0.000129, acc.: 100.00%] [G loss: 4.665098]\n",
      "190 [D loss: 0.000051, acc.: 100.00%] [G loss: 4.702762]\n",
      "191 [D loss: 0.000061, acc.: 100.00%] [G loss: 4.674164]\n",
      "192 [D loss: 0.000104, acc.: 100.00%] [G loss: 4.698055]\n",
      "193 [D loss: 0.000110, acc.: 100.00%] [G loss: 4.675969]\n",
      "194 [D loss: 0.000150, acc.: 100.00%] [G loss: 4.684815]\n",
      "195 [D loss: 0.000135, acc.: 100.00%] [G loss: 4.699853]\n",
      "196 [D loss: 0.000096, acc.: 100.00%] [G loss: 4.687237]\n",
      "197 [D loss: 0.000074, acc.: 100.00%] [G loss: 4.692436]\n",
      "198 [D loss: 0.000068, acc.: 100.00%] [G loss: 4.680555]\n",
      "199 [D loss: 0.000032, acc.: 100.00%] [G loss: 4.687072]\n",
      "200 [D loss: 0.000092, acc.: 100.00%] [G loss: 4.696270]\n",
      "[[[-0.6886449 ]\n",
      "  [-0.05420382]\n",
      "  [-0.30053988]\n",
      "  ...\n",
      "  [-0.43196237]\n",
      "  [-0.38847268]\n",
      "  [ 0.03853906]]\n",
      "\n",
      " [[-0.6327484 ]\n",
      "  [-0.2151201 ]\n",
      "  [-0.13391335]\n",
      "  ...\n",
      "  [-0.5702647 ]\n",
      "  [-0.2528915 ]\n",
      "  [-0.30256212]]\n",
      "\n",
      " [[-0.72295463]\n",
      "  [-0.30838573]\n",
      "  [-0.17352338]\n",
      "  ...\n",
      "  [-0.42187878]\n",
      "  [-0.35204107]\n",
      "  [-0.11862586]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.608591  ]\n",
      "  [ 0.10655034]\n",
      "  [-0.3061426 ]\n",
      "  ...\n",
      "  [-0.26822138]\n",
      "  [-0.3323733 ]\n",
      "  [-0.02944539]]\n",
      "\n",
      " [[-0.69386566]\n",
      "  [ 0.10187004]\n",
      "  [-0.43229216]\n",
      "  ...\n",
      "  [-0.24607456]\n",
      "  [-0.27675012]\n",
      "  [-0.06339233]]\n",
      "\n",
      " [[-0.45466936]\n",
      "  [-0.47034228]\n",
      "  [ 0.22474681]\n",
      "  ...\n",
      "  [-0.34022066]\n",
      "  [-0.3504678 ]\n",
      "  [-0.39578897]]]\n",
      "201 [D loss: 0.000258, acc.: 100.00%] [G loss: 4.679582]\n",
      "202 [D loss: 0.000306, acc.: 100.00%] [G loss: 4.680655]\n",
      "203 [D loss: 0.000061, acc.: 100.00%] [G loss: 4.681373]\n",
      "204 [D loss: 0.000040, acc.: 100.00%] [G loss: 4.689211]\n",
      "205 [D loss: 0.000039, acc.: 100.00%] [G loss: 4.674923]\n",
      "206 [D loss: 0.000881, acc.: 100.00%] [G loss: 4.691108]\n",
      "207 [D loss: 0.000048, acc.: 100.00%] [G loss: 4.650241]\n",
      "208 [D loss: 0.000243, acc.: 100.00%] [G loss: 4.669691]\n",
      "209 [D loss: 0.000331, acc.: 100.00%] [G loss: 4.673175]\n",
      "210 [D loss: 0.000108, acc.: 100.00%] [G loss: 4.645054]\n",
      "211 [D loss: 0.000049, acc.: 100.00%] [G loss: 4.646282]\n",
      "212 [D loss: 0.000771, acc.: 100.00%] [G loss: 4.643399]\n",
      "213 [D loss: 0.000229, acc.: 100.00%] [G loss: 4.650610]\n",
      "214 [D loss: 0.000449, acc.: 100.00%] [G loss: 4.630719]\n",
      "215 [D loss: 0.000080, acc.: 100.00%] [G loss: 4.632078]\n",
      "216 [D loss: 0.000096, acc.: 100.00%] [G loss: 4.652740]\n",
      "217 [D loss: 0.000033, acc.: 100.00%] [G loss: 4.637601]\n",
      "218 [D loss: 0.000073, acc.: 100.00%] [G loss: 4.643717]\n",
      "219 [D loss: 0.000252, acc.: 100.00%] [G loss: 4.606876]\n",
      "220 [D loss: 0.000071, acc.: 100.00%] [G loss: 4.621611]\n",
      "221 [D loss: 0.000031, acc.: 100.00%] [G loss: 4.620794]\n",
      "222 [D loss: 0.000088, acc.: 100.00%] [G loss: 4.605029]\n",
      "223 [D loss: 0.000054, acc.: 100.00%] [G loss: 4.600487]\n",
      "224 [D loss: 0.000623, acc.: 100.00%] [G loss: 4.611169]\n",
      "225 [D loss: 0.000129, acc.: 100.00%] [G loss: 4.596795]\n",
      "226 [D loss: 0.000443, acc.: 100.00%] [G loss: 4.598971]\n",
      "227 [D loss: 0.000511, acc.: 100.00%] [G loss: 4.602788]\n",
      "228 [D loss: 0.000049, acc.: 100.00%] [G loss: 4.556909]\n",
      "229 [D loss: 0.000102, acc.: 100.00%] [G loss: 4.557648]\n",
      "230 [D loss: 0.000242, acc.: 100.00%] [G loss: 4.598678]\n",
      "231 [D loss: 0.000017, acc.: 100.00%] [G loss: 4.580424]\n",
      "232 [D loss: 0.000024, acc.: 100.00%] [G loss: 4.564935]\n",
      "233 [D loss: 0.000049, acc.: 100.00%] [G loss: 4.559482]\n",
      "234 [D loss: 0.000145, acc.: 100.00%] [G loss: 4.557360]\n",
      "235 [D loss: 0.000139, acc.: 100.00%] [G loss: 4.552743]\n",
      "236 [D loss: 0.000050, acc.: 100.00%] [G loss: 4.527693]\n",
      "237 [D loss: 0.000201, acc.: 100.00%] [G loss: 4.562725]\n",
      "238 [D loss: 0.000121, acc.: 100.00%] [G loss: 4.563188]\n",
      "239 [D loss: 0.000038, acc.: 100.00%] [G loss: 4.561280]\n",
      "240 [D loss: 0.000029, acc.: 100.00%] [G loss: 4.551297]\n",
      "241 [D loss: 0.000135, acc.: 100.00%] [G loss: 4.531378]\n",
      "242 [D loss: 0.000052, acc.: 100.00%] [G loss: 4.522878]\n",
      "243 [D loss: 0.000061, acc.: 100.00%] [G loss: 4.483802]\n",
      "244 [D loss: 0.000092, acc.: 100.00%] [G loss: 4.496320]\n",
      "245 [D loss: 0.000038, acc.: 100.00%] [G loss: 4.500232]\n",
      "246 [D loss: 0.000040, acc.: 100.00%] [G loss: 4.510749]\n",
      "247 [D loss: 0.000049, acc.: 100.00%] [G loss: 4.487726]\n",
      "248 [D loss: 0.000026, acc.: 100.00%] [G loss: 4.467771]\n",
      "249 [D loss: 0.000339, acc.: 100.00%] [G loss: 4.495605]\n",
      "250 [D loss: 0.000075, acc.: 100.00%] [G loss: 4.468273]\n",
      "251 [D loss: 0.000023, acc.: 100.00%] [G loss: 4.469145]\n",
      "252 [D loss: 0.000126, acc.: 100.00%] [G loss: 4.450213]\n",
      "253 [D loss: 0.000147, acc.: 100.00%] [G loss: 4.437998]\n",
      "254 [D loss: 0.000040, acc.: 100.00%] [G loss: 4.425673]\n",
      "255 [D loss: 0.000090, acc.: 100.00%] [G loss: 4.431937]\n",
      "256 [D loss: 0.000053, acc.: 100.00%] [G loss: 4.431592]\n",
      "257 [D loss: 0.000040, acc.: 100.00%] [G loss: 4.424642]\n",
      "258 [D loss: 0.000056, acc.: 100.00%] [G loss: 4.423394]\n",
      "259 [D loss: 0.000084, acc.: 100.00%] [G loss: 4.411716]\n",
      "260 [D loss: 0.000026, acc.: 100.00%] [G loss: 4.421047]\n",
      "261 [D loss: 0.000019, acc.: 100.00%] [G loss: 4.398785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 [D loss: 0.000040, acc.: 100.00%] [G loss: 4.420502]\n",
      "263 [D loss: 0.000179, acc.: 100.00%] [G loss: 4.401505]\n",
      "264 [D loss: 0.000036, acc.: 100.00%] [G loss: 4.406304]\n",
      "265 [D loss: 0.000024, acc.: 100.00%] [G loss: 4.408289]\n",
      "266 [D loss: 0.000026, acc.: 100.00%] [G loss: 4.376614]\n",
      "267 [D loss: 0.000078, acc.: 100.00%] [G loss: 4.405519]\n",
      "268 [D loss: 0.000094, acc.: 100.00%] [G loss: 4.400614]\n",
      "269 [D loss: 0.000311, acc.: 100.00%] [G loss: 4.384201]\n",
      "270 [D loss: 0.000039, acc.: 100.00%] [G loss: 4.364533]\n",
      "271 [D loss: 0.000088, acc.: 100.00%] [G loss: 4.389098]\n",
      "272 [D loss: 0.000112, acc.: 100.00%] [G loss: 4.385431]\n",
      "273 [D loss: 0.000068, acc.: 100.00%] [G loss: 4.374782]\n",
      "274 [D loss: 0.000120, acc.: 100.00%] [G loss: 4.388917]\n",
      "275 [D loss: 0.000173, acc.: 100.00%] [G loss: 4.363624]\n",
      "276 [D loss: 0.000226, acc.: 100.00%] [G loss: 4.383709]\n",
      "277 [D loss: 0.000043, acc.: 100.00%] [G loss: 4.360116]\n",
      "278 [D loss: 0.000018, acc.: 100.00%] [G loss: 4.359218]\n",
      "279 [D loss: 0.000097, acc.: 100.00%] [G loss: 4.380146]\n",
      "280 [D loss: 0.000031, acc.: 100.00%] [G loss: 4.356368]\n",
      "281 [D loss: 0.000018, acc.: 100.00%] [G loss: 4.359074]\n",
      "282 [D loss: 0.000041, acc.: 100.00%] [G loss: 4.348252]\n",
      "283 [D loss: 0.000030, acc.: 100.00%] [G loss: 4.356879]\n",
      "284 [D loss: 0.000032, acc.: 100.00%] [G loss: 4.325794]\n",
      "285 [D loss: 0.000040, acc.: 100.00%] [G loss: 4.339096]\n",
      "286 [D loss: 0.000027, acc.: 100.00%] [G loss: 4.326000]\n",
      "287 [D loss: 0.000058, acc.: 100.00%] [G loss: 4.306683]\n",
      "288 [D loss: 0.000022, acc.: 100.00%] [G loss: 4.281734]\n",
      "289 [D loss: 0.000047, acc.: 100.00%] [G loss: 4.280623]\n",
      "290 [D loss: 0.000025, acc.: 100.00%] [G loss: 4.247099]\n",
      "291 [D loss: 0.000090, acc.: 100.00%] [G loss: 4.243377]\n",
      "292 [D loss: 0.000019, acc.: 100.00%] [G loss: 4.229576]\n",
      "293 [D loss: 0.000127, acc.: 100.00%] [G loss: 4.209867]\n",
      "294 [D loss: 0.000047, acc.: 100.00%] [G loss: 4.197677]\n",
      "295 [D loss: 0.000027, acc.: 100.00%] [G loss: 4.201803]\n",
      "296 [D loss: 0.000033, acc.: 100.00%] [G loss: 4.189710]\n",
      "297 [D loss: 0.000098, acc.: 100.00%] [G loss: 4.202758]\n",
      "298 [D loss: 0.000221, acc.: 100.00%] [G loss: 4.208417]\n",
      "299 [D loss: 0.000045, acc.: 100.00%] [G loss: 4.207583]\n",
      "300 [D loss: 0.000392, acc.: 100.00%] [G loss: 4.209324]\n",
      "[[[-0.72945046]\n",
      "  [-0.31950146]\n",
      "  [-0.28763688]\n",
      "  ...\n",
      "  [-0.47179967]\n",
      "  [-0.21070784]\n",
      "  [-0.06793825]]\n",
      "\n",
      " [[-0.8461949 ]\n",
      "  [ 0.17824109]\n",
      "  [-0.662333  ]\n",
      "  ...\n",
      "  [-0.2568036 ]\n",
      "  [-0.55893743]\n",
      "  [-0.29593253]]\n",
      "\n",
      " [[-0.5134505 ]\n",
      "  [-0.28818575]\n",
      "  [-0.15897219]\n",
      "  ...\n",
      "  [-0.49183157]\n",
      "  [-0.6677762 ]\n",
      "  [-0.23153433]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.61067367]\n",
      "  [-0.32948518]\n",
      "  [-0.50415206]\n",
      "  ...\n",
      "  [-0.31316686]\n",
      "  [-0.35088226]\n",
      "  [-0.30487338]]\n",
      "\n",
      " [[-0.6969495 ]\n",
      "  [-0.26323324]\n",
      "  [-0.32564947]\n",
      "  ...\n",
      "  [-0.42091057]\n",
      "  [-0.5249665 ]\n",
      "  [ 0.2230653 ]]\n",
      "\n",
      " [[-0.6287972 ]\n",
      "  [-0.24460204]\n",
      "  [-0.40147904]\n",
      "  ...\n",
      "  [-0.4591003 ]\n",
      "  [-0.2989252 ]\n",
      "  [-0.4018548 ]]]\n",
      "301 [D loss: 0.000126, acc.: 100.00%] [G loss: 4.230805]\n",
      "302 [D loss: 0.000022, acc.: 100.00%] [G loss: 4.208574]\n",
      "303 [D loss: 0.000032, acc.: 100.00%] [G loss: 4.224458]\n",
      "304 [D loss: 0.000014, acc.: 100.00%] [G loss: 4.216157]\n",
      "305 [D loss: 0.000020, acc.: 100.00%] [G loss: 4.200336]\n",
      "306 [D loss: 0.000037, acc.: 100.00%] [G loss: 4.170071]\n",
      "307 [D loss: 0.000216, acc.: 100.00%] [G loss: 4.204470]\n",
      "308 [D loss: 0.000049, acc.: 100.00%] [G loss: 4.200162]\n",
      "309 [D loss: 0.000033, acc.: 100.00%] [G loss: 4.181555]\n",
      "310 [D loss: 0.000025, acc.: 100.00%] [G loss: 4.175038]\n",
      "311 [D loss: 0.000064, acc.: 100.00%] [G loss: 4.203834]\n",
      "312 [D loss: 0.000046, acc.: 100.00%] [G loss: 4.189770]\n",
      "313 [D loss: 0.000100, acc.: 100.00%] [G loss: 4.149699]\n",
      "314 [D loss: 0.000187, acc.: 100.00%] [G loss: 4.185159]\n",
      "315 [D loss: 0.000018, acc.: 100.00%] [G loss: 4.156071]\n",
      "316 [D loss: 0.000049, acc.: 100.00%] [G loss: 4.144061]\n",
      "317 [D loss: 0.000022, acc.: 100.00%] [G loss: 4.121098]\n",
      "318 [D loss: 0.000197, acc.: 100.00%] [G loss: 4.146513]\n",
      "319 [D loss: 0.000166, acc.: 100.00%] [G loss: 4.141177]\n",
      "320 [D loss: 0.000103, acc.: 100.00%] [G loss: 4.143416]\n",
      "321 [D loss: 0.000023, acc.: 100.00%] [G loss: 4.119145]\n",
      "322 [D loss: 0.000092, acc.: 100.00%] [G loss: 4.115601]\n",
      "323 [D loss: 0.000073, acc.: 100.00%] [G loss: 4.136974]\n",
      "324 [D loss: 0.000028, acc.: 100.00%] [G loss: 4.119080]\n",
      "325 [D loss: 0.000024, acc.: 100.00%] [G loss: 4.112793]\n",
      "326 [D loss: 0.000082, acc.: 100.00%] [G loss: 4.102785]\n",
      "327 [D loss: 0.000063, acc.: 100.00%] [G loss: 4.092343]\n",
      "328 [D loss: 0.000137, acc.: 100.00%] [G loss: 4.102931]\n",
      "329 [D loss: 0.000053, acc.: 100.00%] [G loss: 4.105490]\n",
      "330 [D loss: 0.000025, acc.: 100.00%] [G loss: 4.093820]\n",
      "331 [D loss: 0.000136, acc.: 100.00%] [G loss: 4.086874]\n",
      "332 [D loss: 0.000054, acc.: 100.00%] [G loss: 4.099014]\n",
      "333 [D loss: 0.000078, acc.: 100.00%] [G loss: 4.081924]\n",
      "334 [D loss: 0.000030, acc.: 100.00%] [G loss: 4.087376]\n",
      "335 [D loss: 0.000099, acc.: 100.00%] [G loss: 4.057871]\n",
      "336 [D loss: 0.000136, acc.: 100.00%] [G loss: 4.054910]\n",
      "337 [D loss: 0.000012, acc.: 100.00%] [G loss: 4.053960]\n",
      "338 [D loss: 0.000057, acc.: 100.00%] [G loss: 4.028235]\n",
      "339 [D loss: 0.000027, acc.: 100.00%] [G loss: 4.007936]\n",
      "340 [D loss: 0.000025, acc.: 100.00%] [G loss: 4.003900]\n",
      "341 [D loss: 0.000076, acc.: 100.00%] [G loss: 3.991912]\n",
      "342 [D loss: 0.000153, acc.: 100.00%] [G loss: 4.008536]\n",
      "343 [D loss: 0.000393, acc.: 100.00%] [G loss: 3.999492]\n",
      "344 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.963579]\n",
      "345 [D loss: 0.000059, acc.: 100.00%] [G loss: 3.985796]\n",
      "346 [D loss: 0.000058, acc.: 100.00%] [G loss: 3.964904]\n",
      "347 [D loss: 0.000131, acc.: 100.00%] [G loss: 3.964532]\n",
      "348 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.963832]\n",
      "349 [D loss: 0.000066, acc.: 100.00%] [G loss: 3.961218]\n",
      "350 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.954940]\n",
      "351 [D loss: 0.000056, acc.: 100.00%] [G loss: 3.954307]\n",
      "352 [D loss: 0.000065, acc.: 100.00%] [G loss: 3.970436]\n",
      "353 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.931008]\n",
      "354 [D loss: 0.000054, acc.: 100.00%] [G loss: 3.938016]\n",
      "355 [D loss: 0.000042, acc.: 100.00%] [G loss: 3.915441]\n",
      "356 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.889375]\n",
      "357 [D loss: 0.000038, acc.: 100.00%] [G loss: 3.878367]\n",
      "358 [D loss: 0.000041, acc.: 100.00%] [G loss: 3.876835]\n",
      "359 [D loss: 0.000042, acc.: 100.00%] [G loss: 3.886353]\n",
      "360 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.883412]\n",
      "361 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.854708]\n",
      "362 [D loss: 0.000051, acc.: 100.00%] [G loss: 3.875380]\n",
      "363 [D loss: 0.000050, acc.: 100.00%] [G loss: 3.856003]\n",
      "364 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.871494]\n",
      "365 [D loss: 0.000055, acc.: 100.00%] [G loss: 3.841933]\n",
      "366 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.852750]\n",
      "367 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.857784]\n",
      "368 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.850428]\n",
      "369 [D loss: 0.000155, acc.: 100.00%] [G loss: 3.844178]\n",
      "370 [D loss: 0.000038, acc.: 100.00%] [G loss: 3.850180]\n",
      "371 [D loss: 0.000048, acc.: 100.00%] [G loss: 3.831213]\n",
      "372 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.819661]\n",
      "373 [D loss: 0.000087, acc.: 100.00%] [G loss: 3.812248]\n",
      "374 [D loss: 0.000035, acc.: 100.00%] [G loss: 3.807925]\n",
      "375 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.793946]\n",
      "376 [D loss: 0.000050, acc.: 100.00%] [G loss: 3.801598]\n",
      "377 [D loss: 0.000187, acc.: 100.00%] [G loss: 3.804316]\n",
      "378 [D loss: 0.000051, acc.: 100.00%] [G loss: 3.824498]\n",
      "379 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.830969]\n",
      "380 [D loss: 0.000379, acc.: 100.00%] [G loss: 3.823830]\n",
      "381 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.833299]\n",
      "382 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.809038]\n",
      "383 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.802525]\n",
      "384 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.783668]\n",
      "385 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.795037]\n",
      "386 [D loss: 0.000052, acc.: 100.00%] [G loss: 3.790397]\n",
      "387 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.782922]\n",
      "388 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.805563]\n",
      "389 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.786061]\n",
      "390 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.762625]\n",
      "391 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.770740]\n",
      "392 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.759842]\n",
      "393 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.752609]\n",
      "394 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.722937]\n",
      "395 [D loss: 0.000090, acc.: 100.00%] [G loss: 3.746332]\n",
      "396 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.734399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.719093]\n",
      "398 [D loss: 0.000035, acc.: 100.00%] [G loss: 3.731342]\n",
      "399 [D loss: 0.000077, acc.: 100.00%] [G loss: 3.741534]\n",
      "400 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.719930]\n",
      "[[[-0.81503725]\n",
      "  [-0.4755303 ]\n",
      "  [-0.48175147]\n",
      "  ...\n",
      "  [-0.4972495 ]\n",
      "  [-0.45620465]\n",
      "  [-0.29708165]]\n",
      "\n",
      " [[-0.9030464 ]\n",
      "  [-0.3576363 ]\n",
      "  [-0.3371441 ]\n",
      "  ...\n",
      "  [-0.6056801 ]\n",
      "  [-0.5265176 ]\n",
      "  [-0.75438136]]\n",
      "\n",
      " [[-0.49192452]\n",
      "  [-0.27591032]\n",
      "  [-0.689909  ]\n",
      "  ...\n",
      "  [ 0.3819026 ]\n",
      "  [-0.779733  ]\n",
      "  [ 0.04674721]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.86645377]\n",
      "  [ 0.14322037]\n",
      "  [-0.4966145 ]\n",
      "  ...\n",
      "  [-0.63841736]\n",
      "  [-0.69629556]\n",
      "  [-0.14824685]]\n",
      "\n",
      " [[-0.72193855]\n",
      "  [-0.06150733]\n",
      "  [-0.26614186]\n",
      "  ...\n",
      "  [-0.19045363]\n",
      "  [-0.48115745]\n",
      "  [-0.4325406 ]]\n",
      "\n",
      " [[-0.55029917]\n",
      "  [-0.5006468 ]\n",
      "  [-0.60233426]\n",
      "  ...\n",
      "  [-0.28545544]\n",
      "  [-0.56377876]\n",
      "  [-0.3958565 ]]]\n",
      "401 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.702417]\n",
      "402 [D loss: 0.000104, acc.: 100.00%] [G loss: 3.735946]\n",
      "403 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.716118]\n",
      "404 [D loss: 0.000083, acc.: 100.00%] [G loss: 3.720430]\n",
      "405 [D loss: 0.000039, acc.: 100.00%] [G loss: 3.687004]\n",
      "406 [D loss: 0.000060, acc.: 100.00%] [G loss: 3.690123]\n",
      "407 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.672805]\n",
      "408 [D loss: 0.000147, acc.: 100.00%] [G loss: 3.681380]\n",
      "409 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.658566]\n",
      "410 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.662168]\n",
      "411 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.656729]\n",
      "412 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.626606]\n",
      "413 [D loss: 0.000064, acc.: 100.00%] [G loss: 3.651448]\n",
      "414 [D loss: 0.000065, acc.: 100.00%] [G loss: 3.656274]\n",
      "415 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.649462]\n",
      "416 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.676139]\n",
      "417 [D loss: 0.000195, acc.: 100.00%] [G loss: 3.647380]\n",
      "418 [D loss: 0.000051, acc.: 100.00%] [G loss: 3.661872]\n",
      "419 [D loss: 0.000056, acc.: 100.00%] [G loss: 3.659055]\n",
      "420 [D loss: 0.000057, acc.: 100.00%] [G loss: 3.639886]\n",
      "421 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.652672]\n",
      "422 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.676070]\n",
      "423 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.634931]\n",
      "424 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.652028]\n",
      "425 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.625023]\n",
      "426 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.626716]\n",
      "427 [D loss: 0.000103, acc.: 100.00%] [G loss: 3.618643]\n",
      "428 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.615842]\n",
      "429 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.613998]\n",
      "430 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.597329]\n",
      "431 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.615278]\n",
      "432 [D loss: 0.000038, acc.: 100.00%] [G loss: 3.600583]\n",
      "433 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.608951]\n",
      "434 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.608564]\n",
      "435 [D loss: 0.000046, acc.: 100.00%] [G loss: 3.600006]\n",
      "436 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.604130]\n",
      "437 [D loss: 0.000033, acc.: 100.00%] [G loss: 3.602673]\n",
      "438 [D loss: 0.000047, acc.: 100.00%] [G loss: 3.631604]\n",
      "439 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.599514]\n",
      "440 [D loss: 0.000082, acc.: 100.00%] [G loss: 3.601108]\n",
      "441 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.589406]\n",
      "442 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.565304]\n",
      "443 [D loss: 0.000052, acc.: 100.00%] [G loss: 3.552474]\n",
      "444 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.547844]\n",
      "445 [D loss: 0.000047, acc.: 100.00%] [G loss: 3.538786]\n",
      "446 [D loss: 0.000049, acc.: 100.00%] [G loss: 3.543641]\n",
      "447 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.538616]\n",
      "448 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.537061]\n",
      "449 [D loss: 0.000111, acc.: 100.00%] [G loss: 3.548069]\n",
      "450 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.559664]\n",
      "451 [D loss: 0.000086, acc.: 100.00%] [G loss: 3.544808]\n",
      "452 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.543018]\n",
      "453 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.548195]\n",
      "454 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.549154]\n",
      "455 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.532156]\n",
      "456 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.529923]\n",
      "457 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.530138]\n",
      "458 [D loss: 0.000052, acc.: 100.00%] [G loss: 3.526421]\n",
      "459 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.521839]\n",
      "460 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.518937]\n",
      "461 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.507936]\n",
      "462 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.493116]\n",
      "463 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.490658]\n",
      "464 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.495927]\n",
      "465 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.506326]\n",
      "466 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.481283]\n",
      "467 [D loss: 0.000111, acc.: 100.00%] [G loss: 3.475622]\n",
      "468 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.473145]\n",
      "469 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.439675]\n",
      "470 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.439667]\n",
      "471 [D loss: 0.000057, acc.: 100.00%] [G loss: 3.435574]\n",
      "472 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.431177]\n",
      "473 [D loss: 0.000042, acc.: 100.00%] [G loss: 3.430792]\n",
      "474 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.440168]\n",
      "475 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.419336]\n",
      "476 [D loss: 0.000190, acc.: 100.00%] [G loss: 3.422151]\n",
      "477 [D loss: 0.000112, acc.: 100.00%] [G loss: 3.440202]\n",
      "478 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.419696]\n",
      "479 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.430574]\n",
      "480 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.440897]\n",
      "481 [D loss: 0.000226, acc.: 100.00%] [G loss: 3.442835]\n",
      "482 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.455245]\n",
      "483 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.446263]\n",
      "484 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.428989]\n",
      "485 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.439185]\n",
      "486 [D loss: 0.000041, acc.: 100.00%] [G loss: 3.440913]\n",
      "487 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.406273]\n",
      "488 [D loss: 0.000037, acc.: 100.00%] [G loss: 3.411403]\n",
      "489 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.411674]\n",
      "490 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.397797]\n",
      "491 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.390877]\n",
      "492 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.399364]\n",
      "493 [D loss: 0.000050, acc.: 100.00%] [G loss: 3.384417]\n",
      "494 [D loss: 0.000125, acc.: 100.00%] [G loss: 3.394896]\n",
      "495 [D loss: 0.000038, acc.: 100.00%] [G loss: 3.392007]\n",
      "496 [D loss: 0.000096, acc.: 100.00%] [G loss: 3.373438]\n",
      "497 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.368151]\n",
      "498 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.405767]\n",
      "499 [D loss: 0.000111, acc.: 100.00%] [G loss: 3.394318]\n",
      "500 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.367287]\n",
      "[[[ 0.06027502]\n",
      "  [ 0.6028838 ]\n",
      "  [-0.88065153]\n",
      "  ...\n",
      "  [-0.2705425 ]\n",
      "  [-0.53688896]\n",
      "  [-0.5830146 ]]\n",
      "\n",
      " [[ 0.98200655]\n",
      "  [-0.70262367]\n",
      "  [ 0.8948304 ]\n",
      "  ...\n",
      "  [ 0.5133983 ]\n",
      "  [-0.9132827 ]\n",
      "  [-0.503422  ]]\n",
      "\n",
      " [[-0.21408807]\n",
      "  [-0.04917258]\n",
      "  [ 0.894224  ]\n",
      "  ...\n",
      "  [-0.7118412 ]\n",
      "  [ 0.67492104]\n",
      "  [-0.8110049 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.01131431]\n",
      "  [-0.3340392 ]\n",
      "  [-0.1767951 ]\n",
      "  ...\n",
      "  [-0.39057702]\n",
      "  [-0.6912791 ]\n",
      "  [-0.6171342 ]]\n",
      "\n",
      " [[-0.7144408 ]\n",
      "  [ 0.0747285 ]\n",
      "  [-0.44473633]\n",
      "  ...\n",
      "  [ 0.92608577]\n",
      "  [-0.73455083]\n",
      "  [-0.01881756]]\n",
      "\n",
      " [[-0.6411463 ]\n",
      "  [-0.4590852 ]\n",
      "  [-0.51039404]\n",
      "  ...\n",
      "  [ 0.31953952]\n",
      "  [ 0.29795024]\n",
      "  [-0.34780157]]]\n",
      "501 [D loss: 0.000076, acc.: 100.00%] [G loss: 3.398738]\n",
      "502 [D loss: 0.000043, acc.: 100.00%] [G loss: 3.393754]\n",
      "503 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.397439]\n",
      "504 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.390259]\n",
      "505 [D loss: 0.000056, acc.: 100.00%] [G loss: 3.393091]\n",
      "506 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.390663]\n",
      "507 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.398377]\n",
      "508 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.408703]\n",
      "509 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.368479]\n",
      "510 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.354658]\n",
      "511 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.351612]\n",
      "512 [D loss: 0.000053, acc.: 100.00%] [G loss: 3.348628]\n",
      "513 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.345276]\n",
      "514 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.358442]\n",
      "515 [D loss: 0.000074, acc.: 100.00%] [G loss: 3.350737]\n",
      "516 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.344888]\n",
      "517 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.345205]\n",
      "518 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.328195]\n",
      "519 [D loss: 0.000054, acc.: 100.00%] [G loss: 3.338433]\n",
      "520 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.351964]\n",
      "521 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.330680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.334671]\n",
      "523 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.326841]\n",
      "524 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.317326]\n",
      "525 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.309861]\n",
      "526 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.287345]\n",
      "527 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.302042]\n",
      "528 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.288261]\n",
      "529 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.287725]\n",
      "530 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.272947]\n",
      "531 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.279075]\n",
      "532 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.267601]\n",
      "533 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.255790]\n",
      "534 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.272650]\n",
      "535 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.251596]\n",
      "536 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.268721]\n",
      "537 [D loss: 0.000069, acc.: 100.00%] [G loss: 3.275481]\n",
      "538 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.275587]\n",
      "539 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.253240]\n",
      "540 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.263392]\n",
      "541 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.282802]\n",
      "542 [D loss: 0.000045, acc.: 100.00%] [G loss: 3.295349]\n",
      "543 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.278606]\n",
      "544 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.316411]\n",
      "545 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.298215]\n",
      "546 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.305351]\n",
      "547 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.299957]\n",
      "548 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.310904]\n",
      "549 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.288697]\n",
      "550 [D loss: 0.000078, acc.: 100.00%] [G loss: 3.301265]\n",
      "551 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.285851]\n",
      "552 [D loss: 0.000044, acc.: 100.00%] [G loss: 3.307119]\n",
      "553 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.314520]\n",
      "554 [D loss: 0.000038, acc.: 100.00%] [G loss: 3.294246]\n",
      "555 [D loss: 0.000048, acc.: 100.00%] [G loss: 3.300445]\n",
      "556 [D loss: 0.000060, acc.: 100.00%] [G loss: 3.316398]\n",
      "557 [D loss: 0.000069, acc.: 100.00%] [G loss: 3.301974]\n",
      "558 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.282296]\n",
      "559 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.277032]\n",
      "560 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.290065]\n",
      "561 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.261392]\n",
      "562 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.264329]\n",
      "563 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.265355]\n",
      "564 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.237954]\n",
      "565 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.256948]\n",
      "566 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.245248]\n",
      "567 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.253405]\n",
      "568 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.234763]\n",
      "569 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.222980]\n",
      "570 [D loss: 0.000079, acc.: 100.00%] [G loss: 3.238922]\n",
      "571 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.266718]\n",
      "572 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.246089]\n",
      "573 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.237396]\n",
      "574 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.239487]\n",
      "575 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.232087]\n",
      "576 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.226843]\n",
      "577 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.245092]\n",
      "578 [D loss: 0.000057, acc.: 100.00%] [G loss: 3.239603]\n",
      "579 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.229740]\n",
      "580 [D loss: 0.000069, acc.: 100.00%] [G loss: 3.228299]\n",
      "581 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.236508]\n",
      "582 [D loss: 0.000172, acc.: 100.00%] [G loss: 3.234345]\n",
      "583 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.241592]\n",
      "584 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.235108]\n",
      "585 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.220564]\n",
      "586 [D loss: 0.000041, acc.: 100.00%] [G loss: 3.244587]\n",
      "587 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.221626]\n",
      "588 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.229244]\n",
      "589 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.222444]\n",
      "590 [D loss: 0.000053, acc.: 100.00%] [G loss: 3.219147]\n",
      "591 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.234232]\n",
      "592 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.227257]\n",
      "593 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.230412]\n",
      "594 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.199897]\n",
      "595 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.215420]\n",
      "596 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.214464]\n",
      "597 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.223984]\n",
      "598 [D loss: 0.000110, acc.: 100.00%] [G loss: 3.217150]\n",
      "599 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.226032]\n",
      "600 [D loss: 0.000045, acc.: 100.00%] [G loss: 3.236453]\n",
      "[[[ 0.2842079 ]\n",
      "  [-0.7523529 ]\n",
      "  [-0.7022586 ]\n",
      "  ...\n",
      "  [-0.44939023]\n",
      "  [-0.39982712]\n",
      "  [-0.36488405]]\n",
      "\n",
      " [[ 0.21718968]\n",
      "  [ 0.5263958 ]\n",
      "  [-0.37452015]\n",
      "  ...\n",
      "  [ 0.49912044]\n",
      "  [-0.3440865 ]\n",
      "  [-0.6611692 ]]\n",
      "\n",
      " [[-0.69141716]\n",
      "  [ 0.8862481 ]\n",
      "  [-0.7070848 ]\n",
      "  ...\n",
      "  [-0.64996696]\n",
      "  [ 0.25860465]\n",
      "  [-0.05791217]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.14049225]\n",
      "  [ 0.5073592 ]\n",
      "  [-0.6954615 ]\n",
      "  ...\n",
      "  [-0.7180846 ]\n",
      "  [-0.7332653 ]\n",
      "  [-0.38241675]]\n",
      "\n",
      " [[ 0.78692186]\n",
      "  [-0.84112686]\n",
      "  [-0.7356094 ]\n",
      "  ...\n",
      "  [ 0.6297155 ]\n",
      "  [-0.87640226]\n",
      "  [-0.35818285]]\n",
      "\n",
      " [[-0.78321314]\n",
      "  [ 0.40524548]\n",
      "  [-0.3954742 ]\n",
      "  ...\n",
      "  [ 0.11404274]\n",
      "  [-0.19353689]\n",
      "  [-0.58079433]]]\n",
      "601 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.211758]\n",
      "602 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.214855]\n",
      "603 [D loss: 0.000041, acc.: 100.00%] [G loss: 3.215127]\n",
      "604 [D loss: 0.000048, acc.: 100.00%] [G loss: 3.214240]\n",
      "605 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.209258]\n",
      "606 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.213703]\n",
      "607 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.202641]\n",
      "608 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.226621]\n",
      "609 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.231292]\n",
      "610 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.227664]\n",
      "611 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.213497]\n",
      "612 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.207559]\n",
      "613 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.212774]\n",
      "614 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.209188]\n",
      "615 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.205097]\n",
      "616 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.212722]\n",
      "617 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.205710]\n",
      "618 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.215099]\n",
      "619 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.205894]\n",
      "620 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.223859]\n",
      "621 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.211332]\n",
      "622 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.216776]\n",
      "623 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.221281]\n",
      "624 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.222113]\n",
      "625 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.194345]\n",
      "626 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.210901]\n",
      "627 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.207258]\n",
      "628 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.206455]\n",
      "629 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.195480]\n",
      "630 [D loss: 0.000043, acc.: 100.00%] [G loss: 3.206641]\n",
      "631 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.215686]\n",
      "632 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.209898]\n",
      "633 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.204861]\n",
      "634 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.212592]\n",
      "635 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.208977]\n",
      "636 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.196865]\n",
      "637 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.200435]\n",
      "638 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.190065]\n",
      "639 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.195745]\n",
      "640 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.207808]\n",
      "641 [D loss: 0.000058, acc.: 100.00%] [G loss: 3.187069]\n",
      "642 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.199767]\n",
      "643 [D loss: 0.000037, acc.: 100.00%] [G loss: 3.205515]\n",
      "644 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.204420]\n",
      "645 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.207187]\n",
      "646 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.199681]\n",
      "647 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.190648]\n",
      "648 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.191316]\n",
      "649 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.200574]\n",
      "650 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.180987]\n",
      "651 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.200886]\n",
      "652 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.189729]\n",
      "653 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.206894]\n",
      "654 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.198726]\n",
      "655 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.199917]\n",
      "656 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.194859]\n",
      "657 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.183675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.204480]\n",
      "659 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.200030]\n",
      "660 [D loss: 0.000058, acc.: 100.00%] [G loss: 3.195338]\n",
      "661 [D loss: 0.000146, acc.: 100.00%] [G loss: 3.200634]\n",
      "662 [D loss: 0.000063, acc.: 100.00%] [G loss: 3.212523]\n",
      "663 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.222265]\n",
      "664 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.210652]\n",
      "665 [D loss: 0.000043, acc.: 100.00%] [G loss: 3.214430]\n",
      "666 [D loss: 0.000086, acc.: 100.00%] [G loss: 3.208889]\n",
      "667 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.213501]\n",
      "668 [D loss: 0.000065, acc.: 100.00%] [G loss: 3.209286]\n",
      "669 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.192136]\n",
      "670 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.195311]\n",
      "671 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.187983]\n",
      "672 [D loss: 0.000134, acc.: 100.00%] [G loss: 3.190061]\n",
      "673 [D loss: 0.000033, acc.: 100.00%] [G loss: 3.216706]\n",
      "674 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.200232]\n",
      "675 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.204081]\n",
      "676 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.194943]\n",
      "677 [D loss: 0.000042, acc.: 100.00%] [G loss: 3.191800]\n",
      "678 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.216528]\n",
      "679 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.176965]\n",
      "680 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.177468]\n",
      "681 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.180925]\n",
      "682 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.193634]\n",
      "683 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.188666]\n",
      "684 [D loss: 0.000075, acc.: 100.00%] [G loss: 3.177000]\n",
      "685 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.171655]\n",
      "686 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.188490]\n",
      "687 [D loss: 0.000058, acc.: 100.00%] [G loss: 3.195267]\n",
      "688 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.189138]\n",
      "689 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.169437]\n",
      "690 [D loss: 0.000038, acc.: 100.00%] [G loss: 3.175374]\n",
      "691 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.175426]\n",
      "692 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.183832]\n",
      "693 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.171351]\n",
      "694 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.172128]\n",
      "695 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.173398]\n",
      "696 [D loss: 0.000033, acc.: 100.00%] [G loss: 3.178669]\n",
      "697 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.181664]\n",
      "698 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.166642]\n",
      "699 [D loss: 0.000035, acc.: 100.00%] [G loss: 3.199072]\n",
      "700 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.173066]\n",
      "[[[ 0.39714777]\n",
      "  [-0.74879825]\n",
      "  [-0.15501945]\n",
      "  ...\n",
      "  [-0.5525539 ]\n",
      "  [-0.8602091 ]\n",
      "  [-0.31497443]]\n",
      "\n",
      " [[ 0.9672837 ]\n",
      "  [ 0.89703006]\n",
      "  [-0.2436615 ]\n",
      "  ...\n",
      "  [ 0.640671  ]\n",
      "  [-0.9239573 ]\n",
      "  [-0.35820165]]\n",
      "\n",
      " [[ 0.9712255 ]\n",
      "  [ 0.9950463 ]\n",
      "  [ 0.91883016]\n",
      "  ...\n",
      "  [ 0.68319213]\n",
      "  [ 0.7933946 ]\n",
      "  [-0.87705916]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.9431109 ]\n",
      "  [-0.18127377]\n",
      "  [-0.5653049 ]\n",
      "  ...\n",
      "  [ 0.10372122]\n",
      "  [ 0.5510082 ]\n",
      "  [-0.84370136]]\n",
      "\n",
      " [[-0.819391  ]\n",
      "  [-0.6546712 ]\n",
      "  [-0.19648229]\n",
      "  ...\n",
      "  [ 0.2871983 ]\n",
      "  [-0.25892958]\n",
      "  [ 0.48950192]]\n",
      "\n",
      " [[-0.74226105]\n",
      "  [-0.55164397]\n",
      "  [-0.5217199 ]\n",
      "  ...\n",
      "  [-0.2647193 ]\n",
      "  [-0.4176541 ]\n",
      "  [-0.3404375 ]]]\n",
      "701 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.165008]\n",
      "702 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.180481]\n",
      "703 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.177371]\n",
      "704 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.186072]\n",
      "705 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.182482]\n",
      "706 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.167568]\n",
      "707 [D loss: 0.000038, acc.: 100.00%] [G loss: 3.166390]\n",
      "708 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.170912]\n",
      "709 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.166450]\n",
      "710 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.163508]\n",
      "711 [D loss: 0.000047, acc.: 100.00%] [G loss: 3.168154]\n",
      "712 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.159736]\n",
      "713 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.176594]\n",
      "714 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.163229]\n",
      "715 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.161324]\n",
      "716 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.154749]\n",
      "717 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.169037]\n",
      "718 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.147359]\n",
      "719 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.169702]\n",
      "720 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.167078]\n",
      "721 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.160522]\n",
      "722 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.167457]\n",
      "723 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.158364]\n",
      "724 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.181202]\n",
      "725 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.176863]\n",
      "726 [D loss: 0.000065, acc.: 100.00%] [G loss: 3.168357]\n",
      "727 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.179728]\n",
      "728 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.176840]\n",
      "729 [D loss: 0.000050, acc.: 100.00%] [G loss: 3.168321]\n",
      "730 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.180747]\n",
      "731 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.189246]\n",
      "732 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.156965]\n",
      "733 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.175589]\n",
      "734 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.177727]\n",
      "735 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.173456]\n",
      "736 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.168123]\n",
      "737 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.177954]\n",
      "738 [D loss: 0.000074, acc.: 100.00%] [G loss: 3.175830]\n",
      "739 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.162279]\n",
      "740 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.169086]\n",
      "741 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.162226]\n",
      "742 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.162979]\n",
      "743 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.171713]\n",
      "744 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.170537]\n",
      "745 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.172850]\n",
      "746 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.165102]\n",
      "747 [D loss: 0.000107, acc.: 100.00%] [G loss: 3.162616]\n",
      "748 [D loss: 0.000033, acc.: 100.00%] [G loss: 3.163803]\n",
      "749 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.170171]\n",
      "750 [D loss: 0.000047, acc.: 100.00%] [G loss: 3.171971]\n",
      "751 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.148107]\n",
      "752 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.164117]\n",
      "753 [D loss: 0.000166, acc.: 100.00%] [G loss: 3.154609]\n",
      "754 [D loss: 0.000033, acc.: 100.00%] [G loss: 3.179235]\n",
      "755 [D loss: 0.000049, acc.: 100.00%] [G loss: 3.167275]\n",
      "756 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.170777]\n",
      "757 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.182518]\n",
      "758 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.163803]\n",
      "759 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.171059]\n",
      "760 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.176469]\n",
      "761 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.175377]\n",
      "762 [D loss: 0.000090, acc.: 100.00%] [G loss: 3.184085]\n",
      "763 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.186633]\n",
      "764 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.164999]\n",
      "765 [D loss: 0.000073, acc.: 100.00%] [G loss: 3.182391]\n",
      "766 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.183617]\n",
      "767 [D loss: 0.000037, acc.: 100.00%] [G loss: 3.157983]\n",
      "768 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.171839]\n",
      "769 [D loss: 0.000033, acc.: 100.00%] [G loss: 3.174031]\n",
      "770 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.167408]\n",
      "771 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.165382]\n",
      "772 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.152326]\n",
      "773 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.164569]\n",
      "774 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.162097]\n",
      "775 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.154795]\n",
      "776 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.160268]\n",
      "777 [D loss: 0.000061, acc.: 100.00%] [G loss: 3.167832]\n",
      "778 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.175701]\n",
      "779 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.164809]\n",
      "780 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.156034]\n",
      "781 [D loss: 0.000035, acc.: 100.00%] [G loss: 3.151754]\n",
      "782 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.145746]\n",
      "783 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.167472]\n",
      "784 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.156133]\n",
      "785 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.161401]\n",
      "786 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.167841]\n",
      "787 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.154498]\n",
      "788 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.172573]\n",
      "789 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.161778]\n",
      "790 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.160672]\n",
      "791 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.168520]\n",
      "792 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.163033]\n",
      "793 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.149858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.156358]\n",
      "795 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.157891]\n",
      "796 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.156502]\n",
      "797 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.151485]\n",
      "798 [D loss: 0.000039, acc.: 100.00%] [G loss: 3.162773]\n",
      "799 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.148334]\n",
      "800 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.155560]\n",
      "[[[-0.14688358]\n",
      "  [-0.73596025]\n",
      "  [-0.7489184 ]\n",
      "  ...\n",
      "  [-0.32392952]\n",
      "  [-0.5849371 ]\n",
      "  [-0.63373077]]\n",
      "\n",
      " [[ 0.49766058]\n",
      "  [-0.6425408 ]\n",
      "  [-0.6809534 ]\n",
      "  ...\n",
      "  [ 0.6937896 ]\n",
      "  [-0.9129556 ]\n",
      "  [-0.34902516]]\n",
      "\n",
      " [[ 0.22692114]\n",
      "  [ 0.97998494]\n",
      "  [-0.7625967 ]\n",
      "  ...\n",
      "  [-0.5062378 ]\n",
      "  [ 0.372636  ]\n",
      "  [-0.5384592 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.61785877]\n",
      "  [-0.2583454 ]\n",
      "  [-0.57202023]\n",
      "  ...\n",
      "  [-0.84618104]\n",
      "  [-0.3495567 ]\n",
      "  [-0.21863772]]\n",
      "\n",
      " [[-0.93108195]\n",
      "  [ 0.8268447 ]\n",
      "  [-0.5419325 ]\n",
      "  ...\n",
      "  [ 0.34060365]\n",
      "  [-0.43654695]\n",
      "  [-0.83336437]]\n",
      "\n",
      " [[-0.8890758 ]\n",
      "  [-0.03476597]\n",
      "  [-0.48670948]\n",
      "  ...\n",
      "  [-0.48788512]\n",
      "  [-0.64949346]\n",
      "  [-0.41944727]]]\n",
      "801 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.150995]\n",
      "802 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.146639]\n",
      "803 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.154707]\n",
      "804 [D loss: 0.000047, acc.: 100.00%] [G loss: 3.173747]\n",
      "805 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.155114]\n",
      "806 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.177289]\n",
      "807 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.151388]\n",
      "808 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.146963]\n",
      "809 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.160206]\n",
      "810 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.148354]\n",
      "811 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.161362]\n",
      "812 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.151717]\n",
      "813 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.162181]\n",
      "814 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.168768]\n",
      "815 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.147057]\n",
      "816 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.154094]\n",
      "817 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.142012]\n",
      "818 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.147058]\n",
      "819 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.154553]\n",
      "820 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.145577]\n",
      "821 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.152245]\n",
      "822 [D loss: 0.000037, acc.: 100.00%] [G loss: 3.145557]\n",
      "823 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.156222]\n",
      "824 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.137020]\n",
      "825 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.145649]\n",
      "826 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.132768]\n",
      "827 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.143801]\n",
      "828 [D loss: 0.000041, acc.: 100.00%] [G loss: 3.150215]\n",
      "829 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.132169]\n",
      "830 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.152121]\n",
      "831 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.145018]\n",
      "832 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.150905]\n",
      "833 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.134758]\n",
      "834 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.129515]\n",
      "835 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.149558]\n",
      "836 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.148788]\n",
      "837 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.142253]\n",
      "838 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.137938]\n",
      "839 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.153370]\n",
      "840 [D loss: 0.000078, acc.: 100.00%] [G loss: 3.143810]\n",
      "841 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.154057]\n",
      "842 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.152369]\n",
      "843 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.128800]\n",
      "844 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.156543]\n",
      "845 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.152595]\n",
      "846 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.153915]\n",
      "847 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.167032]\n",
      "848 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.148448]\n",
      "849 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.148862]\n",
      "850 [D loss: 0.000105, acc.: 100.00%] [G loss: 3.159634]\n",
      "851 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.165871]\n",
      "852 [D loss: 0.000039, acc.: 100.00%] [G loss: 3.165499]\n",
      "853 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.171730]\n",
      "854 [D loss: 0.000039, acc.: 100.00%] [G loss: 3.165833]\n",
      "855 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.150661]\n",
      "856 [D loss: 0.000146, acc.: 100.00%] [G loss: 3.164462]\n",
      "857 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.159351]\n",
      "858 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.157322]\n",
      "859 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.140242]\n",
      "860 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.150578]\n",
      "861 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.152158]\n",
      "862 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.135911]\n",
      "863 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.123326]\n",
      "864 [D loss: 0.000094, acc.: 100.00%] [G loss: 3.130828]\n",
      "865 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.134878]\n",
      "866 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.137023]\n",
      "867 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.139350]\n",
      "868 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.136927]\n",
      "869 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.136886]\n",
      "870 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.129466]\n",
      "871 [D loss: 0.000065, acc.: 100.00%] [G loss: 3.132741]\n",
      "872 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.142385]\n",
      "873 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.148812]\n",
      "874 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.151212]\n",
      "875 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.144180]\n",
      "876 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.140542]\n",
      "877 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.139467]\n",
      "878 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.142398]\n",
      "879 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.158989]\n",
      "880 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.139339]\n",
      "881 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.131785]\n",
      "882 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.153121]\n",
      "883 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.140806]\n",
      "884 [D loss: 0.000091, acc.: 100.00%] [G loss: 3.158635]\n",
      "885 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.162612]\n",
      "886 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.146700]\n",
      "887 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.148565]\n",
      "888 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.159326]\n",
      "889 [D loss: 0.000048, acc.: 100.00%] [G loss: 3.171820]\n",
      "890 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.139397]\n",
      "891 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.147568]\n",
      "892 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.161785]\n",
      "893 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.149126]\n",
      "894 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.142373]\n",
      "895 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.155551]\n",
      "896 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.156909]\n",
      "897 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.141248]\n",
      "898 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.150800]\n",
      "899 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.154962]\n",
      "900 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.152360]\n",
      "[[[-0.94595665]\n",
      "  [-0.41226676]\n",
      "  [-0.7620573 ]\n",
      "  ...\n",
      "  [-0.69236684]\n",
      "  [-0.34790233]\n",
      "  [-0.8678161 ]]\n",
      "\n",
      " [[-0.24750733]\n",
      "  [-0.08480161]\n",
      "  [-0.3730101 ]\n",
      "  ...\n",
      "  [ 0.10332578]\n",
      "  [-0.95233124]\n",
      "  [ 0.6767323 ]]\n",
      "\n",
      " [[ 0.40852258]\n",
      "  [-0.558967  ]\n",
      "  [-0.22392406]\n",
      "  ...\n",
      "  [ 0.36149254]\n",
      "  [ 0.60077167]\n",
      "  [-0.29923403]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.73198295]\n",
      "  [ 0.9747069 ]\n",
      "  [ 0.50993305]\n",
      "  ...\n",
      "  [-0.7974172 ]\n",
      "  [-0.2285025 ]\n",
      "  [-0.35294372]]\n",
      "\n",
      " [[ 0.23255251]\n",
      "  [ 0.9891384 ]\n",
      "  [ 0.18777132]\n",
      "  ...\n",
      "  [-0.29004374]\n",
      "  [-0.53104436]\n",
      "  [-0.18775555]]\n",
      "\n",
      " [[-0.43926144]\n",
      "  [ 0.94311905]\n",
      "  [-0.3180223 ]\n",
      "  ...\n",
      "  [ 0.4051847 ]\n",
      "  [-0.69271994]\n",
      "  [-0.7967708 ]]]\n",
      "901 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.140547]\n",
      "902 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.140229]\n",
      "903 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.153892]\n",
      "904 [D loss: 0.000045, acc.: 100.00%] [G loss: 3.149779]\n",
      "905 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.149324]\n",
      "906 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.138860]\n",
      "907 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.134730]\n",
      "908 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.138187]\n",
      "909 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.148318]\n",
      "910 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.153595]\n",
      "911 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.137391]\n",
      "912 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.147245]\n",
      "913 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.157604]\n",
      "914 [D loss: 0.000120, acc.: 100.00%] [G loss: 3.146976]\n",
      "915 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.150888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.157543]\n",
      "917 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.155945]\n",
      "918 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.152984]\n",
      "919 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.155576]\n",
      "920 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.178913]\n",
      "921 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.159878]\n",
      "922 [D loss: 0.000037, acc.: 100.00%] [G loss: 3.165024]\n",
      "923 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.145044]\n",
      "924 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.162171]\n",
      "925 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.145928]\n",
      "926 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.165125]\n",
      "927 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.160962]\n",
      "928 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.153174]\n",
      "929 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.138626]\n",
      "930 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.144153]\n",
      "931 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.151272]\n",
      "932 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.144731]\n",
      "933 [D loss: 0.000049, acc.: 100.00%] [G loss: 3.147757]\n",
      "934 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.146593]\n",
      "935 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.157495]\n",
      "936 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.144530]\n",
      "937 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.152637]\n",
      "938 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.140340]\n",
      "939 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.151504]\n",
      "940 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.148134]\n",
      "941 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.149167]\n",
      "942 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.147391]\n",
      "943 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.148216]\n",
      "944 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.147501]\n",
      "945 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.138391]\n",
      "946 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.160742]\n",
      "947 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.157305]\n",
      "948 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.146757]\n",
      "949 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.155798]\n",
      "950 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.141531]\n",
      "951 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.148759]\n",
      "952 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.142668]\n",
      "953 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.150064]\n",
      "954 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.148634]\n",
      "955 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.166093]\n",
      "956 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.153001]\n",
      "957 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.142541]\n",
      "958 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.140145]\n",
      "959 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.154812]\n",
      "960 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.141063]\n",
      "961 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.134676]\n",
      "962 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.143434]\n",
      "963 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.149020]\n",
      "964 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.129737]\n",
      "965 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.129724]\n",
      "966 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.143735]\n",
      "967 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.144871]\n",
      "968 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.141810]\n",
      "969 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.139052]\n",
      "970 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.139812]\n",
      "971 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.148569]\n",
      "972 [D loss: 0.000056, acc.: 100.00%] [G loss: 3.146243]\n",
      "973 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.142149]\n",
      "974 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.142488]\n",
      "975 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.150056]\n",
      "976 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.159069]\n",
      "977 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.153699]\n",
      "978 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.149539]\n",
      "979 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.148788]\n",
      "980 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.156193]\n",
      "981 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.150679]\n",
      "982 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.151053]\n",
      "983 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.138703]\n",
      "984 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.152481]\n",
      "985 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.149580]\n",
      "986 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.143370]\n",
      "987 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.142807]\n",
      "988 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.144749]\n",
      "989 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.143621]\n",
      "990 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.142032]\n",
      "991 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.137367]\n",
      "992 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.140142]\n",
      "993 [D loss: 0.000044, acc.: 100.00%] [G loss: 3.130301]\n",
      "994 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.146599]\n",
      "995 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.140427]\n",
      "996 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.158575]\n",
      "997 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.146611]\n",
      "998 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.141167]\n",
      "999 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.146055]\n",
      "1000 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.148606]\n",
      "[[[-0.6676798 ]\n",
      "  [-0.69830585]\n",
      "  [-0.84727484]\n",
      "  ...\n",
      "  [-0.79812133]\n",
      "  [-0.8206774 ]\n",
      "  [-0.40310925]]\n",
      "\n",
      " [[-0.02946315]\n",
      "  [ 0.17014909]\n",
      "  [-0.96024543]\n",
      "  ...\n",
      "  [ 0.12999068]\n",
      "  [-0.5809295 ]\n",
      "  [ 0.19504397]]\n",
      "\n",
      " [[ 0.74755347]\n",
      "  [ 0.91007125]\n",
      "  [-0.8233763 ]\n",
      "  ...\n",
      "  [ 0.19804211]\n",
      "  [ 0.542657  ]\n",
      "  [-0.8531087 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.21751341]\n",
      "  [ 0.9391283 ]\n",
      "  [ 0.23530506]\n",
      "  ...\n",
      "  [-0.8050196 ]\n",
      "  [ 0.12312946]\n",
      "  [ 0.16087058]]\n",
      "\n",
      " [[-0.01926376]\n",
      "  [ 0.50443137]\n",
      "  [ 0.7624176 ]\n",
      "  ...\n",
      "  [-0.7016084 ]\n",
      "  [-0.541832  ]\n",
      "  [ 0.07133629]]\n",
      "\n",
      " [[-0.8899553 ]\n",
      "  [ 0.4358329 ]\n",
      "  [ 0.03504899]\n",
      "  ...\n",
      "  [-0.65187615]\n",
      "  [-0.58045596]\n",
      "  [-0.52861774]]]\n",
      "1001 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.139643]\n",
      "1002 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.161670]\n",
      "1003 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.154308]\n",
      "1004 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.140983]\n",
      "1005 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.160756]\n",
      "1006 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.150272]\n",
      "1007 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.149182]\n",
      "1008 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.166565]\n",
      "1009 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.147546]\n",
      "1010 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.150207]\n",
      "1011 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.143455]\n",
      "1012 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.147883]\n",
      "1013 [D loss: 0.000048, acc.: 100.00%] [G loss: 3.157031]\n",
      "1014 [D loss: 0.000035, acc.: 100.00%] [G loss: 3.157132]\n",
      "1015 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.162402]\n",
      "1016 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.174666]\n",
      "1017 [D loss: 0.000067, acc.: 100.00%] [G loss: 3.163638]\n",
      "1018 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.166172]\n",
      "1019 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.166784]\n",
      "1020 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.167846]\n",
      "1021 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.175581]\n",
      "1022 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.162504]\n",
      "1023 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.178431]\n",
      "1024 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.168629]\n",
      "1025 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.159555]\n",
      "1026 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.159370]\n",
      "1027 [D loss: 0.000036, acc.: 100.00%] [G loss: 3.175565]\n",
      "1028 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.172009]\n",
      "1029 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.162021]\n",
      "1030 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.155513]\n",
      "1031 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.146907]\n",
      "1032 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.152820]\n",
      "1033 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.163848]\n",
      "1034 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.153746]\n",
      "1035 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.156380]\n",
      "1036 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.178781]\n",
      "1037 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.166705]\n",
      "1038 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.174411]\n",
      "1039 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.180128]\n",
      "1040 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.172947]\n",
      "1041 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.159369]\n",
      "1042 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.157500]\n",
      "1043 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.170201]\n",
      "1044 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.160674]\n",
      "1045 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.153865]\n",
      "1046 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.159432]\n",
      "1047 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.152721]\n",
      "1048 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.165385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049 [D loss: 0.000033, acc.: 100.00%] [G loss: 3.153648]\n",
      "1050 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.151046]\n",
      "1051 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.162477]\n",
      "1052 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.152202]\n",
      "1053 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.163572]\n",
      "1054 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.161775]\n",
      "1055 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.145934]\n",
      "1056 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.159358]\n",
      "1057 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.166299]\n",
      "1058 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.161280]\n",
      "1059 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.155597]\n",
      "1060 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.171045]\n",
      "1061 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.169100]\n",
      "1062 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.170015]\n",
      "1063 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.159754]\n",
      "1064 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.184081]\n",
      "1065 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.164266]\n",
      "1066 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.171277]\n",
      "1067 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.178334]\n",
      "1068 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.182511]\n",
      "1069 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.172471]\n",
      "1070 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.173501]\n",
      "1071 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.165238]\n",
      "1072 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.162585]\n",
      "1073 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.160618]\n",
      "1074 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.176730]\n",
      "1075 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.166483]\n",
      "1076 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.158315]\n",
      "1077 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.165341]\n",
      "1078 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.172199]\n",
      "1079 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.168922]\n",
      "1080 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.156649]\n",
      "1081 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.162175]\n",
      "1082 [D loss: 0.000028, acc.: 100.00%] [G loss: 3.163517]\n",
      "1083 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.182275]\n",
      "1084 [D loss: 0.000026, acc.: 100.00%] [G loss: 3.170298]\n",
      "1085 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.170284]\n",
      "1086 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.155718]\n",
      "1087 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.169703]\n",
      "1088 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.170440]\n",
      "1089 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.169724]\n",
      "1090 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.171337]\n",
      "1091 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.163209]\n",
      "1092 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.150043]\n",
      "1093 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.186086]\n",
      "1094 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.169592]\n",
      "1095 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.179691]\n",
      "1096 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.162491]\n",
      "1097 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.170081]\n",
      "1098 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.172051]\n",
      "1099 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.162877]\n",
      "1100 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.153250]\n",
      "[[[-0.7326265 ]\n",
      "  [-0.76277536]\n",
      "  [-0.86531794]\n",
      "  ...\n",
      "  [-0.32276538]\n",
      "  [-0.80688757]\n",
      "  [-0.6761963 ]]\n",
      "\n",
      " [[-0.5674508 ]\n",
      "  [-0.3128186 ]\n",
      "  [-0.9357401 ]\n",
      "  ...\n",
      "  [-0.05738503]\n",
      "  [-0.8351984 ]\n",
      "  [-0.06130591]]\n",
      "\n",
      " [[ 0.12753837]\n",
      "  [-0.52037966]\n",
      "  [ 0.01279553]\n",
      "  ...\n",
      "  [-0.46909577]\n",
      "  [ 0.54429615]\n",
      "  [-0.915538  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.28771845]\n",
      "  [-0.6864732 ]\n",
      "  [ 0.24233177]\n",
      "  ...\n",
      "  [ 0.8791692 ]\n",
      "  [-0.7242042 ]\n",
      "  [-0.7298039 ]]\n",
      "\n",
      " [[-0.85257137]\n",
      "  [ 0.6406604 ]\n",
      "  [ 0.08154251]\n",
      "  ...\n",
      "  [ 0.596438  ]\n",
      "  [ 0.8484327 ]\n",
      "  [-0.75505733]]\n",
      "\n",
      " [[-0.78924274]\n",
      "  [ 0.23433346]\n",
      "  [ 0.03135906]\n",
      "  ...\n",
      "  [-0.6439597 ]\n",
      "  [-0.50128484]\n",
      "  [ 0.694022  ]]]\n",
      "1101 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.162963]\n",
      "1102 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.151981]\n",
      "1103 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.156935]\n",
      "1104 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.165933]\n",
      "1105 [D loss: 0.000045, acc.: 100.00%] [G loss: 3.182672]\n",
      "1106 [D loss: 0.000035, acc.: 100.00%] [G loss: 3.171503]\n",
      "1107 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.152966]\n",
      "1108 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.154925]\n",
      "1109 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.147201]\n",
      "1110 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.153392]\n",
      "1111 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.156084]\n",
      "1112 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.157604]\n",
      "1113 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.159880]\n",
      "1114 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.168008]\n",
      "1115 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.148591]\n",
      "1116 [D loss: 0.000047, acc.: 100.00%] [G loss: 3.162369]\n",
      "1117 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.167265]\n",
      "1118 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.156476]\n",
      "1119 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.163384]\n",
      "1120 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.159292]\n",
      "1121 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.155248]\n",
      "1122 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.156597]\n",
      "1123 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.155141]\n",
      "1124 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.154198]\n",
      "1125 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.158986]\n",
      "1126 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.151242]\n",
      "1127 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.150506]\n",
      "1128 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.154813]\n",
      "1129 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.149839]\n",
      "1130 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.150061]\n",
      "1131 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.175929]\n",
      "1132 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.156122]\n",
      "1133 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.169259]\n",
      "1134 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.181461]\n",
      "1135 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.157646]\n",
      "1136 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.180889]\n",
      "1137 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.180732]\n",
      "1138 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.188416]\n",
      "1139 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.169550]\n",
      "1140 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.173564]\n",
      "1141 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.179853]\n",
      "1142 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.159410]\n",
      "1143 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.165123]\n",
      "1144 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.165802]\n",
      "1145 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.160582]\n",
      "1146 [D loss: 0.000035, acc.: 100.00%] [G loss: 3.179943]\n",
      "1147 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.165406]\n",
      "1148 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182841]\n",
      "1149 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.163493]\n",
      "1150 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.161889]\n",
      "1151 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.166929]\n",
      "1152 [D loss: 0.000034, acc.: 100.00%] [G loss: 3.177692]\n",
      "1153 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.164808]\n",
      "1154 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.168839]\n",
      "1155 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.155697]\n",
      "1156 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.158362]\n",
      "1157 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.165833]\n",
      "1158 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.164985]\n",
      "1159 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.161257]\n",
      "1160 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.165753]\n",
      "1161 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.170112]\n",
      "1162 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.173087]\n",
      "1163 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.168937]\n",
      "1164 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.178358]\n",
      "1165 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.170076]\n",
      "1166 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.160827]\n",
      "1167 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.174203]\n",
      "1168 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.164443]\n",
      "1169 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.158589]\n",
      "1170 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.166949]\n",
      "1171 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.168523]\n",
      "1172 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.180084]\n",
      "1173 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.164734]\n",
      "1174 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.170290]\n",
      "1175 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.175411]\n",
      "1176 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.167041]\n",
      "1177 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.156376]\n",
      "1178 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.147032]\n",
      "1179 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.183369]\n",
      "1180 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.181790]\n",
      "1181 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.172249]\n",
      "1182 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.163445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183 [D loss: 0.000044, acc.: 100.00%] [G loss: 3.180812]\n",
      "1184 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.169158]\n",
      "1185 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.183761]\n",
      "1186 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.176032]\n",
      "1187 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.158469]\n",
      "1188 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.173127]\n",
      "1189 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.155180]\n",
      "1190 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.176472]\n",
      "1191 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.170912]\n",
      "1192 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.175733]\n",
      "1193 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.179038]\n",
      "1194 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.169150]\n",
      "1195 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.176657]\n",
      "1196 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.167656]\n",
      "1197 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.166857]\n",
      "1198 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.159703]\n",
      "1199 [D loss: 0.000030, acc.: 100.00%] [G loss: 3.178270]\n",
      "1200 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.186191]\n",
      "[[[-0.35487008]\n",
      "  [-0.5980103 ]\n",
      "  [-0.5788744 ]\n",
      "  ...\n",
      "  [-0.13437414]\n",
      "  [ 0.09672133]\n",
      "  [-0.90667576]]\n",
      "\n",
      " [[ 0.52101797]\n",
      "  [-0.6998032 ]\n",
      "  [-0.84429884]\n",
      "  ...\n",
      "  [ 0.8419088 ]\n",
      "  [-0.8118582 ]\n",
      "  [ 0.85267806]]\n",
      "\n",
      " [[-0.7314013 ]\n",
      "  [ 0.9203297 ]\n",
      "  [-0.964609  ]\n",
      "  ...\n",
      "  [-0.77260923]\n",
      "  [ 0.94288313]\n",
      "  [-0.39852116]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.69882977]\n",
      "  [ 0.77189094]\n",
      "  [-0.7757516 ]\n",
      "  ...\n",
      "  [-0.9315046 ]\n",
      "  [-0.41492727]\n",
      "  [ 0.53373265]]\n",
      "\n",
      " [[ 0.36608773]\n",
      "  [ 0.3346224 ]\n",
      "  [ 0.28811565]\n",
      "  ...\n",
      "  [-0.8937386 ]\n",
      "  [-0.22000858]\n",
      "  [ 0.04777385]]\n",
      "\n",
      " [[-0.29593495]\n",
      "  [ 0.00790785]\n",
      "  [-0.69428575]\n",
      "  ...\n",
      "  [ 0.15614356]\n",
      "  [-0.7418387 ]\n",
      "  [-0.44379628]]]\n",
      "1201 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.190560]\n",
      "1202 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.163033]\n",
      "1203 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.162425]\n",
      "1204 [D loss: 0.000053, acc.: 100.00%] [G loss: 3.183615]\n",
      "1205 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.194243]\n",
      "1206 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.181321]\n",
      "1207 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.182619]\n",
      "1208 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.190427]\n",
      "1209 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.191913]\n",
      "1210 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.193387]\n",
      "1211 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.212659]\n",
      "1212 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.192203]\n",
      "1213 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.193130]\n",
      "1214 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.199465]\n",
      "1215 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.176489]\n",
      "1216 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.194486]\n",
      "1217 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.170961]\n",
      "1218 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.188522]\n",
      "1219 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.169485]\n",
      "1220 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.172736]\n",
      "1221 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.167593]\n",
      "1222 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.177085]\n",
      "1223 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.168979]\n",
      "1224 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.163229]\n",
      "1225 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.169844]\n",
      "1226 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.169835]\n",
      "1227 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.182405]\n",
      "1228 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.155396]\n",
      "1229 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.173560]\n",
      "1230 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.157081]\n",
      "1231 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.176993]\n",
      "1232 [D loss: 0.000032, acc.: 100.00%] [G loss: 3.185426]\n",
      "1233 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.185344]\n",
      "1234 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.171653]\n",
      "1235 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.164544]\n",
      "1236 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.156362]\n",
      "1237 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.177948]\n",
      "1238 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.182288]\n",
      "1239 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.177613]\n",
      "1240 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.180427]\n",
      "1241 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.180579]\n",
      "1242 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.184134]\n",
      "1243 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.185130]\n",
      "1244 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.194878]\n",
      "1245 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.199087]\n",
      "1246 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.210494]\n",
      "1247 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.189925]\n",
      "1248 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.188811]\n",
      "1249 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.188931]\n",
      "1250 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.189720]\n",
      "1251 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.175775]\n",
      "1252 [D loss: 0.000044, acc.: 100.00%] [G loss: 3.193079]\n",
      "1253 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.168013]\n",
      "1254 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.181026]\n",
      "1255 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.198241]\n",
      "1256 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.184487]\n",
      "1257 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.169943]\n",
      "1258 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.191696]\n",
      "1259 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.175355]\n",
      "1260 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.181948]\n",
      "1261 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.177872]\n",
      "1262 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.175367]\n",
      "1263 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.165254]\n",
      "1264 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.173633]\n",
      "1265 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.176346]\n",
      "1266 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.165003]\n",
      "1267 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.157962]\n",
      "1268 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.179461]\n",
      "1269 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.165862]\n",
      "1270 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.157044]\n",
      "1271 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.159578]\n",
      "1272 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.154112]\n",
      "1273 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.160714]\n",
      "1274 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.163501]\n",
      "1275 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.166651]\n",
      "1276 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.171174]\n",
      "1277 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.162259]\n",
      "1278 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.174878]\n",
      "1279 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.174760]\n",
      "1280 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.179811]\n",
      "1281 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.152456]\n",
      "1282 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.166611]\n",
      "1283 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.158788]\n",
      "1284 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.176339]\n",
      "1285 [D loss: 0.000043, acc.: 100.00%] [G loss: 3.177121]\n",
      "1286 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.184610]\n",
      "1287 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.180617]\n",
      "1288 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.167717]\n",
      "1289 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.190509]\n",
      "1290 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.186602]\n",
      "1291 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.175014]\n",
      "1292 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.168788]\n",
      "1293 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.175185]\n",
      "1294 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.168981]\n",
      "1295 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.163137]\n",
      "1296 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.159565]\n",
      "1297 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.163634]\n",
      "1298 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.181430]\n",
      "1299 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.189325]\n",
      "1300 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.180702]\n",
      "[[[-0.71072465]\n",
      "  [-0.24692816]\n",
      "  [-0.90354073]\n",
      "  ...\n",
      "  [-0.8756469 ]\n",
      "  [-0.91441286]\n",
      "  [-0.26371375]]\n",
      "\n",
      " [[ 0.8074794 ]\n",
      "  [-0.9115041 ]\n",
      "  [ 0.18179451]\n",
      "  ...\n",
      "  [ 0.5830734 ]\n",
      "  [-0.9301994 ]\n",
      "  [-0.7764326 ]]\n",
      "\n",
      " [[-0.37829003]\n",
      "  [-0.48468181]\n",
      "  [-0.7875513 ]\n",
      "  ...\n",
      "  [ 0.3681867 ]\n",
      "  [-0.01541158]\n",
      "  [-0.9227689 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.4572171 ]\n",
      "  [ 0.9766053 ]\n",
      "  [-0.9651001 ]\n",
      "  ...\n",
      "  [ 0.7794409 ]\n",
      "  [-0.8118051 ]\n",
      "  [-0.14340104]]\n",
      "\n",
      " [[ 0.75592107]\n",
      "  [ 0.13054419]\n",
      "  [-0.671203  ]\n",
      "  ...\n",
      "  [ 0.8249565 ]\n",
      "  [-0.89277196]\n",
      "  [-0.4072552 ]]\n",
      "\n",
      " [[-0.709779  ]\n",
      "  [ 0.35400477]\n",
      "  [-0.6746681 ]\n",
      "  ...\n",
      "  [-0.75475526]\n",
      "  [ 0.6581478 ]\n",
      "  [-0.65009737]]]\n",
      "1301 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.172054]\n",
      "1302 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.191798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1303 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.170893]\n",
      "1304 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.168294]\n",
      "1305 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.174264]\n",
      "1306 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.187380]\n",
      "1307 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.185984]\n",
      "1308 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.189619]\n",
      "1309 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.184254]\n",
      "1310 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.203892]\n",
      "1311 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191617]\n",
      "1312 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.174632]\n",
      "1313 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.197325]\n",
      "1314 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.194339]\n",
      "1315 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.178701]\n",
      "1316 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.180331]\n",
      "1317 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.166566]\n",
      "1318 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.204677]\n",
      "1319 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.194153]\n",
      "1320 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.191657]\n",
      "1321 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.177487]\n",
      "1322 [D loss: 0.000044, acc.: 100.00%] [G loss: 3.209523]\n",
      "1323 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.195331]\n",
      "1324 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.176107]\n",
      "1325 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.180802]\n",
      "1326 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.175766]\n",
      "1327 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.182369]\n",
      "1328 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.204914]\n",
      "1329 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.171951]\n",
      "1330 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.189956]\n",
      "1331 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.192798]\n",
      "1332 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.199725]\n",
      "1333 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.186898]\n",
      "1334 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.200665]\n",
      "1335 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.187305]\n",
      "1336 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.197329]\n",
      "1337 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.169420]\n",
      "1338 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.191746]\n",
      "1339 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.206193]\n",
      "1340 [D loss: 0.000044, acc.: 100.00%] [G loss: 3.190055]\n",
      "1341 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.203048]\n",
      "1342 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.224839]\n",
      "1343 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.200664]\n",
      "1344 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.180901]\n",
      "1345 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.188210]\n",
      "1346 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.201174]\n",
      "1347 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.206515]\n",
      "1348 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.187100]\n",
      "1349 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.187883]\n",
      "1350 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.165217]\n",
      "1351 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.190949]\n",
      "1352 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.177489]\n",
      "1353 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.190203]\n",
      "1354 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.197742]\n",
      "1355 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.180512]\n",
      "1356 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.183769]\n",
      "1357 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.174540]\n",
      "1358 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.203493]\n",
      "1359 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.186689]\n",
      "1360 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.182623]\n",
      "1361 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.186553]\n",
      "1362 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.184647]\n",
      "1363 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.183301]\n",
      "1364 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.175147]\n",
      "1365 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.196007]\n",
      "1366 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.185193]\n",
      "1367 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.192097]\n",
      "1368 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.177875]\n",
      "1369 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.182987]\n",
      "1370 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.181747]\n",
      "1371 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.184611]\n",
      "1372 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.192478]\n",
      "1373 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.174174]\n",
      "1374 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.185166]\n",
      "1375 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.195816]\n",
      "1376 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.160885]\n",
      "1377 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.189737]\n",
      "1378 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180557]\n",
      "1379 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.176033]\n",
      "1380 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.191099]\n",
      "1381 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.203125]\n",
      "1382 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.179866]\n",
      "1383 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.204623]\n",
      "1384 [D loss: 0.000060, acc.: 100.00%] [G loss: 3.187233]\n",
      "1385 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190975]\n",
      "1386 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.197432]\n",
      "1387 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.189672]\n",
      "1388 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.188745]\n",
      "1389 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.197089]\n",
      "1390 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.191174]\n",
      "1391 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.208372]\n",
      "1392 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.195533]\n",
      "1393 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.184254]\n",
      "1394 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.191844]\n",
      "1395 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.188008]\n",
      "1396 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.156175]\n",
      "1397 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.173991]\n",
      "1398 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.169251]\n",
      "1399 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.187088]\n",
      "1400 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.164795]\n",
      "[[[-0.13751447]\n",
      "  [-0.737206  ]\n",
      "  [-0.6523816 ]\n",
      "  ...\n",
      "  [-0.0532464 ]\n",
      "  [-0.22654815]\n",
      "  [-0.93906   ]]\n",
      "\n",
      " [[ 0.13987215]\n",
      "  [-0.4533743 ]\n",
      "  [-0.7678093 ]\n",
      "  ...\n",
      "  [ 0.99831796]\n",
      "  [ 0.57280314]\n",
      "  [ 0.9571633 ]]\n",
      "\n",
      " [[-0.93511343]\n",
      "  [ 0.39378345]\n",
      "  [-0.65581137]\n",
      "  ...\n",
      "  [ 0.91379476]\n",
      "  [ 0.9978581 ]\n",
      "  [ 0.98974115]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.4271627 ]\n",
      "  [-0.5600962 ]\n",
      "  [-0.7121425 ]\n",
      "  ...\n",
      "  [-0.7780614 ]\n",
      "  [-0.9074669 ]\n",
      "  [ 0.18239494]]\n",
      "\n",
      " [[-0.65499556]\n",
      "  [ 0.3473852 ]\n",
      "  [-0.0935817 ]\n",
      "  ...\n",
      "  [-0.9126184 ]\n",
      "  [-0.50922847]\n",
      "  [-0.23532455]]\n",
      "\n",
      " [[-0.90913206]\n",
      "  [-0.29790926]\n",
      "  [-0.76289463]\n",
      "  ...\n",
      "  [-0.14871313]\n",
      "  [-0.71965075]\n",
      "  [-0.7485939 ]]]\n",
      "1401 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.182750]\n",
      "1402 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.177888]\n",
      "1403 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.178886]\n",
      "1404 [D loss: 0.000040, acc.: 100.00%] [G loss: 3.172834]\n",
      "1405 [D loss: 0.000055, acc.: 100.00%] [G loss: 3.164871]\n",
      "1406 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.170258]\n",
      "1407 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.192468]\n",
      "1408 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.178790]\n",
      "1409 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.183807]\n",
      "1410 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.169714]\n",
      "1411 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.168020]\n",
      "1412 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.176603]\n",
      "1413 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.185874]\n",
      "1414 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.201369]\n",
      "1415 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.173832]\n",
      "1416 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.178796]\n",
      "1417 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.176692]\n",
      "1418 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.169491]\n",
      "1419 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.183738]\n",
      "1420 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.159037]\n",
      "1421 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.162317]\n",
      "1422 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.158783]\n",
      "1423 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.164799]\n",
      "1424 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.182579]\n",
      "1425 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.181615]\n",
      "1426 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.161952]\n",
      "1427 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.164699]\n",
      "1428 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.174784]\n",
      "1429 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.177421]\n",
      "1430 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.172861]\n",
      "1431 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.155669]\n",
      "1432 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.181759]\n",
      "1433 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.179578]\n",
      "1434 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.165307]\n",
      "1435 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.197407]\n",
      "1436 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.185397]\n",
      "1437 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.205234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438 [D loss: 0.000048, acc.: 100.00%] [G loss: 3.171854]\n",
      "1439 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.186837]\n",
      "1440 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.200792]\n",
      "1441 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.183591]\n",
      "1442 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.192556]\n",
      "1443 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.163156]\n",
      "1444 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.167058]\n",
      "1445 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.181360]\n",
      "1446 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.174384]\n",
      "1447 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.181627]\n",
      "1448 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.190741]\n",
      "1449 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.157157]\n",
      "1450 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187001]\n",
      "1451 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.171163]\n",
      "1452 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.193844]\n",
      "1453 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.174951]\n",
      "1454 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.175613]\n",
      "1455 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.174742]\n",
      "1456 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.179690]\n",
      "1457 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.167448]\n",
      "1458 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.170894]\n",
      "1459 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.159316]\n",
      "1460 [D loss: 0.000037, acc.: 100.00%] [G loss: 3.192168]\n",
      "1461 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179767]\n",
      "1462 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.173398]\n",
      "1463 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.171625]\n",
      "1464 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.167796]\n",
      "1465 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.158342]\n",
      "1466 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.161554]\n",
      "1467 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.183777]\n",
      "1468 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.167410]\n",
      "1469 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.176853]\n",
      "1470 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.176168]\n",
      "1471 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.163740]\n",
      "1472 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.158328]\n",
      "1473 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.179862]\n",
      "1474 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.151914]\n",
      "1475 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.171209]\n",
      "1476 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.166258]\n",
      "1477 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.164483]\n",
      "1478 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.174311]\n",
      "1479 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182681]\n",
      "1480 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.172784]\n",
      "1481 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.148440]\n",
      "1482 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.174139]\n",
      "1483 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.150429]\n",
      "1484 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.164376]\n",
      "1485 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.165969]\n",
      "1486 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.170579]\n",
      "1487 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.154441]\n",
      "1488 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.164683]\n",
      "1489 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.165637]\n",
      "1490 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.175524]\n",
      "1491 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.168274]\n",
      "1492 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.188196]\n",
      "1493 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186204]\n",
      "1494 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.156656]\n",
      "1495 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.191541]\n",
      "1496 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.171683]\n",
      "1497 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.165456]\n",
      "1498 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.168805]\n",
      "1499 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.148390]\n",
      "1500 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.154764]\n",
      "[[[-0.86400586]\n",
      "  [-0.76327133]\n",
      "  [-0.8843261 ]\n",
      "  ...\n",
      "  [-0.90875673]\n",
      "  [-0.9174724 ]\n",
      "  [-0.7957359 ]]\n",
      "\n",
      " [[-0.83867955]\n",
      "  [-0.6517473 ]\n",
      "  [-0.9654888 ]\n",
      "  ...\n",
      "  [ 0.54267377]\n",
      "  [-0.93413246]\n",
      "  [-0.81460375]]\n",
      "\n",
      " [[ 0.27039778]\n",
      "  [ 0.05115142]\n",
      "  [-0.44121355]\n",
      "  ...\n",
      "  [ 0.7305045 ]\n",
      "  [-0.48789203]\n",
      "  [-0.9169587 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.47556835]\n",
      "  [-0.38541484]\n",
      "  [-0.7026384 ]\n",
      "  ...\n",
      "  [ 0.30795115]\n",
      "  [-0.00173732]\n",
      "  [ 0.23947093]]\n",
      "\n",
      " [[-0.6214162 ]\n",
      "  [ 0.649994  ]\n",
      "  [-0.69498813]\n",
      "  ...\n",
      "  [ 0.8973632 ]\n",
      "  [ 0.11699764]\n",
      "  [-0.92103976]]\n",
      "\n",
      " [[-0.49063075]\n",
      "  [-0.6917688 ]\n",
      "  [ 0.06751562]\n",
      "  ...\n",
      "  [-0.45618197]\n",
      "  [-0.9103119 ]\n",
      "  [-0.29864702]]]\n",
      "1501 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.161861]\n",
      "1502 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.159793]\n",
      "1503 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.165784]\n",
      "1504 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.166323]\n",
      "1505 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.179165]\n",
      "1506 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.159941]\n",
      "1507 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.159513]\n",
      "1508 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.139657]\n",
      "1509 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.177858]\n",
      "1510 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.148745]\n",
      "1511 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.148996]\n",
      "1512 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.161384]\n",
      "1513 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.164405]\n",
      "1514 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.175608]\n",
      "1515 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.169449]\n",
      "1516 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.164966]\n",
      "1517 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.169374]\n",
      "1518 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.150658]\n",
      "1519 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.162250]\n",
      "1520 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.163423]\n",
      "1521 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.188968]\n",
      "1522 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.180880]\n",
      "1523 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.172709]\n",
      "1524 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.177418]\n",
      "1525 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.179415]\n",
      "1526 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.156242]\n",
      "1527 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.174821]\n",
      "1528 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.163523]\n",
      "1529 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.181345]\n",
      "1530 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.174742]\n",
      "1531 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.152393]\n",
      "1532 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.188225]\n",
      "1533 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.170740]\n",
      "1534 [D loss: 0.000023, acc.: 100.00%] [G loss: 3.188930]\n",
      "1535 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.197103]\n",
      "1536 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.167413]\n",
      "1537 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.166464]\n",
      "1538 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.175808]\n",
      "1539 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.173913]\n",
      "1540 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.162226]\n",
      "1541 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.179363]\n",
      "1542 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.174683]\n",
      "1543 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.188412]\n",
      "1544 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.169069]\n",
      "1545 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.175804]\n",
      "1546 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.185245]\n",
      "1547 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.180840]\n",
      "1548 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.184286]\n",
      "1549 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.171115]\n",
      "1550 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.173109]\n",
      "1551 [D loss: 0.000056, acc.: 100.00%] [G loss: 3.173098]\n",
      "1552 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.177009]\n",
      "1553 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.184650]\n",
      "1554 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.201228]\n",
      "1555 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.176532]\n",
      "1556 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180045]\n",
      "1557 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.178658]\n",
      "1558 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.168373]\n",
      "1559 [D loss: 0.000021, acc.: 100.00%] [G loss: 3.164945]\n",
      "1560 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.169711]\n",
      "1561 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.189185]\n",
      "1562 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.143050]\n",
      "1563 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.161669]\n",
      "1564 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.173998]\n",
      "1565 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.153898]\n",
      "1566 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.157477]\n",
      "1567 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.172435]\n",
      "1568 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.151784]\n",
      "1569 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.159576]\n",
      "1570 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.164430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1571 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.180026]\n",
      "1572 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.175137]\n",
      "1573 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.167732]\n",
      "1574 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.143066]\n",
      "1575 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.173154]\n",
      "1576 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.143525]\n",
      "1577 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.167571]\n",
      "1578 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.175671]\n",
      "1579 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.148729]\n",
      "1580 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.169857]\n",
      "1581 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.166973]\n",
      "1582 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.148370]\n",
      "1583 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.164783]\n",
      "1584 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.163547]\n",
      "1585 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.168794]\n",
      "1586 [D loss: 0.000054, acc.: 100.00%] [G loss: 3.190644]\n",
      "1587 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.164787]\n",
      "1588 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.173855]\n",
      "1589 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.171709]\n",
      "1590 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.181189]\n",
      "1591 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.169789]\n",
      "1592 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.158823]\n",
      "1593 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.171507]\n",
      "1594 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.170074]\n",
      "1595 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.159036]\n",
      "1596 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.175950]\n",
      "1597 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.156102]\n",
      "1598 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.168372]\n",
      "1599 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.153020]\n",
      "1600 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.175830]\n",
      "[[[-0.69180685]\n",
      "  [-0.79247475]\n",
      "  [-0.48059252]\n",
      "  ...\n",
      "  [-0.8913452 ]\n",
      "  [-0.44758555]\n",
      "  [-0.46069187]]\n",
      "\n",
      " [[-0.27775925]\n",
      "  [ 0.03632279]\n",
      "  [-0.2851051 ]\n",
      "  ...\n",
      "  [-0.9369661 ]\n",
      "  [-0.9315218 ]\n",
      "  [-0.71812963]]\n",
      "\n",
      " [[-0.18856765]\n",
      "  [ 0.61640996]\n",
      "  [-0.35442144]\n",
      "  ...\n",
      "  [ 0.05826652]\n",
      "  [-0.8902732 ]\n",
      "  [-0.7296232 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.01506393]\n",
      "  [ 0.4577983 ]\n",
      "  [-0.73793864]\n",
      "  ...\n",
      "  [-0.34742913]\n",
      "  [-0.92087156]\n",
      "  [-0.18916017]]\n",
      "\n",
      " [[ 0.9012894 ]\n",
      "  [-0.89547855]\n",
      "  [-0.19851597]\n",
      "  ...\n",
      "  [ 0.6287184 ]\n",
      "  [-0.30804566]\n",
      "  [ 0.06845371]]\n",
      "\n",
      " [[-0.9206108 ]\n",
      "  [ 0.7632751 ]\n",
      "  [-0.6131194 ]\n",
      "  ...\n",
      "  [ 0.37330797]\n",
      "  [-0.41559795]\n",
      "  [-0.58661675]]]\n",
      "1601 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.162341]\n",
      "1602 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.168959]\n",
      "1603 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.170206]\n",
      "1604 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.166124]\n",
      "1605 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.183245]\n",
      "1606 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.158909]\n",
      "1607 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.162262]\n",
      "1608 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.151291]\n",
      "1609 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.151228]\n",
      "1610 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.148616]\n",
      "1611 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.162104]\n",
      "1612 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.168062]\n",
      "1613 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.167443]\n",
      "1614 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.175294]\n",
      "1615 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.172760]\n",
      "1616 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.187888]\n",
      "1617 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180938]\n",
      "1618 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.172094]\n",
      "1619 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.177921]\n",
      "1620 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.178490]\n",
      "1621 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.172739]\n",
      "1622 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.169963]\n",
      "1623 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.141083]\n",
      "1624 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.172507]\n",
      "1625 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.167443]\n",
      "1626 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.162908]\n",
      "1627 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.156043]\n",
      "1628 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.150663]\n",
      "1629 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.169163]\n",
      "1630 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.150866]\n",
      "1631 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.161351]\n",
      "1632 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.166133]\n",
      "1633 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.175699]\n",
      "1634 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.154666]\n",
      "1635 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.160958]\n",
      "1636 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.164772]\n",
      "1637 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.181806]\n",
      "1638 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.162391]\n",
      "1639 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.140790]\n",
      "1640 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.166433]\n",
      "1641 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.167448]\n",
      "1642 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.157248]\n",
      "1643 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.150209]\n",
      "1644 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.192111]\n",
      "1645 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.170512]\n",
      "1646 [D loss: 0.000019, acc.: 100.00%] [G loss: 3.132207]\n",
      "1647 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.160354]\n",
      "1648 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.158744]\n",
      "1649 [D loss: 0.000025, acc.: 100.00%] [G loss: 3.162514]\n",
      "1650 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.156018]\n",
      "1651 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.179255]\n",
      "1652 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.169354]\n",
      "1653 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.196924]\n",
      "1654 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.178833]\n",
      "1655 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.196084]\n",
      "1656 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.171185]\n",
      "1657 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.172495]\n",
      "1658 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.174952]\n",
      "1659 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.183519]\n",
      "1660 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.185094]\n",
      "1661 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.164009]\n",
      "1662 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.161883]\n",
      "1663 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.167064]\n",
      "1664 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.163788]\n",
      "1665 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.155646]\n",
      "1666 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.171278]\n",
      "1667 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.160557]\n",
      "1668 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.162049]\n",
      "1669 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.162566]\n",
      "1670 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.174258]\n",
      "1671 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.194278]\n",
      "1672 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.165181]\n",
      "1673 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.169037]\n",
      "1674 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.160080]\n",
      "1675 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177360]\n",
      "1676 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.178822]\n",
      "1677 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.154980]\n",
      "1678 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.159467]\n",
      "1679 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177867]\n",
      "1680 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.161305]\n",
      "1681 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.174353]\n",
      "1682 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.169832]\n",
      "1683 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.154224]\n",
      "1684 [D loss: 0.000024, acc.: 100.00%] [G loss: 3.171291]\n",
      "1685 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.155788]\n",
      "1686 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.166771]\n",
      "1687 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.176168]\n",
      "1688 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.192980]\n",
      "1689 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.181685]\n",
      "1690 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.172906]\n",
      "1691 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.164690]\n",
      "1692 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.179184]\n",
      "1693 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.170102]\n",
      "1694 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.178821]\n",
      "1695 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.161547]\n",
      "1696 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.161564]\n",
      "1697 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.171015]\n",
      "1698 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.182222]\n",
      "1699 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.176792]\n",
      "1700 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.154034]\n",
      "[[[-0.00569362]\n",
      "  [-0.79244787]\n",
      "  [-0.86260927]\n",
      "  ...\n",
      "  [-0.8682412 ]\n",
      "  [-0.73165345]\n",
      "  [-0.6942899 ]]\n",
      "\n",
      " [[-0.22558403]\n",
      "  [ 0.8163605 ]\n",
      "  [-0.8415344 ]\n",
      "  ...\n",
      "  [ 0.9547169 ]\n",
      "  [-0.9709577 ]\n",
      "  [-0.9005337 ]]\n",
      "\n",
      " [[ 0.5427209 ]\n",
      "  [ 0.8447005 ]\n",
      "  [-0.07344248]\n",
      "  ...\n",
      "  [-0.7561906 ]\n",
      "  [ 0.9495888 ]\n",
      "  [-0.9651037 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.9714867 ]\n",
      "  [ 0.5422027 ]\n",
      "  [-0.9713535 ]\n",
      "  ...\n",
      "  [-0.6829138 ]\n",
      "  [-0.9428816 ]\n",
      "  [-0.63341486]]\n",
      "\n",
      " [[ 0.7645636 ]\n",
      "  [-0.27298126]\n",
      "  [ 0.6905935 ]\n",
      "  ...\n",
      "  [ 0.6182865 ]\n",
      "  [-0.28722998]\n",
      "  [-0.02752308]]\n",
      "\n",
      " [[-0.96777683]\n",
      "  [ 0.97093517]\n",
      "  [-0.40230083]\n",
      "  ...\n",
      "  [-0.05387797]\n",
      "  [-0.41809583]\n",
      "  [-0.3349482 ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.154654]\n",
      "1702 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180045]\n",
      "1703 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.156584]\n",
      "1704 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.150705]\n",
      "1705 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.154812]\n",
      "1706 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.156584]\n",
      "1707 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.168292]\n",
      "1708 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.155333]\n",
      "1709 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.170120]\n",
      "1710 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.171084]\n",
      "1711 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.156172]\n",
      "1712 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.171919]\n",
      "1713 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.153231]\n",
      "1714 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.138595]\n",
      "1715 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.176682]\n",
      "1716 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.166600]\n",
      "1717 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.168540]\n",
      "1718 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.147997]\n",
      "1719 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.164513]\n",
      "1720 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.152641]\n",
      "1721 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.165262]\n",
      "1722 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.179559]\n",
      "1723 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.161139]\n",
      "1724 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.182300]\n",
      "1725 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.177753]\n",
      "1726 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.179257]\n",
      "1727 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.180301]\n",
      "1728 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.188541]\n",
      "1729 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.174242]\n",
      "1730 [D loss: 0.000022, acc.: 100.00%] [G loss: 3.173243]\n",
      "1731 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.166116]\n",
      "1732 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.165490]\n",
      "1733 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.176045]\n",
      "1734 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.169701]\n",
      "1735 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.164239]\n",
      "1736 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.162823]\n",
      "1737 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.182487]\n",
      "1738 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.156016]\n",
      "1739 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.169425]\n",
      "1740 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.182287]\n",
      "1741 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.176460]\n",
      "1742 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.191298]\n",
      "1743 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.192224]\n",
      "1744 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.160306]\n",
      "1745 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.171796]\n",
      "1746 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.160485]\n",
      "1747 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.168513]\n",
      "1748 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.179264]\n",
      "1749 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.168471]\n",
      "1750 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.168803]\n",
      "1751 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.191352]\n",
      "1752 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.171554]\n",
      "1753 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.159395]\n",
      "1754 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.172070]\n",
      "1755 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.165145]\n",
      "1756 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.186615]\n",
      "1757 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.179957]\n",
      "1758 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.167263]\n",
      "1759 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.185588]\n",
      "1760 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.189839]\n",
      "1761 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.162629]\n",
      "1762 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.180668]\n",
      "1763 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.156970]\n",
      "1764 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.189583]\n",
      "1765 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.201108]\n",
      "1766 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188154]\n",
      "1767 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.194478]\n",
      "1768 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179356]\n",
      "1769 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.176952]\n",
      "1770 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.193042]\n",
      "1771 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.174201]\n",
      "1772 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.168770]\n",
      "1773 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.163824]\n",
      "1774 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.193170]\n",
      "1775 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.178714]\n",
      "1776 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.171058]\n",
      "1777 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.170499]\n",
      "1778 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.191078]\n",
      "1779 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.189032]\n",
      "1780 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.185205]\n",
      "1781 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.189594]\n",
      "1782 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.183318]\n",
      "1783 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.178886]\n",
      "1784 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182536]\n",
      "1785 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.178349]\n",
      "1786 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.181355]\n",
      "1787 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.178990]\n",
      "1788 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.197854]\n",
      "1789 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.182451]\n",
      "1790 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.195688]\n",
      "1791 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.171033]\n",
      "1792 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182523]\n",
      "1793 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179550]\n",
      "1794 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.198088]\n",
      "1795 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.183460]\n",
      "1796 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.171868]\n",
      "1797 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.166822]\n",
      "1798 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.175855]\n",
      "1799 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.180275]\n",
      "1800 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.162428]\n",
      "[[[-0.833023  ]\n",
      "  [-0.8375744 ]\n",
      "  [-0.8497807 ]\n",
      "  ...\n",
      "  [-0.26534712]\n",
      "  [ 0.2821593 ]\n",
      "  [-0.7279351 ]]\n",
      "\n",
      " [[-0.87746966]\n",
      "  [-0.41027573]\n",
      "  [-0.8493545 ]\n",
      "  ...\n",
      "  [ 0.8057767 ]\n",
      "  [-0.34960487]\n",
      "  [ 0.88464564]]\n",
      "\n",
      " [[-0.33079287]\n",
      "  [-0.2469388 ]\n",
      "  [-0.9331688 ]\n",
      "  ...\n",
      "  [-0.14217158]\n",
      "  [ 0.38498276]\n",
      "  [ 0.09805173]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.5572711 ]\n",
      "  [ 0.7027031 ]\n",
      "  [-0.87073356]\n",
      "  ...\n",
      "  [ 0.12184536]\n",
      "  [-0.6232866 ]\n",
      "  [ 0.43621007]]\n",
      "\n",
      " [[ 0.02223343]\n",
      "  [-0.30132422]\n",
      "  [-0.7722653 ]\n",
      "  ...\n",
      "  [-0.8059795 ]\n",
      "  [ 0.483717  ]\n",
      "  [ 0.1604245 ]]\n",
      "\n",
      " [[-0.91898376]\n",
      "  [ 0.5888114 ]\n",
      "  [-0.8513403 ]\n",
      "  ...\n",
      "  [-0.6898712 ]\n",
      "  [-0.40410653]\n",
      "  [ 0.11600895]]]\n",
      "1801 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.177762]\n",
      "1802 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190254]\n",
      "1803 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.163692]\n",
      "1804 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.156774]\n",
      "1805 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.184468]\n",
      "1806 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.172658]\n",
      "1807 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.161604]\n",
      "1808 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.166986]\n",
      "1809 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.173753]\n",
      "1810 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.183716]\n",
      "1811 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.179844]\n",
      "1812 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.166832]\n",
      "1813 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.174005]\n",
      "1814 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.180635]\n",
      "1815 [D loss: 0.000027, acc.: 100.00%] [G loss: 3.191766]\n",
      "1816 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.173953]\n",
      "1817 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.188918]\n",
      "1818 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.203422]\n",
      "1819 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.162036]\n",
      "1820 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.180168]\n",
      "1821 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.171410]\n",
      "1822 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.164010]\n",
      "1823 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.177499]\n",
      "1824 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.164656]\n",
      "1825 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186692]\n",
      "1826 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.160743]\n",
      "1827 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.163118]\n",
      "1828 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.168963]\n",
      "1829 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.174532]\n",
      "1830 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.161693]\n",
      "1831 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.204545]\n",
      "1832 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.193583]\n",
      "1833 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186982]\n",
      "1834 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.199472]\n",
      "1835 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.198351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.172849]\n",
      "1837 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177006]\n",
      "1838 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.181330]\n",
      "1839 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.189453]\n",
      "1840 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.180225]\n",
      "1841 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.184872]\n",
      "1842 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.202576]\n",
      "1843 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.193014]\n",
      "1844 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.205507]\n",
      "1845 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.189082]\n",
      "1846 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.168296]\n",
      "1847 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.172136]\n",
      "1848 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.197017]\n",
      "1849 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.188312]\n",
      "1850 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.193294]\n",
      "1851 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.205647]\n",
      "1852 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200571]\n",
      "1853 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.178478]\n",
      "1854 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.168787]\n",
      "1855 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.165725]\n",
      "1856 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.180350]\n",
      "1857 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.176728]\n",
      "1858 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.177285]\n",
      "1859 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177795]\n",
      "1860 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.155217]\n",
      "1861 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.177460]\n",
      "1862 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.185031]\n",
      "1863 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.162545]\n",
      "1864 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185866]\n",
      "1865 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.172809]\n",
      "1866 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.181226]\n",
      "1867 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.171072]\n",
      "1868 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.192265]\n",
      "1869 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186217]\n",
      "1870 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.192084]\n",
      "1871 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.180946]\n",
      "1872 [D loss: 0.000029, acc.: 100.00%] [G loss: 3.169161]\n",
      "1873 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.194379]\n",
      "1874 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.174335]\n",
      "1875 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180905]\n",
      "1876 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177747]\n",
      "1877 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.192355]\n",
      "1878 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.168378]\n",
      "1879 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182817]\n",
      "1880 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.166766]\n",
      "1881 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.163593]\n",
      "1882 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.165716]\n",
      "1883 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.177388]\n",
      "1884 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.164153]\n",
      "1885 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.166649]\n",
      "1886 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.183201]\n",
      "1887 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.172966]\n",
      "1888 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.163754]\n",
      "1889 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195506]\n",
      "1890 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.164789]\n",
      "1891 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.182647]\n",
      "1892 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.168672]\n",
      "1893 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.189113]\n",
      "1894 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.173624]\n",
      "1895 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.187770]\n",
      "1896 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.192708]\n",
      "1897 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.184213]\n",
      "1898 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.199123]\n",
      "1899 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188112]\n",
      "1900 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.174811]\n",
      "[[[-0.77388924]\n",
      "  [-0.91959393]\n",
      "  [-0.9529352 ]\n",
      "  ...\n",
      "  [-0.9526262 ]\n",
      "  [-0.9108152 ]\n",
      "  [-0.7696196 ]]\n",
      "\n",
      " [[-0.8974615 ]\n",
      "  [ 0.36136195]\n",
      "  [-0.9095356 ]\n",
      "  ...\n",
      "  [-0.01239142]\n",
      "  [-0.9051794 ]\n",
      "  [-0.8632101 ]]\n",
      "\n",
      " [[ 0.6665001 ]\n",
      "  [ 0.550295  ]\n",
      "  [ 0.6750716 ]\n",
      "  ...\n",
      "  [-0.40261722]\n",
      "  [-0.7305709 ]\n",
      "  [-0.83573383]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.25355113]\n",
      "  [ 0.9809903 ]\n",
      "  [-0.94442284]\n",
      "  ...\n",
      "  [-0.8771695 ]\n",
      "  [-0.9354093 ]\n",
      "  [-0.3782858 ]]\n",
      "\n",
      " [[ 0.95077986]\n",
      "  [ 0.9371176 ]\n",
      "  [ 0.24394503]\n",
      "  ...\n",
      "  [-0.79234934]\n",
      "  [-0.2299383 ]\n",
      "  [-0.35817897]]\n",
      "\n",
      " [[ 0.383413  ]\n",
      "  [ 0.971454  ]\n",
      "  [-0.5631353 ]\n",
      "  ...\n",
      "  [ 0.8959849 ]\n",
      "  [-0.91004443]\n",
      "  [-0.85007256]]]\n",
      "1901 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.169899]\n",
      "1902 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.170881]\n",
      "1903 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.185447]\n",
      "1904 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.172919]\n",
      "1905 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.160025]\n",
      "1906 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.175641]\n",
      "1907 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.165349]\n",
      "1908 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.184087]\n",
      "1909 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.179118]\n",
      "1910 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182247]\n",
      "1911 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.152925]\n",
      "1912 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188353]\n",
      "1913 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.176814]\n",
      "1914 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.199944]\n",
      "1915 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.172810]\n",
      "1916 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.196157]\n",
      "1917 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.155363]\n",
      "1918 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.192192]\n",
      "1919 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.179464]\n",
      "1920 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.181274]\n",
      "1921 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.171341]\n",
      "1922 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.190272]\n",
      "1923 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187845]\n",
      "1924 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.188134]\n",
      "1925 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.198044]\n",
      "1926 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.183737]\n",
      "1927 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.195767]\n",
      "1928 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.175073]\n",
      "1929 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.170845]\n",
      "1930 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.180905]\n",
      "1931 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.175163]\n",
      "1932 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205444]\n",
      "1933 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.212817]\n",
      "1934 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.191730]\n",
      "1935 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.174855]\n",
      "1936 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.198350]\n",
      "1937 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206349]\n",
      "1938 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191185]\n",
      "1939 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.196856]\n",
      "1940 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182354]\n",
      "1941 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.175593]\n",
      "1942 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.203854]\n",
      "1943 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.193467]\n",
      "1944 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.186759]\n",
      "1945 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.193888]\n",
      "1946 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.191226]\n",
      "1947 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180212]\n",
      "1948 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.213656]\n",
      "1949 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.206796]\n",
      "1950 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201921]\n",
      "1951 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.197559]\n",
      "1952 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195262]\n",
      "1953 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.200234]\n",
      "1954 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.188898]\n",
      "1955 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.187560]\n",
      "1956 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.206837]\n",
      "1957 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.187799]\n",
      "1958 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.197932]\n",
      "1959 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.207195]\n",
      "1960 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.183178]\n",
      "1961 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177699]\n",
      "1962 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.172743]\n",
      "1963 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189415]\n",
      "1964 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.182167]\n",
      "1965 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186978]\n",
      "1966 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191883]\n",
      "1967 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.163407]\n",
      "1968 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.190275]\n",
      "1969 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.197979]\n",
      "1970 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.168751]\n",
      "1971 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.201202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.200369]\n",
      "1973 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.189776]\n",
      "1974 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.206510]\n",
      "1975 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.172110]\n",
      "1976 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203900]\n",
      "1977 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.196798]\n",
      "1978 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.193887]\n",
      "1979 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179107]\n",
      "1980 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186138]\n",
      "1981 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.187320]\n",
      "1982 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.222650]\n",
      "1983 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.167327]\n",
      "1984 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186880]\n",
      "1985 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200189]\n",
      "1986 [D loss: 0.000052, acc.: 100.00%] [G loss: 3.161349]\n",
      "1987 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.193721]\n",
      "1988 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.179663]\n",
      "1989 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.178177]\n",
      "1990 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.165554]\n",
      "1991 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183583]\n",
      "1992 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.175031]\n",
      "1993 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.198264]\n",
      "1994 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.184817]\n",
      "1995 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.184268]\n",
      "1996 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186284]\n",
      "1997 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.188364]\n",
      "1998 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.199264]\n",
      "1999 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.200676]\n",
      "2000 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191005]\n",
      "[[[-0.7891721 ]\n",
      "  [-0.6945893 ]\n",
      "  [-0.8545791 ]\n",
      "  ...\n",
      "  [-0.89844596]\n",
      "  [-0.8654145 ]\n",
      "  [-0.42675975]]\n",
      "\n",
      " [[-0.30664513]\n",
      "  [ 0.46483165]\n",
      "  [-0.5470919 ]\n",
      "  ...\n",
      "  [ 0.9901611 ]\n",
      "  [-0.91608196]\n",
      "  [-0.7707814 ]]\n",
      "\n",
      " [[ 0.21851252]\n",
      "  [ 0.81755906]\n",
      "  [-0.2855763 ]\n",
      "  ...\n",
      "  [-0.35862085]\n",
      "  [ 0.25951627]\n",
      "  [-0.6716765 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.34251755]\n",
      "  [ 0.93691224]\n",
      "  [ 0.05251106]\n",
      "  ...\n",
      "  [ 0.5250796 ]\n",
      "  [-0.9363101 ]\n",
      "  [-0.10429987]]\n",
      "\n",
      " [[-0.22815496]\n",
      "  [ 0.9979243 ]\n",
      "  [-0.5158072 ]\n",
      "  ...\n",
      "  [-0.36840582]\n",
      "  [ 0.875409  ]\n",
      "  [-0.7166796 ]]\n",
      "\n",
      " [[ 0.4369925 ]\n",
      "  [-0.5075213 ]\n",
      "  [ 0.57346386]\n",
      "  ...\n",
      "  [ 0.30849048]\n",
      "  [-0.59219384]\n",
      "  [ 0.05546641]]]\n",
      "2001 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.191352]\n",
      "2002 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189371]\n",
      "2003 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195295]\n",
      "2004 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.182088]\n",
      "2005 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.183346]\n",
      "2006 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177797]\n",
      "2007 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.168672]\n",
      "2008 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.177009]\n",
      "2009 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.185230]\n",
      "2010 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.179206]\n",
      "2011 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.194988]\n",
      "2012 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.201486]\n",
      "2013 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186347]\n",
      "2014 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.182630]\n",
      "2015 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.167826]\n",
      "2016 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.193988]\n",
      "2017 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.193375]\n",
      "2018 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.181413]\n",
      "2019 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.194140]\n",
      "2020 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.211023]\n",
      "2021 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.189047]\n",
      "2022 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182808]\n",
      "2023 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180516]\n",
      "2024 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.186594]\n",
      "2025 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.187179]\n",
      "2026 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.181725]\n",
      "2027 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.189608]\n",
      "2028 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.169888]\n",
      "2029 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179422]\n",
      "2030 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191494]\n",
      "2031 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.168423]\n",
      "2032 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.188440]\n",
      "2033 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.204896]\n",
      "2034 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.196459]\n",
      "2035 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.196035]\n",
      "2036 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.206681]\n",
      "2037 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.173459]\n",
      "2038 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.181435]\n",
      "2039 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.185684]\n",
      "2040 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.190551]\n",
      "2041 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.203220]\n",
      "2042 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.188094]\n",
      "2043 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.193044]\n",
      "2044 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188459]\n",
      "2045 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.190383]\n",
      "2046 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.193453]\n",
      "2047 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.186605]\n",
      "2048 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.183939]\n",
      "2049 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.173449]\n",
      "2050 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.160635]\n",
      "2051 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.162084]\n",
      "2052 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182053]\n",
      "2053 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195871]\n",
      "2054 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.171394]\n",
      "2055 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180481]\n",
      "2056 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.184525]\n",
      "2057 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190908]\n",
      "2058 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186410]\n",
      "2059 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.195323]\n",
      "2060 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200468]\n",
      "2061 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.181672]\n",
      "2062 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.195633]\n",
      "2063 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.184226]\n",
      "2064 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.171467]\n",
      "2065 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.196424]\n",
      "2066 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182451]\n",
      "2067 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188763]\n",
      "2068 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183393]\n",
      "2069 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.198842]\n",
      "2070 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.188737]\n",
      "2071 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191437]\n",
      "2072 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.188725]\n",
      "2073 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.172853]\n",
      "2074 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.160341]\n",
      "2075 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.170521]\n",
      "2076 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.179212]\n",
      "2077 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.169824]\n",
      "2078 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.185030]\n",
      "2079 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.184531]\n",
      "2080 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.178005]\n",
      "2081 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.177704]\n",
      "2082 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189083]\n",
      "2083 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.191112]\n",
      "2084 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.188303]\n",
      "2085 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.187991]\n",
      "2086 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.189850]\n",
      "2087 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.197600]\n",
      "2088 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185707]\n",
      "2089 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194168]\n",
      "2090 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.187870]\n",
      "2091 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.161050]\n",
      "2092 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177873]\n",
      "2093 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182477]\n",
      "2094 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.169668]\n",
      "2095 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.177789]\n",
      "2096 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188340]\n",
      "2097 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.196237]\n",
      "2098 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.188038]\n",
      "2099 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.195695]\n",
      "2100 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.194080]\n",
      "[[[-0.6779778 ]\n",
      "  [-0.37387565]\n",
      "  [-0.909727  ]\n",
      "  ...\n",
      "  [-0.601225  ]\n",
      "  [ 0.04032771]\n",
      "  [-0.8939827 ]]\n",
      "\n",
      " [[ 0.7592799 ]\n",
      "  [ 0.45637396]\n",
      "  [-0.27855596]\n",
      "  ...\n",
      "  [ 0.9974584 ]\n",
      "  [-0.9470673 ]\n",
      "  [ 0.9764978 ]]\n",
      "\n",
      " [[ 0.37594506]\n",
      "  [ 0.6943083 ]\n",
      "  [-0.75369716]\n",
      "  ...\n",
      "  [ 0.8505981 ]\n",
      "  [ 0.9699304 ]\n",
      "  [-0.5070817 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.5435472 ]\n",
      "  [-0.9509833 ]\n",
      "  [-0.407364  ]\n",
      "  ...\n",
      "  [-0.69697285]\n",
      "  [-0.888325  ]\n",
      "  [ 0.21168448]]\n",
      "\n",
      " [[ 0.34923372]\n",
      "  [-0.01246031]\n",
      "  [ 0.1284941 ]\n",
      "  ...\n",
      "  [ 0.73543775]\n",
      "  [-0.9219114 ]\n",
      "  [-0.41737345]]\n",
      "\n",
      " [[-0.88034374]\n",
      "  [ 0.9728999 ]\n",
      "  [-0.69775987]\n",
      "  ...\n",
      "  [-0.8075988 ]\n",
      "  [-0.40797782]\n",
      "  [-0.5724518 ]]]\n",
      "2101 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2102 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189054]\n",
      "2103 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.147868]\n",
      "2104 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.185305]\n",
      "2105 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.166001]\n",
      "2106 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.173237]\n",
      "2107 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.195361]\n",
      "2108 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.195007]\n",
      "2109 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.161193]\n",
      "2110 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.194458]\n",
      "2111 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199199]\n",
      "2112 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.185489]\n",
      "2113 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186688]\n",
      "2114 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.194562]\n",
      "2115 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.167369]\n",
      "2116 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.176175]\n",
      "2117 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195421]\n",
      "2118 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185382]\n",
      "2119 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.189245]\n",
      "2120 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.213022]\n",
      "2121 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.189238]\n",
      "2122 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.194352]\n",
      "2123 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.178103]\n",
      "2124 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.186131]\n",
      "2125 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191586]\n",
      "2126 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210958]\n",
      "2127 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.185214]\n",
      "2128 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.192380]\n",
      "2129 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.201432]\n",
      "2130 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.212373]\n",
      "2131 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.197391]\n",
      "2132 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.196265]\n",
      "2133 [D loss: 0.000031, acc.: 100.00%] [G loss: 3.192175]\n",
      "2134 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204269]\n",
      "2135 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.208635]\n",
      "2136 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201859]\n",
      "2137 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185003]\n",
      "2138 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.185747]\n",
      "2139 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.185875]\n",
      "2140 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.201304]\n",
      "2141 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.219849]\n",
      "2142 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.217039]\n",
      "2143 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.193939]\n",
      "2144 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.175283]\n",
      "2145 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.205914]\n",
      "2146 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.196152]\n",
      "2147 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.207974]\n",
      "2148 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.209769]\n",
      "2149 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.199574]\n",
      "2150 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.198126]\n",
      "2151 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196465]\n",
      "2152 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190932]\n",
      "2153 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.196699]\n",
      "2154 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.211637]\n",
      "2155 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.193780]\n",
      "2156 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.199569]\n",
      "2157 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190216]\n",
      "2158 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204934]\n",
      "2159 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.198062]\n",
      "2160 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.177796]\n",
      "2161 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177131]\n",
      "2162 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.170556]\n",
      "2163 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.171289]\n",
      "2164 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.172848]\n",
      "2165 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182036]\n",
      "2166 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183661]\n",
      "2167 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.202399]\n",
      "2168 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.196113]\n",
      "2169 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.197037]\n",
      "2170 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182997]\n",
      "2171 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183413]\n",
      "2172 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.183559]\n",
      "2173 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.192102]\n",
      "2174 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.189569]\n",
      "2175 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195864]\n",
      "2176 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.193450]\n",
      "2177 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.200855]\n",
      "2178 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.189800]\n",
      "2179 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.169941]\n",
      "2180 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.196842]\n",
      "2181 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.187382]\n",
      "2182 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.205179]\n",
      "2183 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182725]\n",
      "2184 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.194448]\n",
      "2185 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.181768]\n",
      "2186 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186687]\n",
      "2187 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.197732]\n",
      "2188 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.201833]\n",
      "2189 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.202410]\n",
      "2190 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.190081]\n",
      "2191 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188626]\n",
      "2192 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.212157]\n",
      "2193 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182166]\n",
      "2194 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190118]\n",
      "2195 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182281]\n",
      "2196 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.180927]\n",
      "2197 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186258]\n",
      "2198 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196361]\n",
      "2199 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185220]\n",
      "2200 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.200720]\n",
      "[[[-0.8458246 ]\n",
      "  [-0.90129906]\n",
      "  [-0.7826688 ]\n",
      "  ...\n",
      "  [-0.8901964 ]\n",
      "  [-0.85172343]\n",
      "  [-0.5833571 ]]\n",
      "\n",
      " [[-0.96052897]\n",
      "  [-0.30195418]\n",
      "  [-0.9182967 ]\n",
      "  ...\n",
      "  [ 0.9755922 ]\n",
      "  [-0.9530642 ]\n",
      "  [-0.7974602 ]]\n",
      "\n",
      " [[ 0.35592937]\n",
      "  [-0.5776273 ]\n",
      "  [-0.7110996 ]\n",
      "  ...\n",
      "  [ 0.65991855]\n",
      "  [ 0.9714277 ]\n",
      "  [-0.91794026]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.1425263 ]\n",
      "  [-0.6284424 ]\n",
      "  [-0.9368438 ]\n",
      "  ...\n",
      "  [ 0.5334448 ]\n",
      "  [ 0.17318788]\n",
      "  [ 0.82681406]]\n",
      "\n",
      " [[-0.683107  ]\n",
      "  [ 0.65560013]\n",
      "  [-0.6024321 ]\n",
      "  ...\n",
      "  [ 0.9934227 ]\n",
      "  [ 0.99870634]\n",
      "  [-0.6228835 ]]\n",
      "\n",
      " [[ 0.41282347]\n",
      "  [ 0.81679696]\n",
      "  [-0.8835156 ]\n",
      "  ...\n",
      "  [-0.6433878 ]\n",
      "  [ 0.95257306]\n",
      "  [ 0.917579  ]]]\n",
      "2201 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.193168]\n",
      "2202 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.197457]\n",
      "2203 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.192894]\n",
      "2204 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.202855]\n",
      "2205 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.203211]\n",
      "2206 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.182578]\n",
      "2207 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204518]\n",
      "2208 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.200611]\n",
      "2209 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.181377]\n",
      "2210 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.197003]\n",
      "2211 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.185390]\n",
      "2212 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189476]\n",
      "2213 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.216749]\n",
      "2214 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.190723]\n",
      "2215 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191071]\n",
      "2216 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.170252]\n",
      "2217 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.189909]\n",
      "2218 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177089]\n",
      "2219 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.169800]\n",
      "2220 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186684]\n",
      "2221 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.193533]\n",
      "2222 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182388]\n",
      "2223 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.195494]\n",
      "2224 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.208127]\n",
      "2225 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.187969]\n",
      "2226 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.192826]\n",
      "2227 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.178603]\n",
      "2228 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203557]\n",
      "2229 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.195927]\n",
      "2230 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.195089]\n",
      "2231 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185762]\n",
      "2232 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.176921]\n",
      "2233 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2234 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.163773]\n",
      "2235 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186607]\n",
      "2236 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192482]\n",
      "2237 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.165527]\n",
      "2238 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.184693]\n",
      "2239 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.183402]\n",
      "2240 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.185877]\n",
      "2241 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191419]\n",
      "2242 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.182406]\n",
      "2243 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.193489]\n",
      "2244 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.176651]\n",
      "2245 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182302]\n",
      "2246 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200811]\n",
      "2247 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.172147]\n",
      "2248 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.203652]\n",
      "2249 [D loss: 0.000020, acc.: 100.00%] [G loss: 3.187477]\n",
      "2250 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.207854]\n",
      "2251 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197354]\n",
      "2252 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.175311]\n",
      "2253 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.175398]\n",
      "2254 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.178137]\n",
      "2255 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.170617]\n",
      "2256 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.175565]\n",
      "2257 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.195675]\n",
      "2258 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189991]\n",
      "2259 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192174]\n",
      "2260 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.175049]\n",
      "2261 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.203640]\n",
      "2262 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195014]\n",
      "2263 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195813]\n",
      "2264 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.180978]\n",
      "2265 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.185318]\n",
      "2266 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188763]\n",
      "2267 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.198919]\n",
      "2268 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.188008]\n",
      "2269 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191636]\n",
      "2270 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.178596]\n",
      "2271 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.189707]\n",
      "2272 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.175419]\n",
      "2273 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209284]\n",
      "2274 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200727]\n",
      "2275 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.179682]\n",
      "2276 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190267]\n",
      "2277 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.168541]\n",
      "2278 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193734]\n",
      "2279 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195501]\n",
      "2280 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.171818]\n",
      "2281 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.170675]\n",
      "2282 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.179053]\n",
      "2283 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.188608]\n",
      "2284 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.174542]\n",
      "2285 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210514]\n",
      "2286 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.192070]\n",
      "2287 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.213159]\n",
      "2288 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.200531]\n",
      "2289 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.214893]\n",
      "2290 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.213378]\n",
      "2291 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208752]\n",
      "2292 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.185701]\n",
      "2293 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185689]\n",
      "2294 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.207654]\n",
      "2295 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.206164]\n",
      "2296 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.217266]\n",
      "2297 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.221956]\n",
      "2298 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191477]\n",
      "2299 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.188946]\n",
      "2300 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187373]\n",
      "[[[-0.90151715]\n",
      "  [-0.8763056 ]\n",
      "  [-0.90380913]\n",
      "  ...\n",
      "  [-0.91038907]\n",
      "  [-0.7887371 ]\n",
      "  [-0.5035633 ]]\n",
      "\n",
      " [[-0.8930751 ]\n",
      "  [-0.36189434]\n",
      "  [-0.92536205]\n",
      "  ...\n",
      "  [-0.7998787 ]\n",
      "  [-0.92006165]\n",
      "  [-0.4510801 ]]\n",
      "\n",
      " [[ 0.9309958 ]\n",
      "  [-0.7976421 ]\n",
      "  [ 0.5193525 ]\n",
      "  ...\n",
      "  [-0.9355401 ]\n",
      "  [-0.5018902 ]\n",
      "  [-0.4076051 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.89554083]\n",
      "  [ 0.7485547 ]\n",
      "  [-0.9014864 ]\n",
      "  ...\n",
      "  [-0.9203972 ]\n",
      "  [-0.7210712 ]\n",
      "  [-0.56300616]]\n",
      "\n",
      " [[ 0.7431904 ]\n",
      "  [-0.678277  ]\n",
      "  [-0.61064184]\n",
      "  ...\n",
      "  [ 0.94392943]\n",
      "  [-0.9198335 ]\n",
      "  [ 0.1035273 ]]\n",
      "\n",
      " [[-0.8970958 ]\n",
      "  [ 0.8575334 ]\n",
      "  [-0.6527891 ]\n",
      "  ...\n",
      "  [-0.24522196]\n",
      "  [-0.44533652]\n",
      "  [-0.21699019]]]\n",
      "2301 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.207525]\n",
      "2302 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.191773]\n",
      "2303 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202135]\n",
      "2304 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206862]\n",
      "2305 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.194760]\n",
      "2306 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.189205]\n",
      "2307 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.220225]\n",
      "2308 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203393]\n",
      "2309 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205173]\n",
      "2310 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209096]\n",
      "2311 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204383]\n",
      "2312 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192163]\n",
      "2313 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196174]\n",
      "2314 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.191936]\n",
      "2315 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.195272]\n",
      "2316 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196199]\n",
      "2317 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.199096]\n",
      "2318 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.206772]\n",
      "2319 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.200333]\n",
      "2320 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199103]\n",
      "2321 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.196672]\n",
      "2322 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.168199]\n",
      "2323 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.185997]\n",
      "2324 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187913]\n",
      "2325 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.180889]\n",
      "2326 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186926]\n",
      "2327 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.166251]\n",
      "2328 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182498]\n",
      "2329 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.158129]\n",
      "2330 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.177668]\n",
      "2331 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.182899]\n",
      "2332 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.149238]\n",
      "2333 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.181321]\n",
      "2334 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189773]\n",
      "2335 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.162794]\n",
      "2336 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.162819]\n",
      "2337 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198564]\n",
      "2338 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.166175]\n",
      "2339 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.169266]\n",
      "2340 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188795]\n",
      "2341 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.174333]\n",
      "2342 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202452]\n",
      "2343 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.197616]\n",
      "2344 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.201501]\n",
      "2345 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189477]\n",
      "2346 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201344]\n",
      "2347 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.195493]\n",
      "2348 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.185558]\n",
      "2349 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.200503]\n",
      "2350 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175427]\n",
      "2351 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.203037]\n",
      "2352 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192259]\n",
      "2353 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.179430]\n",
      "2354 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.203554]\n",
      "2355 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211451]\n",
      "2356 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211266]\n",
      "2357 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.203239]\n",
      "2358 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.194357]\n",
      "2359 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202457]\n",
      "2360 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.198678]\n",
      "2361 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.205240]\n",
      "2362 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.216115]\n",
      "2363 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.207580]\n",
      "2364 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187322]\n",
      "2365 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198783]\n",
      "2366 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.190813]\n",
      "2367 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.170341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200622]\n",
      "2369 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196281]\n",
      "2370 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188232]\n",
      "2371 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188721]\n",
      "2372 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186121]\n",
      "2373 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.199092]\n",
      "2374 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203181]\n",
      "2375 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215224]\n",
      "2376 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179029]\n",
      "2377 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.192820]\n",
      "2378 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.196041]\n",
      "2379 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196342]\n",
      "2380 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192510]\n",
      "2381 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.184401]\n",
      "2382 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.206460]\n",
      "2383 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186182]\n",
      "2384 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196356]\n",
      "2385 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.196670]\n",
      "2386 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200860]\n",
      "2387 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211749]\n",
      "2388 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.198361]\n",
      "2389 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.203854]\n",
      "2390 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.198798]\n",
      "2391 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.205578]\n",
      "2392 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186522]\n",
      "2393 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.209568]\n",
      "2394 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.213108]\n",
      "2395 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.197591]\n",
      "2396 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.199878]\n",
      "2397 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205171]\n",
      "2398 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.207243]\n",
      "2399 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.187927]\n",
      "2400 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198467]\n",
      "[[[-0.16170311]\n",
      "  [-0.848922  ]\n",
      "  [-0.8649287 ]\n",
      "  ...\n",
      "  [-0.9331363 ]\n",
      "  [-0.7387565 ]\n",
      "  [-0.6479428 ]]\n",
      "\n",
      " [[ 0.4500297 ]\n",
      "  [ 0.01688159]\n",
      "  [ 0.56825477]\n",
      "  ...\n",
      "  [ 0.6612744 ]\n",
      "  [-0.9663911 ]\n",
      "  [-0.6160678 ]]\n",
      "\n",
      " [[ 0.8865837 ]\n",
      "  [ 0.99594146]\n",
      "  [-0.9271269 ]\n",
      "  ...\n",
      "  [ 0.44656938]\n",
      "  [ 0.15546605]\n",
      "  [-0.8408693 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.83847886]\n",
      "  [-0.7049413 ]\n",
      "  [-0.9527692 ]\n",
      "  ...\n",
      "  [ 0.28652325]\n",
      "  [-0.23056301]\n",
      "  [ 0.9656623 ]]\n",
      "\n",
      " [[-0.38563478]\n",
      "  [-0.21672879]\n",
      "  [-0.8882397 ]\n",
      "  ...\n",
      "  [-0.08922843]\n",
      "  [ 0.47143835]\n",
      "  [-0.25851884]]\n",
      "\n",
      " [[-0.04462631]\n",
      "  [ 0.8231996 ]\n",
      "  [-0.8291361 ]\n",
      "  ...\n",
      "  [-0.88649356]\n",
      "  [ 0.48518205]\n",
      "  [ 0.01145332]]]\n",
      "2401 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190760]\n",
      "2402 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183930]\n",
      "2403 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.189564]\n",
      "2404 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.173630]\n",
      "2405 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.193926]\n",
      "2406 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189697]\n",
      "2407 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180521]\n",
      "2408 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189457]\n",
      "2409 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.176011]\n",
      "2410 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.185888]\n",
      "2411 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208048]\n",
      "2412 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.197766]\n",
      "2413 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188854]\n",
      "2414 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190626]\n",
      "2415 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192156]\n",
      "2416 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206383]\n",
      "2417 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190336]\n",
      "2418 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184140]\n",
      "2419 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201061]\n",
      "2420 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.189914]\n",
      "2421 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205454]\n",
      "2422 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191008]\n",
      "2423 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194541]\n",
      "2424 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.186047]\n",
      "2425 [D loss: 0.000018, acc.: 100.00%] [G loss: 3.206849]\n",
      "2426 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.179230]\n",
      "2427 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209102]\n",
      "2428 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204265]\n",
      "2429 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183969]\n",
      "2430 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.192692]\n",
      "2431 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198407]\n",
      "2432 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.180719]\n",
      "2433 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.215359]\n",
      "2434 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185042]\n",
      "2435 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187173]\n",
      "2436 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.200513]\n",
      "2437 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.219745]\n",
      "2438 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189386]\n",
      "2439 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.212347]\n",
      "2440 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.193492]\n",
      "2441 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202430]\n",
      "2442 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.207469]\n",
      "2443 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.194264]\n",
      "2444 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.198073]\n",
      "2445 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195081]\n",
      "2446 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.173297]\n",
      "2447 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192291]\n",
      "2448 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192445]\n",
      "2449 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200508]\n",
      "2450 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.178636]\n",
      "2451 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.201780]\n",
      "2452 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.194461]\n",
      "2453 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.202903]\n",
      "2454 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203767]\n",
      "2455 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.215706]\n",
      "2456 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.198280]\n",
      "2457 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220172]\n",
      "2458 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.232581]\n",
      "2459 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191915]\n",
      "2460 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202146]\n",
      "2461 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.221945]\n",
      "2462 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200544]\n",
      "2463 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.194311]\n",
      "2464 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.201655]\n",
      "2465 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193295]\n",
      "2466 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215253]\n",
      "2467 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.195610]\n",
      "2468 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206653]\n",
      "2469 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199192]\n",
      "2470 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.207372]\n",
      "2471 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197051]\n",
      "2472 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198253]\n",
      "2473 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.214146]\n",
      "2474 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192585]\n",
      "2475 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221538]\n",
      "2476 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.201895]\n",
      "2477 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192081]\n",
      "2478 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.201986]\n",
      "2479 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.209590]\n",
      "2480 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185444]\n",
      "2481 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186652]\n",
      "2482 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.213035]\n",
      "2483 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.195572]\n",
      "2484 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.220619]\n",
      "2485 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213203]\n",
      "2486 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204485]\n",
      "2487 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188745]\n",
      "2488 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.213159]\n",
      "2489 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.213223]\n",
      "2490 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.201735]\n",
      "2491 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.198040]\n",
      "2492 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.212075]\n",
      "2493 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209278]\n",
      "2494 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.225363]\n",
      "2495 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206039]\n",
      "2496 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.219726]\n",
      "2497 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199337]\n",
      "2498 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.214135]\n",
      "2499 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.203442]\n",
      "2500 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207162]\n",
      "[[[ 0.00590737]\n",
      "  [-0.90577304]\n",
      "  [-0.5286715 ]\n",
      "  ...\n",
      "  [-0.88111883]\n",
      "  [-0.39455092]\n",
      "  [-0.72805107]]\n",
      "\n",
      " [[-0.32757303]\n",
      "  [-0.90495545]\n",
      "  [-0.7904008 ]\n",
      "  ...\n",
      "  [ 0.43692392]\n",
      "  [-0.909772  ]\n",
      "  [-0.1416482 ]]\n",
      "\n",
      " [[-0.685501  ]\n",
      "  [ 0.8856414 ]\n",
      "  [-0.97723997]\n",
      "  ...\n",
      "  [-0.56250197]\n",
      "  [-0.6664225 ]\n",
      "  [-0.4773735 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.9546038 ]\n",
      "  [-0.75233376]\n",
      "  [-0.94322115]\n",
      "  ...\n",
      "  [-0.1407092 ]\n",
      "  [-0.2698865 ]\n",
      "  [ 0.96878886]]\n",
      "\n",
      " [[ 0.25792268]\n",
      "  [ 0.94405395]\n",
      "  [-0.16886246]\n",
      "  ...\n",
      "  [ 0.96434754]\n",
      "  [ 0.97255164]\n",
      "  [-0.778529  ]]\n",
      "\n",
      " [[ 0.6963518 ]\n",
      "  [ 0.8340601 ]\n",
      "  [-0.06230605]\n",
      "  ...\n",
      "  [-0.256757  ]\n",
      "  [ 0.48797226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [ 0.4873707 ]]]\n",
      "2501 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.193819]\n",
      "2502 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195978]\n",
      "2503 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.212899]\n",
      "2504 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200442]\n",
      "2505 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186031]\n",
      "2506 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.179111]\n",
      "2507 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200768]\n",
      "2508 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191708]\n",
      "2509 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.177763]\n",
      "2510 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183912]\n",
      "2511 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.207017]\n",
      "2512 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191988]\n",
      "2513 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188416]\n",
      "2514 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.177488]\n",
      "2515 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.179557]\n",
      "2516 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.221490]\n",
      "2517 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208639]\n",
      "2518 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179451]\n",
      "2519 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.203592]\n",
      "2520 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.187348]\n",
      "2521 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189899]\n",
      "2522 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.198550]\n",
      "2523 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186511]\n",
      "2524 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.185620]\n",
      "2525 [D loss: 0.000014, acc.: 100.00%] [G loss: 3.209880]\n",
      "2526 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217564]\n",
      "2527 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.199364]\n",
      "2528 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201171]\n",
      "2529 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.168492]\n",
      "2530 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.187459]\n",
      "2531 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.215958]\n",
      "2532 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.207263]\n",
      "2533 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182997]\n",
      "2534 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.217494]\n",
      "2535 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205148]\n",
      "2536 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203059]\n",
      "2537 [D loss: 0.000016, acc.: 100.00%] [G loss: 3.199919]\n",
      "2538 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183681]\n",
      "2539 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.194298]\n",
      "2540 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.188254]\n",
      "2541 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.180826]\n",
      "2542 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185612]\n",
      "2543 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.180144]\n",
      "2544 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.199370]\n",
      "2545 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.198565]\n",
      "2546 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.209403]\n",
      "2547 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194252]\n",
      "2548 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.217578]\n",
      "2549 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.193676]\n",
      "2550 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201729]\n",
      "2551 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196151]\n",
      "2552 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.181908]\n",
      "2553 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190161]\n",
      "2554 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.211884]\n",
      "2555 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190825]\n",
      "2556 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.206257]\n",
      "2557 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.195096]\n",
      "2558 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.186200]\n",
      "2559 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.212012]\n",
      "2560 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.189343]\n",
      "2561 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.219653]\n",
      "2562 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.210033]\n",
      "2563 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.221174]\n",
      "2564 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.211820]\n",
      "2565 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.207513]\n",
      "2566 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175168]\n",
      "2567 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.203387]\n",
      "2568 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209043]\n",
      "2569 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.217721]\n",
      "2570 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.229450]\n",
      "2571 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.223237]\n",
      "2572 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203475]\n",
      "2573 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201584]\n",
      "2574 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.200765]\n",
      "2575 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.225513]\n",
      "2576 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196273]\n",
      "2577 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212085]\n",
      "2578 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210859]\n",
      "2579 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190367]\n",
      "2580 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.188406]\n",
      "2581 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200414]\n",
      "2582 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195861]\n",
      "2583 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188570]\n",
      "2584 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.183679]\n",
      "2585 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.237921]\n",
      "2586 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203806]\n",
      "2587 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.203751]\n",
      "2588 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186221]\n",
      "2589 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192261]\n",
      "2590 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200709]\n",
      "2591 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212849]\n",
      "2592 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.193384]\n",
      "2593 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204779]\n",
      "2594 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.177299]\n",
      "2595 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190289]\n",
      "2596 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.204880]\n",
      "2597 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192924]\n",
      "2598 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195583]\n",
      "2599 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184285]\n",
      "2600 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191656]\n",
      "[[[-0.66093326]\n",
      "  [-0.8411064 ]\n",
      "  [-0.8568938 ]\n",
      "  ...\n",
      "  [-0.8993179 ]\n",
      "  [-0.5575628 ]\n",
      "  [-0.6121341 ]]\n",
      "\n",
      " [[ 0.4840919 ]\n",
      "  [ 0.94020694]\n",
      "  [-0.889302  ]\n",
      "  ...\n",
      "  [ 0.6957551 ]\n",
      "  [-0.9482466 ]\n",
      "  [ 0.4071253 ]]\n",
      "\n",
      " [[ 0.9472731 ]\n",
      "  [-0.09149049]\n",
      "  [ 0.34256142]\n",
      "  ...\n",
      "  [-0.75961465]\n",
      "  [ 0.8735843 ]\n",
      "  [-0.43225473]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.9094686 ]\n",
      "  [-0.71164906]\n",
      "  [-0.926982  ]\n",
      "  ...\n",
      "  [-0.8535445 ]\n",
      "  [-0.48939753]\n",
      "  [ 0.9382725 ]]\n",
      "\n",
      " [[ 0.65111566]\n",
      "  [-0.78093296]\n",
      "  [-0.9202134 ]\n",
      "  ...\n",
      "  [-0.20264691]\n",
      "  [ 0.39332488]\n",
      "  [-0.55387366]]\n",
      "\n",
      " [[ 0.86652935]\n",
      "  [ 0.19501118]\n",
      "  [-0.9656752 ]\n",
      "  ...\n",
      "  [ 0.46045148]\n",
      "  [-0.11101006]\n",
      "  [-0.48094594]]]\n",
      "2601 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203829]\n",
      "2602 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184756]\n",
      "2603 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.167762]\n",
      "2604 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.196892]\n",
      "2605 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192443]\n",
      "2606 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191873]\n",
      "2607 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195061]\n",
      "2608 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.192862]\n",
      "2609 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196085]\n",
      "2610 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182464]\n",
      "2611 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.178143]\n",
      "2612 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204862]\n",
      "2613 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.162110]\n",
      "2614 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.196988]\n",
      "2615 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202177]\n",
      "2616 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.193583]\n",
      "2617 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201077]\n",
      "2618 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.178554]\n",
      "2619 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.189286]\n",
      "2620 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.193914]\n",
      "2621 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205013]\n",
      "2622 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.210618]\n",
      "2623 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.218439]\n",
      "2624 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196744]\n",
      "2625 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.209038]\n",
      "2626 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211815]\n",
      "2627 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205751]\n",
      "2628 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209235]\n",
      "2629 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210205]\n",
      "2630 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.194561]\n",
      "2631 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218547]\n",
      "2632 [D loss: 0.000013, acc.: 100.00%] [G loss: 3.212209]\n",
      "2633 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.212591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2634 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203089]\n",
      "2635 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204380]\n",
      "2636 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196128]\n",
      "2637 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187902]\n",
      "2638 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.227285]\n",
      "2639 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198788]\n",
      "2640 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209276]\n",
      "2641 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.200652]\n",
      "2642 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203062]\n",
      "2643 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.181199]\n",
      "2644 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182795]\n",
      "2645 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185735]\n",
      "2646 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.211598]\n",
      "2647 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200768]\n",
      "2648 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187964]\n",
      "2649 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.191000]\n",
      "2650 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194996]\n",
      "2651 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189363]\n",
      "2652 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190657]\n",
      "2653 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213868]\n",
      "2654 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190228]\n",
      "2655 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.185235]\n",
      "2656 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180964]\n",
      "2657 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.188758]\n",
      "2658 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.194180]\n",
      "2659 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.194394]\n",
      "2660 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.230036]\n",
      "2661 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201530]\n",
      "2662 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180518]\n",
      "2663 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.209441]\n",
      "2664 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187861]\n",
      "2665 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205544]\n",
      "2666 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.217661]\n",
      "2667 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191379]\n",
      "2668 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211455]\n",
      "2669 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190315]\n",
      "2670 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194476]\n",
      "2671 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211184]\n",
      "2672 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.214444]\n",
      "2673 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213235]\n",
      "2674 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.223042]\n",
      "2675 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204183]\n",
      "2676 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.196807]\n",
      "2677 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.229882]\n",
      "2678 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.219059]\n",
      "2679 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196386]\n",
      "2680 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191209]\n",
      "2681 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202196]\n",
      "2682 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207484]\n",
      "2683 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204150]\n",
      "2684 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211128]\n",
      "2685 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211392]\n",
      "2686 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195222]\n",
      "2687 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199147]\n",
      "2688 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194315]\n",
      "2689 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.198881]\n",
      "2690 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.205840]\n",
      "2691 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183847]\n",
      "2692 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.206639]\n",
      "2693 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185958]\n",
      "2694 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206310]\n",
      "2695 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.210923]\n",
      "2696 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206161]\n",
      "2697 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187285]\n",
      "2698 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223786]\n",
      "2699 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.213640]\n",
      "2700 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.224546]\n",
      "[[[-0.93981266]\n",
      "  [-0.93484324]\n",
      "  [-0.9401494 ]\n",
      "  ...\n",
      "  [-0.8902376 ]\n",
      "  [-0.9655176 ]\n",
      "  [-0.38740122]]\n",
      "\n",
      " [[-0.8787941 ]\n",
      "  [-0.8423879 ]\n",
      "  [-0.7856036 ]\n",
      "  ...\n",
      "  [-0.87209094]\n",
      "  [-0.9738082 ]\n",
      "  [ 0.75771904]]\n",
      "\n",
      " [[ 0.4834441 ]\n",
      "  [ 0.04190527]\n",
      "  [ 0.27455044]\n",
      "  ...\n",
      "  [ 0.45825687]\n",
      "  [ 0.4147136 ]\n",
      "  [-0.92200303]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.9869824 ]\n",
      "  [ 0.84897953]\n",
      "  [-0.8867238 ]\n",
      "  ...\n",
      "  [ 0.9552492 ]\n",
      "  [-0.800723  ]\n",
      "  [ 0.5181981 ]]\n",
      "\n",
      " [[ 0.56434125]\n",
      "  [ 0.9442037 ]\n",
      "  [ 0.54044163]\n",
      "  ...\n",
      "  [-0.27118844]\n",
      "  [ 0.9996212 ]\n",
      "  [-0.16595663]]\n",
      "\n",
      " [[-0.05631649]\n",
      "  [ 0.8423526 ]\n",
      "  [-0.37093103]\n",
      "  ...\n",
      "  [-0.5525015 ]\n",
      "  [ 0.21748528]\n",
      "  [ 0.6114503 ]]]\n",
      "2701 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.217917]\n",
      "2702 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.226424]\n",
      "2703 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206689]\n",
      "2704 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.232984]\n",
      "2705 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206833]\n",
      "2706 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205983]\n",
      "2707 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.217370]\n",
      "2708 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.213061]\n",
      "2709 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193878]\n",
      "2710 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217068]\n",
      "2711 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.229285]\n",
      "2712 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226850]\n",
      "2713 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192059]\n",
      "2714 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197691]\n",
      "2715 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.222621]\n",
      "2716 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.237528]\n",
      "2717 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192758]\n",
      "2718 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.207466]\n",
      "2719 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.222994]\n",
      "2720 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.204709]\n",
      "2721 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.209465]\n",
      "2722 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.234534]\n",
      "2723 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.223560]\n",
      "2724 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.211043]\n",
      "2725 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210937]\n",
      "2726 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199379]\n",
      "2727 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208854]\n",
      "2728 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211341]\n",
      "2729 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199196]\n",
      "2730 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207634]\n",
      "2731 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.215019]\n",
      "2732 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.212764]\n",
      "2733 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.207615]\n",
      "2734 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.193995]\n",
      "2735 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203331]\n",
      "2736 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205844]\n",
      "2737 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200052]\n",
      "2738 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210125]\n",
      "2739 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208779]\n",
      "2740 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.220423]\n",
      "2741 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188597]\n",
      "2742 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192247]\n",
      "2743 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.210916]\n",
      "2744 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.203554]\n",
      "2745 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207467]\n",
      "2746 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.197780]\n",
      "2747 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226670]\n",
      "2748 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.212195]\n",
      "2749 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199377]\n",
      "2750 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.216839]\n",
      "2751 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.217976]\n",
      "2752 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211222]\n",
      "2753 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207057]\n",
      "2754 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.208261]\n",
      "2755 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212409]\n",
      "2756 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212087]\n",
      "2757 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.225042]\n",
      "2758 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.217982]\n",
      "2759 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.210763]\n",
      "2760 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197074]\n",
      "2761 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208025]\n",
      "2762 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198142]\n",
      "2763 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210949]\n",
      "2764 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208193]\n",
      "2765 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206415]\n",
      "2766 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211156]\n",
      "2767 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191914]\n",
      "2768 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199034]\n",
      "2769 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2770 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.185116]\n",
      "2771 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.200070]\n",
      "2772 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210196]\n",
      "2773 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222829]\n",
      "2774 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198781]\n",
      "2775 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.213637]\n",
      "2776 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224488]\n",
      "2777 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209823]\n",
      "2778 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210225]\n",
      "2779 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.194876]\n",
      "2780 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188457]\n",
      "2781 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.213454]\n",
      "2782 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196002]\n",
      "2783 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205143]\n",
      "2784 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.200738]\n",
      "2785 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.205898]\n",
      "2786 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.207675]\n",
      "2787 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191008]\n",
      "2788 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193006]\n",
      "2789 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.187536]\n",
      "2790 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186318]\n",
      "2791 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189913]\n",
      "2792 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200665]\n",
      "2793 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.193164]\n",
      "2794 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.191297]\n",
      "2795 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180240]\n",
      "2796 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191480]\n",
      "2797 [D loss: 0.000015, acc.: 100.00%] [G loss: 3.215946]\n",
      "2798 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200565]\n",
      "2799 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.200243]\n",
      "2800 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.218935]\n",
      "[[[-0.7658236 ]\n",
      "  [-0.95418227]\n",
      "  [-0.84584206]\n",
      "  ...\n",
      "  [-0.83097476]\n",
      "  [-0.934703  ]\n",
      "  [-0.14985584]]\n",
      "\n",
      " [[-0.10276672]\n",
      "  [-0.68606687]\n",
      "  [-0.4800774 ]\n",
      "  ...\n",
      "  [-0.848597  ]\n",
      "  [-0.26126182]\n",
      "  [-0.8195534 ]]\n",
      "\n",
      " [[ 0.8460646 ]\n",
      "  [ 0.9971505 ]\n",
      "  [-0.9169313 ]\n",
      "  ...\n",
      "  [ 0.87953687]\n",
      "  [-0.04639921]\n",
      "  [-0.9340609 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.9011448 ]\n",
      "  [-0.2741647 ]\n",
      "  [-0.72538203]\n",
      "  ...\n",
      "  [ 0.7989887 ]\n",
      "  [-0.84899426]\n",
      "  [ 0.910103  ]]\n",
      "\n",
      " [[-0.49624428]\n",
      "  [-0.556514  ]\n",
      "  [-0.5808859 ]\n",
      "  ...\n",
      "  [-0.6499197 ]\n",
      "  [-0.75043726]\n",
      "  [-0.34734386]]\n",
      "\n",
      " [[-0.67817515]\n",
      "  [ 0.31381294]\n",
      "  [-0.9557891 ]\n",
      "  ...\n",
      "  [-0.4966136 ]\n",
      "  [-0.6095582 ]\n",
      "  [-0.49783128]]]\n",
      "2801 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.212181]\n",
      "2802 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.214188]\n",
      "2803 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203456]\n",
      "2804 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.213933]\n",
      "2805 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223433]\n",
      "2806 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.221729]\n",
      "2807 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218127]\n",
      "2808 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.209571]\n",
      "2809 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.231454]\n",
      "2810 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189540]\n",
      "2811 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213258]\n",
      "2812 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215635]\n",
      "2813 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.182692]\n",
      "2814 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218784]\n",
      "2815 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192489]\n",
      "2816 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.202617]\n",
      "2817 [D loss: 0.000011, acc.: 100.00%] [G loss: 3.172688]\n",
      "2818 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207843]\n",
      "2819 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191091]\n",
      "2820 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222348]\n",
      "2821 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.228266]\n",
      "2822 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224573]\n",
      "2823 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.235163]\n",
      "2824 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208180]\n",
      "2825 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.229449]\n",
      "2826 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194172]\n",
      "2827 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202063]\n",
      "2828 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203711]\n",
      "2829 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228081]\n",
      "2830 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208452]\n",
      "2831 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205269]\n",
      "2832 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212751]\n",
      "2833 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184258]\n",
      "2834 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221118]\n",
      "2835 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213814]\n",
      "2836 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195372]\n",
      "2837 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208422]\n",
      "2838 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.178823]\n",
      "2839 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194245]\n",
      "2840 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186288]\n",
      "2841 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.187283]\n",
      "2842 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.207124]\n",
      "2843 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203283]\n",
      "2844 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191730]\n",
      "2845 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.209177]\n",
      "2846 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203979]\n",
      "2847 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210863]\n",
      "2848 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205934]\n",
      "2849 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204975]\n",
      "2850 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206263]\n",
      "2851 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.203823]\n",
      "2852 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206076]\n",
      "2853 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193261]\n",
      "2854 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207940]\n",
      "2855 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188269]\n",
      "2856 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.194420]\n",
      "2857 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187434]\n",
      "2858 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183794]\n",
      "2859 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206147]\n",
      "2860 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202119]\n",
      "2861 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189825]\n",
      "2862 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.199997]\n",
      "2863 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195278]\n",
      "2864 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.211309]\n",
      "2865 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.192400]\n",
      "2866 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200692]\n",
      "2867 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.200984]\n",
      "2868 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208849]\n",
      "2869 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.214447]\n",
      "2870 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226180]\n",
      "2871 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.207807]\n",
      "2872 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201325]\n",
      "2873 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209076]\n",
      "2874 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218151]\n",
      "2875 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.217431]\n",
      "2876 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196092]\n",
      "2877 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204674]\n",
      "2878 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216247]\n",
      "2879 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201727]\n",
      "2880 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202955]\n",
      "2881 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199460]\n",
      "2882 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.227743]\n",
      "2883 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214925]\n",
      "2884 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227641]\n",
      "2885 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213140]\n",
      "2886 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.202086]\n",
      "2887 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.200280]\n",
      "2888 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199421]\n",
      "2889 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209178]\n",
      "2890 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.211307]\n",
      "2891 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204836]\n",
      "2892 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196280]\n",
      "2893 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.225873]\n",
      "2894 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192149]\n",
      "2895 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.230795]\n",
      "2896 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215564]\n",
      "2897 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.189200]\n",
      "2898 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.211982]\n",
      "2899 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203489]\n",
      "2900 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.214292]\n",
      "[[[-0.5695118 ]\n",
      "  [-0.90233004]\n",
      "  [-0.92485917]\n",
      "  ...\n",
      "  [-0.8409266 ]\n",
      "  [-0.9301287 ]\n",
      "  [ 0.07480738]]\n",
      "\n",
      " [[-0.40369302]\n",
      "  [-0.01315273]\n",
      "  [-0.871284  ]\n",
      "  ...\n",
      "  [ 0.9405746 ]\n",
      "  [-0.9222317 ]\n",
      "  [ 0.32019117]]\n",
      "\n",
      " [[ 0.93771386]\n",
      "  [-0.8512634 ]\n",
      "  [-0.740293  ]\n",
      "  ...\n",
      "  [-0.6158887 ]\n",
      "  [ 0.9863747 ]\n",
      "  [-0.92798555]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.7107577 ]\n",
      "  [-0.18776454]\n",
      "  [-0.8857017 ]\n",
      "  ...\n",
      "  [ 0.04645357]\n",
      "  [ 0.5501973 ]\n",
      "  [ 0.603263  ]]\n",
      "\n",
      " [[-0.11048064]\n",
      "  [ 0.9168915 ]\n",
      "  [-0.9297865 ]\n",
      "  ...\n",
      "  [ 0.8590144 ]\n",
      "  [ 0.9494858 ]\n",
      "  [-0.6469923 ]]\n",
      "\n",
      " [[ 0.7137741 ]\n",
      "  [ 0.6963316 ]\n",
      "  [-0.5006014 ]\n",
      "  ...\n",
      "  [-0.01895358]\n",
      "  [-0.7101556 ]\n",
      "  [ 0.8896692 ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2901 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201323]\n",
      "2902 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192779]\n",
      "2903 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195794]\n",
      "2904 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217929]\n",
      "2905 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202468]\n",
      "2906 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226292]\n",
      "2907 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.225201]\n",
      "2908 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223150]\n",
      "2909 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202243]\n",
      "2910 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198514]\n",
      "2911 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202708]\n",
      "2912 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208532]\n",
      "2913 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214718]\n",
      "2914 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203689]\n",
      "2915 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.207567]\n",
      "2916 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204674]\n",
      "2917 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.209031]\n",
      "2918 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188350]\n",
      "2919 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212633]\n",
      "2920 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.200527]\n",
      "2921 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190371]\n",
      "2922 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183231]\n",
      "2923 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.190062]\n",
      "2924 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195685]\n",
      "2925 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.193390]\n",
      "2926 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208797]\n",
      "2927 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197212]\n",
      "2928 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.181605]\n",
      "2929 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207261]\n",
      "2930 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223748]\n",
      "2931 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209985]\n",
      "2932 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192468]\n",
      "2933 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.213571]\n",
      "2934 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.194600]\n",
      "2935 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208753]\n",
      "2936 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.181117]\n",
      "2937 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.199570]\n",
      "2938 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196341]\n",
      "2939 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.202296]\n",
      "2940 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.208717]\n",
      "2941 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209816]\n",
      "2942 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201669]\n",
      "2943 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195660]\n",
      "2944 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222218]\n",
      "2945 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195050]\n",
      "2946 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.212405]\n",
      "2947 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221334]\n",
      "2948 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207878]\n",
      "2949 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199548]\n",
      "2950 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205785]\n",
      "2951 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184801]\n",
      "2952 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.195302]\n",
      "2953 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214880]\n",
      "2954 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182751]\n",
      "2955 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.194352]\n",
      "2956 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204123]\n",
      "2957 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205846]\n",
      "2958 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203748]\n",
      "2959 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.254646]\n",
      "2960 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.215865]\n",
      "2961 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202696]\n",
      "2962 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.227418]\n",
      "2963 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199161]\n",
      "2964 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209934]\n",
      "2965 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.230525]\n",
      "2966 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223000]\n",
      "2967 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216504]\n",
      "2968 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195142]\n",
      "2969 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203560]\n",
      "2970 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.207101]\n",
      "2971 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214019]\n",
      "2972 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.216806]\n",
      "2973 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207666]\n",
      "2974 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219291]\n",
      "2975 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.210284]\n",
      "2976 [D loss: 0.000012, acc.: 100.00%] [G loss: 3.229597]\n",
      "2977 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.216987]\n",
      "2978 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.206083]\n",
      "2979 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.221704]\n",
      "2980 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224738]\n",
      "2981 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213596]\n",
      "2982 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.206326]\n",
      "2983 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.216811]\n",
      "2984 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206995]\n",
      "2985 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189406]\n",
      "2986 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.193856]\n",
      "2987 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207970]\n",
      "2988 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.194696]\n",
      "2989 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210234]\n",
      "2990 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201657]\n",
      "2991 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210297]\n",
      "2992 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.225304]\n",
      "2993 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.214264]\n",
      "2994 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210983]\n",
      "2995 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.215946]\n",
      "2996 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.208463]\n",
      "2997 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.210296]\n",
      "2998 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.215356]\n",
      "2999 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.197594]\n",
      "3000 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200701]\n",
      "[[[-0.91246855]\n",
      "  [-0.92540824]\n",
      "  [-0.9266575 ]\n",
      "  ...\n",
      "  [-0.96525854]\n",
      "  [-0.9048752 ]\n",
      "  [-0.8870574 ]]\n",
      "\n",
      " [[-0.93779516]\n",
      "  [-0.27776727]\n",
      "  [-0.95407647]\n",
      "  ...\n",
      "  [-0.53463745]\n",
      "  [-0.96099734]\n",
      "  [ 0.7315602 ]]\n",
      "\n",
      " [[ 0.06067749]\n",
      "  [-0.18464325]\n",
      "  [-0.7669016 ]\n",
      "  ...\n",
      "  [-0.8303652 ]\n",
      "  [ 0.7032651 ]\n",
      "  [ 0.42457902]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.9558567 ]\n",
      "  [-0.5394175 ]\n",
      "  [-0.8881561 ]\n",
      "  ...\n",
      "  [ 0.28233173]\n",
      "  [-0.9035119 ]\n",
      "  [ 0.93795663]]\n",
      "\n",
      " [[-0.4349869 ]\n",
      "  [-0.9069066 ]\n",
      "  [-0.900887  ]\n",
      "  ...\n",
      "  [ 0.8671552 ]\n",
      "  [-0.03208202]\n",
      "  [ 0.04378825]]\n",
      "\n",
      " [[-0.29666397]\n",
      "  [ 0.5792208 ]\n",
      "  [-0.9721646 ]\n",
      "  ...\n",
      "  [ 0.16941872]\n",
      "  [-0.86591184]\n",
      "  [-0.05993085]]]\n",
      "3001 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.197110]\n",
      "3002 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.202968]\n",
      "3003 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211218]\n",
      "3004 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188178]\n",
      "3005 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185313]\n",
      "3006 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.193150]\n",
      "3007 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203559]\n",
      "3008 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228419]\n",
      "3009 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.211247]\n",
      "3010 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.196824]\n",
      "3011 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206598]\n",
      "3012 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.240332]\n",
      "3013 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217779]\n",
      "3014 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.220668]\n",
      "3015 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.201689]\n",
      "3016 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195532]\n",
      "3017 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.218455]\n",
      "3018 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199653]\n",
      "3019 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.206501]\n",
      "3020 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213603]\n",
      "3021 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.207297]\n",
      "3022 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218835]\n",
      "3023 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211959]\n",
      "3024 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.204847]\n",
      "3025 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201035]\n",
      "3026 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.224442]\n",
      "3027 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200412]\n",
      "3028 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191183]\n",
      "3029 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205514]\n",
      "3030 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.204655]\n",
      "3031 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199101]\n",
      "3032 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201540]\n",
      "3033 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.218133]\n",
      "3034 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212633]\n",
      "3035 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.223053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.235054]\n",
      "3037 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.236413]\n",
      "3038 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196089]\n",
      "3039 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190028]\n",
      "3040 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.213167]\n",
      "3041 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198802]\n",
      "3042 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201578]\n",
      "3043 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208350]\n",
      "3044 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.238556]\n",
      "3045 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.208647]\n",
      "3046 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203420]\n",
      "3047 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205683]\n",
      "3048 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.187285]\n",
      "3049 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207616]\n",
      "3050 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.173944]\n",
      "3051 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.215274]\n",
      "3052 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.195590]\n",
      "3053 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209043]\n",
      "3054 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189854]\n",
      "3055 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200068]\n",
      "3056 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198692]\n",
      "3057 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.191825]\n",
      "3058 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184539]\n",
      "3059 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194474]\n",
      "3060 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180813]\n",
      "3061 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.193567]\n",
      "3062 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212624]\n",
      "3063 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187922]\n",
      "3064 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194844]\n",
      "3065 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.178926]\n",
      "3066 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206772]\n",
      "3067 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197829]\n",
      "3068 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206761]\n",
      "3069 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.189228]\n",
      "3070 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201965]\n",
      "3071 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201579]\n",
      "3072 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203025]\n",
      "3073 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213910]\n",
      "3074 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.230831]\n",
      "3075 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219380]\n",
      "3076 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198872]\n",
      "3077 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.203813]\n",
      "3078 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187524]\n",
      "3079 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214716]\n",
      "3080 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214407]\n",
      "3081 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.218246]\n",
      "3082 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.199019]\n",
      "3083 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.234778]\n",
      "3084 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.220070]\n",
      "3085 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215519]\n",
      "3086 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220369]\n",
      "3087 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.201789]\n",
      "3088 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193609]\n",
      "3089 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208085]\n",
      "3090 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189062]\n",
      "3091 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219760]\n",
      "3092 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195562]\n",
      "3093 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207716]\n",
      "3094 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211110]\n",
      "3095 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.198563]\n",
      "3096 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212931]\n",
      "3097 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.189849]\n",
      "3098 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212587]\n",
      "3099 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.221628]\n",
      "3100 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216234]\n",
      "[[[-0.39693272]\n",
      "  [-0.9358056 ]\n",
      "  [-0.9235388 ]\n",
      "  ...\n",
      "  [-0.9780759 ]\n",
      "  [-0.9000566 ]\n",
      "  [-0.772877  ]]\n",
      "\n",
      " [[-0.7808496 ]\n",
      "  [-0.83866304]\n",
      "  [-0.9406215 ]\n",
      "  ...\n",
      "  [ 0.51225924]\n",
      "  [-0.94012266]\n",
      "  [-0.844544  ]]\n",
      "\n",
      " [[ 0.75895923]\n",
      "  [-0.8803083 ]\n",
      "  [-0.87571216]\n",
      "  ...\n",
      "  [ 0.8632442 ]\n",
      "  [ 0.778699  ]\n",
      "  [ 0.40317738]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.93895185]\n",
      "  [ 0.96804816]\n",
      "  [-0.9300305 ]\n",
      "  ...\n",
      "  [-0.4566501 ]\n",
      "  [-0.92841196]\n",
      "  [ 0.9889303 ]]\n",
      "\n",
      " [[ 0.8147087 ]\n",
      "  [-0.6252055 ]\n",
      "  [-0.77907664]\n",
      "  ...\n",
      "  [-0.82729053]\n",
      "  [ 0.7548298 ]\n",
      "  [-0.5346725 ]]\n",
      "\n",
      " [[ 0.38339946]\n",
      "  [-0.7179706 ]\n",
      "  [-0.930614  ]\n",
      "  ...\n",
      "  [ 0.66113704]\n",
      "  [-0.8981444 ]\n",
      "  [ 0.45925567]]]\n",
      "3101 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.213832]\n",
      "3102 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196741]\n",
      "3103 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.202392]\n",
      "3104 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217738]\n",
      "3105 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.215207]\n",
      "3106 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195781]\n",
      "3107 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.192203]\n",
      "3108 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190103]\n",
      "3109 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.206569]\n",
      "3110 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212659]\n",
      "3111 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216388]\n",
      "3112 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222568]\n",
      "3113 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179975]\n",
      "3114 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183112]\n",
      "3115 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200403]\n",
      "3116 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199275]\n",
      "3117 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201793]\n",
      "3118 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.175354]\n",
      "3119 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193884]\n",
      "3120 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.178346]\n",
      "3121 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.203566]\n",
      "3122 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195452]\n",
      "3123 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213367]\n",
      "3124 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184301]\n",
      "3125 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.177403]\n",
      "3126 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206241]\n",
      "3127 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.193812]\n",
      "3128 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193075]\n",
      "3129 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.184678]\n",
      "3130 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.184215]\n",
      "3131 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.218234]\n",
      "3132 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195806]\n",
      "3133 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202138]\n",
      "3134 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.188767]\n",
      "3135 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.171630]\n",
      "3136 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175024]\n",
      "3137 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201138]\n",
      "3138 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186342]\n",
      "3139 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175747]\n",
      "3140 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.177835]\n",
      "3141 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.197168]\n",
      "3142 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.177033]\n",
      "3143 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188689]\n",
      "3144 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190532]\n",
      "3145 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182760]\n",
      "3146 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194119]\n",
      "3147 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.152476]\n",
      "3148 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182491]\n",
      "3149 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.179424]\n",
      "3150 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.182920]\n",
      "3151 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.179326]\n",
      "3152 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191808]\n",
      "3153 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187758]\n",
      "3154 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199453]\n",
      "3155 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193941]\n",
      "3156 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188661]\n",
      "3157 [D loss: 0.000008, acc.: 100.00%] [G loss: 3.194481]\n",
      "3158 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203601]\n",
      "3159 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202048]\n",
      "3160 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.205308]\n",
      "3161 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201123]\n",
      "3162 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201298]\n",
      "3163 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183104]\n",
      "3164 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183988]\n",
      "3165 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.205575]\n",
      "3166 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202296]\n",
      "3167 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.181630]\n",
      "3168 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197534]\n",
      "3169 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204438]\n",
      "3170 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194475]\n",
      "3171 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3172 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.184346]\n",
      "3173 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.199152]\n",
      "3174 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175974]\n",
      "3175 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207461]\n",
      "3176 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.179286]\n",
      "3177 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.184111]\n",
      "3178 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207246]\n",
      "3179 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.198501]\n",
      "3180 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208438]\n",
      "3181 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.207944]\n",
      "3182 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194842]\n",
      "3183 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210021]\n",
      "3184 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190910]\n",
      "3185 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188758]\n",
      "3186 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196422]\n",
      "3187 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198514]\n",
      "3188 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.197040]\n",
      "3189 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190938]\n",
      "3190 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187821]\n",
      "3191 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.198705]\n",
      "3192 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182321]\n",
      "3193 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187200]\n",
      "3194 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.181260]\n",
      "3195 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.207091]\n",
      "3196 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.187251]\n",
      "3197 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.190322]\n",
      "3198 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.170127]\n",
      "3199 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180864]\n",
      "3200 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.185627]\n",
      "[[[-8.0501923e-04]\n",
      "  [-8.8253808e-01]\n",
      "  [-8.6777443e-01]\n",
      "  ...\n",
      "  [-9.8687905e-01]\n",
      "  [-8.1504442e-02]\n",
      "  [-9.6391964e-01]]\n",
      "\n",
      " [[-3.6860085e-01]\n",
      "  [ 3.2903692e-01]\n",
      "  [-4.5114410e-01]\n",
      "  ...\n",
      "  [ 9.1134137e-01]\n",
      "  [-8.1211007e-01]\n",
      "  [ 9.7316039e-01]]\n",
      "\n",
      " [[ 5.8680940e-01]\n",
      "  [ 8.4658539e-01]\n",
      "  [-9.6831870e-01]\n",
      "  ...\n",
      "  [-1.5971811e-01]\n",
      "  [ 9.7183573e-01]\n",
      "  [-4.6338645e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.1093972e-01]\n",
      "  [-5.5774200e-01]\n",
      "  [-9.6795714e-01]\n",
      "  ...\n",
      "  [-9.0245068e-01]\n",
      "  [-5.4708815e-01]\n",
      "  [ 9.1305476e-01]]\n",
      "\n",
      " [[ 3.5447696e-01]\n",
      "  [-6.8806231e-01]\n",
      "  [ 1.7487463e-01]\n",
      "  ...\n",
      "  [ 9.9970806e-01]\n",
      "  [-8.5834038e-01]\n",
      "  [-6.2504745e-01]]\n",
      "\n",
      " [[-5.8142865e-01]\n",
      "  [ 9.8861247e-01]\n",
      "  [-8.7602949e-01]\n",
      "  ...\n",
      "  [-2.5622147e-01]\n",
      "  [ 2.3580281e-01]\n",
      "  [ 1.5105750e-01]]]\n",
      "3201 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187472]\n",
      "3202 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.177975]\n",
      "3203 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.194829]\n",
      "3204 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204289]\n",
      "3205 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197413]\n",
      "3206 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175618]\n",
      "3207 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218042]\n",
      "3208 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223440]\n",
      "3209 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.181661]\n",
      "3210 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206448]\n",
      "3211 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205315]\n",
      "3212 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194536]\n",
      "3213 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191517]\n",
      "3214 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213238]\n",
      "3215 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202016]\n",
      "3216 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203689]\n",
      "3217 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.191772]\n",
      "3218 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185335]\n",
      "3219 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202429]\n",
      "3220 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202295]\n",
      "3221 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205105]\n",
      "3222 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189604]\n",
      "3223 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.197797]\n",
      "3224 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195214]\n",
      "3225 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208827]\n",
      "3226 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198019]\n",
      "3227 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180689]\n",
      "3228 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.211055]\n",
      "3229 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.188477]\n",
      "3230 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197802]\n",
      "3231 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191374]\n",
      "3232 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211657]\n",
      "3233 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211256]\n",
      "3234 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.224083]\n",
      "3235 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196678]\n",
      "3236 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223094]\n",
      "3237 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209711]\n",
      "3238 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.218277]\n",
      "3239 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214268]\n",
      "3240 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200015]\n",
      "3241 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.203434]\n",
      "3242 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.182577]\n",
      "3243 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208754]\n",
      "3244 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194829]\n",
      "3245 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186329]\n",
      "3246 [D loss: 0.000017, acc.: 100.00%] [G loss: 3.219077]\n",
      "3247 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200159]\n",
      "3248 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206584]\n",
      "3249 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206683]\n",
      "3250 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.220765]\n",
      "3251 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197484]\n",
      "3252 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203764]\n",
      "3253 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214369]\n",
      "3254 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190166]\n",
      "3255 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205640]\n",
      "3256 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.199468]\n",
      "3257 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.208002]\n",
      "3258 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199278]\n",
      "3259 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175700]\n",
      "3260 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188237]\n",
      "3261 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182091]\n",
      "3262 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.214864]\n",
      "3263 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.174117]\n",
      "3264 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192248]\n",
      "3265 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215123]\n",
      "3266 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202090]\n",
      "3267 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201531]\n",
      "3268 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182261]\n",
      "3269 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191451]\n",
      "3270 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186378]\n",
      "3271 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201586]\n",
      "3272 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.218230]\n",
      "3273 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192358]\n",
      "3274 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215127]\n",
      "3275 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216072]\n",
      "3276 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.216398]\n",
      "3277 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208438]\n",
      "3278 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211151]\n",
      "3279 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.215928]\n",
      "3280 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218498]\n",
      "3281 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204603]\n",
      "3282 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.224652]\n",
      "3283 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212922]\n",
      "3284 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212086]\n",
      "3285 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210938]\n",
      "3286 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206355]\n",
      "3287 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.215105]\n",
      "3288 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.201820]\n",
      "3289 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.211328]\n",
      "3290 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.196677]\n",
      "3291 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201444]\n",
      "3292 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207118]\n",
      "3293 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.189594]\n",
      "3294 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.209553]\n",
      "3295 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195268]\n",
      "3296 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.204340]\n",
      "3297 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228724]\n",
      "3298 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.196772]\n",
      "3299 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204413]\n",
      "3300 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227732]\n",
      "[[[ 0.23000902]\n",
      "  [-0.8738399 ]\n",
      "  [-0.9006078 ]\n",
      "  ...\n",
      "  [-0.9397314 ]\n",
      "  [-0.9387269 ]\n",
      "  [-0.8225361 ]]\n",
      "\n",
      " [[-0.63392335]\n",
      "  [-0.9657134 ]\n",
      "  [-0.6147014 ]\n",
      "  ...\n",
      "  [ 0.16013874]\n",
      "  [-0.93180406]\n",
      "  [-0.24229637]]\n",
      "\n",
      " [[-0.5296166 ]\n",
      "  [-0.05473033]\n",
      "  [-0.9321097 ]\n",
      "  ...\n",
      "  [ 0.7070162 ]\n",
      "  [ 0.9973586 ]\n",
      "  [-0.9032737 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.39068228]\n",
      "  [-0.72098184]\n",
      "  [-0.86148   ]\n",
      "  ...\n",
      "  [ 0.948714  ]\n",
      "  [-0.9783758 ]\n",
      "  [ 0.30700782]]\n",
      "\n",
      " [[-0.56672895]\n",
      "  [ 0.03027271]\n",
      "  [-0.8477759 ]\n",
      "  ...\n",
      "  [-0.845129  ]\n",
      "  [-0.24604455]\n",
      "  [-0.6860831 ]]\n",
      "\n",
      " [[ 0.69441783]\n",
      "  [ 0.7335236 ]\n",
      "  [-0.4477364 ]\n",
      "  ...\n",
      "  [-0.08063256]\n",
      "  [-0.6872598 ]\n",
      "  [-0.43961886]]]\n",
      "3301 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192113]\n",
      "3302 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.196009]\n",
      "3303 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204585]\n",
      "3304 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211896]\n",
      "3305 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214863]\n",
      "3306 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.196978]\n",
      "3307 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203753]\n",
      "3308 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192029]\n",
      "3309 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212431]\n",
      "3310 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.212341]\n",
      "3311 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204803]\n",
      "3312 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.199444]\n",
      "3313 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213724]\n",
      "3314 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182543]\n",
      "3315 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190817]\n",
      "3316 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189350]\n",
      "3317 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.175361]\n",
      "3318 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197413]\n",
      "3319 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.187629]\n",
      "3320 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195081]\n",
      "3321 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.204548]\n",
      "3322 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209671]\n",
      "3323 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191691]\n",
      "3324 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.199478]\n",
      "3325 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204650]\n",
      "3326 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.199039]\n",
      "3327 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193384]\n",
      "3328 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201913]\n",
      "3329 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206322]\n",
      "3330 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189002]\n",
      "3331 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.192509]\n",
      "3332 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205676]\n",
      "3333 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198099]\n",
      "3334 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.190897]\n",
      "3335 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216554]\n",
      "3336 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202931]\n",
      "3337 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.211751]\n",
      "3338 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201952]\n",
      "3339 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199236]\n",
      "3340 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193399]\n",
      "3341 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.174307]\n",
      "3342 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.189098]\n",
      "3343 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.180104]\n",
      "3344 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.182989]\n",
      "3345 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.162666]\n",
      "3346 [D loss: 0.000007, acc.: 100.00%] [G loss: 3.190682]\n",
      "3347 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.194436]\n",
      "3348 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.219788]\n",
      "3349 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199507]\n",
      "3350 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.208199]\n",
      "3351 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.198531]\n",
      "3352 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204619]\n",
      "3353 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.221503]\n",
      "3354 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193337]\n",
      "3355 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.204293]\n",
      "3356 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.183671]\n",
      "3357 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.197765]\n",
      "3358 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224840]\n",
      "3359 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220470]\n",
      "3360 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206433]\n",
      "3361 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210557]\n",
      "3362 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.204944]\n",
      "3363 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.190928]\n",
      "3364 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223816]\n",
      "3365 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201368]\n",
      "3366 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196667]\n",
      "3367 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.200015]\n",
      "3368 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202352]\n",
      "3369 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206766]\n",
      "3370 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.193942]\n",
      "3371 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.185686]\n",
      "3372 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210701]\n",
      "3373 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221698]\n",
      "3374 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.184072]\n",
      "3375 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.188601]\n",
      "3376 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.209750]\n",
      "3377 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198341]\n",
      "3378 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213975]\n",
      "3379 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.194957]\n",
      "3380 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.173621]\n",
      "3381 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197341]\n",
      "3382 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207147]\n",
      "3383 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.195076]\n",
      "3384 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186107]\n",
      "3385 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206136]\n",
      "3386 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.179001]\n",
      "3387 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.200766]\n",
      "3388 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197273]\n",
      "3389 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200738]\n",
      "3390 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.196037]\n",
      "3391 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.189870]\n",
      "3392 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.189929]\n",
      "3393 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183679]\n",
      "3394 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.206261]\n",
      "3395 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210368]\n",
      "3396 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198871]\n",
      "3397 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212473]\n",
      "3398 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210341]\n",
      "3399 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.193848]\n",
      "3400 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203171]\n",
      "[[[ 0.71276975]\n",
      "  [-0.9634004 ]\n",
      "  [-0.9367511 ]\n",
      "  ...\n",
      "  [-0.946329  ]\n",
      "  [-0.7775606 ]\n",
      "  [-0.94970775]]\n",
      "\n",
      " [[ 0.48133168]\n",
      "  [-0.8149303 ]\n",
      "  [-0.6929543 ]\n",
      "  ...\n",
      "  [ 0.18818966]\n",
      "  [-0.68240577]\n",
      "  [ 0.96427846]]\n",
      "\n",
      " [[ 0.02052928]\n",
      "  [ 0.9978898 ]\n",
      "  [-0.9477455 ]\n",
      "  ...\n",
      "  [ 0.9241671 ]\n",
      "  [ 0.9976055 ]\n",
      "  [-0.8864981 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.27108485]\n",
      "  [-0.3852363 ]\n",
      "  [-0.9442967 ]\n",
      "  ...\n",
      "  [ 0.30748373]\n",
      "  [-0.95779186]\n",
      "  [ 0.9486862 ]]\n",
      "\n",
      " [[ 0.74636894]\n",
      "  [-0.6805377 ]\n",
      "  [-0.83455014]\n",
      "  ...\n",
      "  [ 0.7800484 ]\n",
      "  [-0.8831712 ]\n",
      "  [-0.4336888 ]]\n",
      "\n",
      " [[-0.19819908]\n",
      "  [ 0.6907439 ]\n",
      "  [-0.39086607]\n",
      "  ...\n",
      "  [-0.64427656]\n",
      "  [ 0.28270143]\n",
      "  [-0.8639286 ]]]\n",
      "3401 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203413]\n",
      "3402 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.216032]\n",
      "3403 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231371]\n",
      "3404 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205491]\n",
      "3405 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206269]\n",
      "3406 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231566]\n",
      "3407 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197975]\n",
      "3408 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215047]\n",
      "3409 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.202105]\n",
      "3410 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207280]\n",
      "3411 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198530]\n",
      "3412 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.210738]\n",
      "3413 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.209098]\n",
      "3414 [D loss: 0.000006, acc.: 100.00%] [G loss: 3.223884]\n",
      "3415 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210332]\n",
      "3416 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186024]\n",
      "3417 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.207817]\n",
      "3418 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228043]\n",
      "3419 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.194378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.212183]\n",
      "3421 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216256]\n",
      "3422 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.235300]\n",
      "3423 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.221238]\n",
      "3424 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.186428]\n",
      "3425 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.215024]\n",
      "3426 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.198654]\n",
      "3427 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217518]\n",
      "3428 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215654]\n",
      "3429 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210753]\n",
      "3430 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199876]\n",
      "3431 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.192605]\n",
      "3432 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224686]\n",
      "3433 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210526]\n",
      "3434 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.185975]\n",
      "3435 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.188767]\n",
      "3436 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204384]\n",
      "3437 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226422]\n",
      "3438 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213091]\n",
      "3439 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210264]\n",
      "3440 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212046]\n",
      "3441 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193899]\n",
      "3442 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208012]\n",
      "3443 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207235]\n",
      "3444 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211971]\n",
      "3445 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.215094]\n",
      "3446 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.204298]\n",
      "3447 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212844]\n",
      "3448 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211547]\n",
      "3449 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198548]\n",
      "3450 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.183082]\n",
      "3451 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227532]\n",
      "3452 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.192058]\n",
      "3453 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213740]\n",
      "3454 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.195986]\n",
      "3455 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213521]\n",
      "3456 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214800]\n",
      "3457 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.225523]\n",
      "3458 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200239]\n",
      "3459 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.196906]\n",
      "3460 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.183330]\n",
      "3461 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.198908]\n",
      "3462 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.195275]\n",
      "3463 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197852]\n",
      "3464 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224106]\n",
      "3465 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202413]\n",
      "3466 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193544]\n",
      "3467 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199886]\n",
      "3468 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.205792]\n",
      "3469 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.209853]\n",
      "3470 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224635]\n",
      "3471 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207656]\n",
      "3472 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.178456]\n",
      "3473 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206085]\n",
      "3474 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210915]\n",
      "3475 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.189237]\n",
      "3476 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193462]\n",
      "3477 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.192829]\n",
      "3478 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187436]\n",
      "3479 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.199126]\n",
      "3480 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199365]\n",
      "3481 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211965]\n",
      "3482 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.196590]\n",
      "3483 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224322]\n",
      "3484 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214203]\n",
      "3485 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226756]\n",
      "3486 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.225083]\n",
      "3487 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.209449]\n",
      "3488 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.190743]\n",
      "3489 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207813]\n",
      "3490 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.192350]\n",
      "3491 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216264]\n",
      "3492 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.190179]\n",
      "3493 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208237]\n",
      "3494 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.211435]\n",
      "3495 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210522]\n",
      "3496 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.204524]\n",
      "3497 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.220449]\n",
      "3498 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212691]\n",
      "3499 [D loss: 0.000009, acc.: 100.00%] [G loss: 3.195208]\n",
      "3500 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193818]\n",
      "[[[-0.89307904]\n",
      "  [-0.94158196]\n",
      "  [-0.79009473]\n",
      "  ...\n",
      "  [-0.9460786 ]\n",
      "  [-0.63118804]\n",
      "  [-0.9240479 ]]\n",
      "\n",
      " [[-0.8820576 ]\n",
      "  [ 0.8802783 ]\n",
      "  [-0.84779197]\n",
      "  ...\n",
      "  [ 0.62212235]\n",
      "  [-0.960099  ]\n",
      "  [ 0.99901813]]\n",
      "\n",
      " [[ 0.9826913 ]\n",
      "  [ 0.8461865 ]\n",
      "  [-0.90313375]\n",
      "  ...\n",
      "  [ 0.5859969 ]\n",
      "  [ 0.9867003 ]\n",
      "  [-0.121805  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.8891444 ]\n",
      "  [-0.65391195]\n",
      "  [-0.92881006]\n",
      "  ...\n",
      "  [-0.93649375]\n",
      "  [-0.9374228 ]\n",
      "  [ 0.9463652 ]]\n",
      "\n",
      " [[ 0.15944582]\n",
      "  [-0.7751834 ]\n",
      "  [-0.59062016]\n",
      "  ...\n",
      "  [ 0.4663354 ]\n",
      "  [ 0.04551721]\n",
      "  [ 0.5930655 ]]\n",
      "\n",
      " [[ 0.749881  ]\n",
      "  [ 0.86664104]\n",
      "  [-0.54943645]\n",
      "  ...\n",
      "  [ 0.3478577 ]\n",
      "  [ 0.27795655]\n",
      "  [-0.6261507 ]]]\n",
      "3501 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.243588]\n",
      "3502 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223161]\n",
      "3503 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228440]\n",
      "3504 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210474]\n",
      "3505 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.188052]\n",
      "3506 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.223702]\n",
      "3507 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224250]\n",
      "3508 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.219154]\n",
      "3509 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217566]\n",
      "3510 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.196529]\n",
      "3511 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187639]\n",
      "3512 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216623]\n",
      "3513 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.211216]\n",
      "3514 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226610]\n",
      "3515 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211988]\n",
      "3516 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.195563]\n",
      "3517 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209787]\n",
      "3518 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.215440]\n",
      "3519 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224460]\n",
      "3520 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.219017]\n",
      "3521 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212516]\n",
      "3522 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.188369]\n",
      "3523 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201586]\n",
      "3524 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.197515]\n",
      "3525 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.209199]\n",
      "3526 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202711]\n",
      "3527 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.199926]\n",
      "3528 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.211852]\n",
      "3529 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222598]\n",
      "3530 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201390]\n",
      "3531 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.201204]\n",
      "3532 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.201455]\n",
      "3533 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206083]\n",
      "3534 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204293]\n",
      "3535 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.187996]\n",
      "3536 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226298]\n",
      "3537 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226030]\n",
      "3538 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203411]\n",
      "3539 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.215488]\n",
      "3540 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.203670]\n",
      "3541 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219991]\n",
      "3542 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204569]\n",
      "3543 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206203]\n",
      "3544 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221264]\n",
      "3545 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.196730]\n",
      "3546 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.236044]\n",
      "3547 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207257]\n",
      "3548 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207878]\n",
      "3549 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.191730]\n",
      "3550 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.230544]\n",
      "3551 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.198456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.195689]\n",
      "3553 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204834]\n",
      "3554 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219995]\n",
      "3555 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.233949]\n",
      "3556 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.229619]\n",
      "3557 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226418]\n",
      "3558 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224869]\n",
      "3559 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.229846]\n",
      "3560 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.212841]\n",
      "3561 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223279]\n",
      "3562 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.228235]\n",
      "3563 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.222577]\n",
      "3564 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227724]\n",
      "3565 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218344]\n",
      "3566 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.235602]\n",
      "3567 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222768]\n",
      "3568 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.234826]\n",
      "3569 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.228260]\n",
      "3570 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.205538]\n",
      "3571 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.200919]\n",
      "3572 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212286]\n",
      "3573 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.250252]\n",
      "3574 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.216093]\n",
      "3575 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223229]\n",
      "3576 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.231545]\n",
      "3577 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231881]\n",
      "3578 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.234462]\n",
      "3579 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.222479]\n",
      "3580 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.225619]\n",
      "3581 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210069]\n",
      "3582 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204440]\n",
      "3583 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208983]\n",
      "3584 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.228944]\n",
      "3585 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.189206]\n",
      "3586 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.210438]\n",
      "3587 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.230266]\n",
      "3588 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220387]\n",
      "3589 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.248513]\n",
      "3590 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216835]\n",
      "3591 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228580]\n",
      "3592 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227192]\n",
      "3593 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.229721]\n",
      "3594 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219060]\n",
      "3595 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.221863]\n",
      "3596 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.235406]\n",
      "3597 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.230850]\n",
      "3598 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.246436]\n",
      "3599 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.215751]\n",
      "3600 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.237312]\n",
      "[[[-0.58245826]\n",
      "  [-0.9499837 ]\n",
      "  [-0.89844394]\n",
      "  ...\n",
      "  [-0.9550325 ]\n",
      "  [-0.95806533]\n",
      "  [-0.86497873]]\n",
      "\n",
      " [[-0.9279511 ]\n",
      "  [-0.6425892 ]\n",
      "  [-0.9551857 ]\n",
      "  ...\n",
      "  [ 0.10828061]\n",
      "  [-0.9537526 ]\n",
      "  [ 0.8843967 ]]\n",
      "\n",
      " [[-0.21832171]\n",
      "  [ 0.206032  ]\n",
      "  [-0.8492442 ]\n",
      "  ...\n",
      "  [ 0.76651216]\n",
      "  [ 0.98808604]\n",
      "  [-0.8839749 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.17955263]\n",
      "  [ 0.60991645]\n",
      "  [-0.8954216 ]\n",
      "  ...\n",
      "  [-0.83583564]\n",
      "  [-0.96745056]\n",
      "  [ 0.9657916 ]]\n",
      "\n",
      " [[ 0.65910065]\n",
      "  [-0.48295945]\n",
      "  [-0.92603475]\n",
      "  ...\n",
      "  [-0.9843681 ]\n",
      "  [ 0.07573917]\n",
      "  [-0.49237955]]\n",
      "\n",
      " [[ 0.40804812]\n",
      "  [ 0.00724761]\n",
      "  [-0.74209213]\n",
      "  ...\n",
      "  [-0.57910514]\n",
      "  [-0.8971936 ]\n",
      "  [-0.50282073]]]\n",
      "3601 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208550]\n",
      "3602 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.236530]\n",
      "3603 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.238504]\n",
      "3604 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.244658]\n",
      "3605 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.216976]\n",
      "3606 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227420]\n",
      "3607 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.217013]\n",
      "3608 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213661]\n",
      "3609 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.235310]\n",
      "3610 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222713]\n",
      "3611 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228523]\n",
      "3612 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226600]\n",
      "3613 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218214]\n",
      "3614 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.216300]\n",
      "3615 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.212879]\n",
      "3616 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.217115]\n",
      "3617 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.218516]\n",
      "3618 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210929]\n",
      "3619 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.209437]\n",
      "3620 [D loss: 0.000005, acc.: 100.00%] [G loss: 3.215003]\n",
      "3621 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.230264]\n",
      "3622 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212811]\n",
      "3623 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.208009]\n",
      "3624 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202322]\n",
      "3625 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.208732]\n",
      "3626 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.218242]\n",
      "3627 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212264]\n",
      "3628 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.197880]\n",
      "3629 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202110]\n",
      "3630 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.193768]\n",
      "3631 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.214797]\n",
      "3632 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206546]\n",
      "3633 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.224620]\n",
      "3634 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.219398]\n",
      "3635 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209978]\n",
      "3636 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219624]\n",
      "3637 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.258401]\n",
      "3638 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212852]\n",
      "3639 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.233230]\n",
      "3640 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.199380]\n",
      "3641 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.239432]\n",
      "3642 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.228531]\n",
      "3643 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.228009]\n",
      "3644 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.236275]\n",
      "3645 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227028]\n",
      "3646 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.232161]\n",
      "3647 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.245456]\n",
      "3648 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.228575]\n",
      "3649 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.252537]\n",
      "3650 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223945]\n",
      "3651 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223106]\n",
      "3652 [D loss: 0.000010, acc.: 100.00%] [G loss: 3.204253]\n",
      "3653 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.227818]\n",
      "3654 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.231335]\n",
      "3655 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.184565]\n",
      "3656 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211779]\n",
      "3657 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213041]\n",
      "3658 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223757]\n",
      "3659 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.232096]\n",
      "3660 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221822]\n",
      "3661 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.221575]\n",
      "3662 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218036]\n",
      "3663 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226594]\n",
      "3664 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.230500]\n",
      "3665 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.246952]\n",
      "3666 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.207739]\n",
      "3667 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.218048]\n",
      "3668 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220402]\n",
      "3669 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211539]\n",
      "3670 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.222749]\n",
      "3671 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231521]\n",
      "3672 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.231460]\n",
      "3673 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210643]\n",
      "3674 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.211624]\n",
      "3675 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227690]\n",
      "3676 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.235206]\n",
      "3677 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.232408]\n",
      "3678 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.216990]\n",
      "3679 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.202959]\n",
      "3680 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227404]\n",
      "3681 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.236485]\n",
      "3682 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.220843]\n",
      "3683 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213315]\n",
      "3684 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213866]\n",
      "3685 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.208780]\n",
      "3686 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3687 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210255]\n",
      "3688 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.206593]\n",
      "3689 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.234381]\n",
      "3690 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.236722]\n",
      "3691 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.231133]\n",
      "3692 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.217937]\n",
      "3693 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.214208]\n",
      "3694 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.234045]\n",
      "3695 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204185]\n",
      "3696 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.222049]\n",
      "3697 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.205249]\n",
      "3698 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.223338]\n",
      "3699 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.203726]\n",
      "3700 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.232425]\n",
      "[[[-0.7197883 ]\n",
      "  [-0.90691775]\n",
      "  [-0.6616161 ]\n",
      "  ...\n",
      "  [-0.90185916]\n",
      "  [-0.8081476 ]\n",
      "  [-0.78213376]]\n",
      "\n",
      " [[ 0.27851087]\n",
      "  [ 0.04465321]\n",
      "  [-0.9246345 ]\n",
      "  ...\n",
      "  [ 0.95997983]\n",
      "  [-0.94139344]\n",
      "  [-0.38993353]]\n",
      "\n",
      " [[ 0.8885947 ]\n",
      "  [-0.8085197 ]\n",
      "  [-0.97520566]\n",
      "  ...\n",
      "  [-0.4447964 ]\n",
      "  [ 0.87933457]\n",
      "  [ 0.02280572]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.01634408]\n",
      "  [ 0.9048755 ]\n",
      "  [-0.91028166]\n",
      "  ...\n",
      "  [-0.48949152]\n",
      "  [-0.8905878 ]\n",
      "  [ 0.5147011 ]]\n",
      "\n",
      " [[ 0.99194884]\n",
      "  [-0.8101377 ]\n",
      "  [-0.71364486]\n",
      "  ...\n",
      "  [-0.82761616]\n",
      "  [ 0.972629  ]\n",
      "  [-0.3069786 ]]\n",
      "\n",
      " [[-0.25119817]\n",
      "  [ 0.9084783 ]\n",
      "  [-0.81646764]\n",
      "  ...\n",
      "  [ 0.89026874]\n",
      "  [-0.624715  ]\n",
      "  [-0.01085665]]]\n",
      "3701 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.206996]\n",
      "3702 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204739]\n",
      "3703 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222479]\n",
      "3704 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.242750]\n",
      "3705 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231305]\n",
      "3706 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231722]\n",
      "3707 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.217893]\n",
      "3708 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223326]\n",
      "3709 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222039]\n",
      "3710 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221307]\n",
      "3711 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.209094]\n",
      "3712 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.200271]\n",
      "3713 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220368]\n",
      "3714 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.213017]\n",
      "3715 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.229876]\n",
      "3716 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219935]\n",
      "3717 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226721]\n",
      "3718 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.223862]\n",
      "3719 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223270]\n",
      "3720 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.222558]\n",
      "3721 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222165]\n",
      "3722 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.216573]\n",
      "3723 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.204400]\n",
      "3724 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.223114]\n",
      "3725 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.208055]\n",
      "3726 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.237513]\n",
      "3727 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228733]\n",
      "3728 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227398]\n",
      "3729 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228186]\n",
      "3730 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.221367]\n",
      "3731 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220143]\n",
      "3732 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.250618]\n",
      "3733 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.214513]\n",
      "3734 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.214490]\n",
      "3735 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220229]\n",
      "3736 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.233492]\n",
      "3737 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.232884]\n",
      "3738 [D loss: 0.000003, acc.: 100.00%] [G loss: 3.229957]\n",
      "3739 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.230203]\n",
      "3740 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.234802]\n",
      "3741 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219674]\n",
      "3742 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228252]\n",
      "3743 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.245073]\n",
      "3744 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.241549]\n",
      "3745 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.221107]\n",
      "3746 [D loss: 0.000004, acc.: 100.00%] [G loss: 3.229617]\n",
      "3747 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226851]\n",
      "3748 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.216141]\n",
      "3749 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.201507]\n",
      "3750 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221498]\n",
      "3751 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218712]\n",
      "3752 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218847]\n",
      "3753 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.236480]\n",
      "3754 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.228865]\n",
      "3755 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.233713]\n",
      "3756 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.217324]\n",
      "3757 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.229143]\n",
      "3758 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.224903]\n",
      "3759 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227418]\n",
      "3760 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228006]\n",
      "3761 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.233120]\n",
      "3762 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.245467]\n",
      "3763 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207504]\n",
      "3764 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.204835]\n",
      "3765 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226268]\n",
      "3766 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.232519]\n",
      "3767 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.212947]\n",
      "3768 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.233379]\n",
      "3769 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.219136]\n",
      "3770 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.218770]\n",
      "3771 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.231872]\n",
      "3772 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226694]\n",
      "3773 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227407]\n",
      "3774 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.221866]\n",
      "3775 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227723]\n",
      "3776 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.222273]\n",
      "3777 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.230036]\n",
      "3778 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.253545]\n",
      "3779 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.235936]\n",
      "3780 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228412]\n",
      "3781 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226240]\n",
      "3782 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.232667]\n",
      "3783 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.229837]\n",
      "3784 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.211980]\n",
      "3785 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.226699]\n",
      "3786 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.213840]\n",
      "3787 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.207577]\n",
      "3788 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.227105]\n",
      "3789 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.202632]\n",
      "3790 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.220361]\n",
      "3791 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.228477]\n",
      "3792 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222697]\n",
      "3793 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.210399]\n",
      "3794 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226873]\n",
      "3795 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226698]\n",
      "3796 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.243303]\n",
      "3797 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.233835]\n",
      "3798 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.237154]\n",
      "3799 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222185]\n",
      "3800 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231892]\n",
      "[[[-0.2295673 ]\n",
      "  [-0.91547024]\n",
      "  [-0.92565936]\n",
      "  ...\n",
      "  [-0.55734026]\n",
      "  [-0.6297933 ]\n",
      "  [-0.9425655 ]]\n",
      "\n",
      " [[ 0.09623123]\n",
      "  [-0.9371798 ]\n",
      "  [-0.93180907]\n",
      "  ...\n",
      "  [ 0.67217827]\n",
      "  [-0.91940016]\n",
      "  [ 0.9997686 ]]\n",
      "\n",
      " [[-0.44479915]\n",
      "  [ 0.914268  ]\n",
      "  [-0.9728334 ]\n",
      "  ...\n",
      "  [ 0.5635693 ]\n",
      "  [ 0.9981364 ]\n",
      "  [ 0.5905363 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.9578468 ]\n",
      "  [-0.87801075]\n",
      "  [-0.84198934]\n",
      "  ...\n",
      "  [-0.9377782 ]\n",
      "  [ 0.7505891 ]\n",
      "  [ 0.38407373]]\n",
      "\n",
      " [[ 0.9690385 ]\n",
      "  [-0.68847656]\n",
      "  [-0.8840531 ]\n",
      "  ...\n",
      "  [ 0.9866137 ]\n",
      "  [-0.5727608 ]\n",
      "  [-0.65161556]]\n",
      "\n",
      " [[-0.16723166]\n",
      "  [ 0.91415113]\n",
      "  [-0.87759715]\n",
      "  ...\n",
      "  [-0.2068967 ]\n",
      "  [ 0.63537526]\n",
      "  [-0.8866801 ]]]\n",
      "3801 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219881]\n",
      "3802 [D loss: 0.000002, acc.: 100.00%] [G loss: 3.250097]\n",
      "3803 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.235288]\n",
      "3804 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.222543]\n",
      "3805 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.246301]\n",
      "3806 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.233145]\n",
      "3807 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227683]\n",
      "3808 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.223640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3809 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.242837]\n",
      "3810 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.238276]\n",
      "3811 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.220465]\n",
      "3812 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.227903]\n",
      "3813 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.246401]\n",
      "3814 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.241841]\n",
      "3815 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.219866]\n",
      "3816 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.245545]\n",
      "3817 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.221095]\n",
      "3818 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.244278]\n",
      "3819 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.237068]\n",
      "3820 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.231157]\n",
      "3821 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.251633]\n",
      "3822 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.226662]\n",
      "3823 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.231366]\n",
      "3824 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.214453]\n",
      "3825 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.242925]\n",
      "3826 [D loss: 0.000001, acc.: 100.00%] [G loss: 3.239904]\n",
      "3827 [D loss: 0.000000, acc.: 100.00%] [G loss: 3.234871]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-305-215e6d7d278c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-303-3841e4087863>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m# Train the discriminator (real classified as ones and generated as zeros)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0md_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0md_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1076\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m           standalone=True)\n\u001b[0m\u001b[0;32m   1079\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m   1080\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[0;32m    415\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m       extract_tensors_from_dataset=True)\n\u001b[1;32m--> 417\u001b[1;33m   \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m   \u001b[1;31m# If `model._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m   \u001b[1;31m# at this point because of the check above.  `train_on_batch` is being run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m   \"\"\"\n\u001b[1;32m--> 545\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   8217\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   8218\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8219\u001b[1;33m         tld.op_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[0;32m   8220\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8221\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(epochs=50000, batch_size=2, save_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316955"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4642604 , -0.01989213, -0.51502289, -2.161932  , -1.4359043 ,\n",
       "        -1.482629  ,  0.80970048, -0.6431316 ,  0.3668454 ,  1.99361244,\n",
       "        -1.33483622, -0.27832457,  0.94887263, -0.77825828,  1.20760963,\n",
       "         0.68041883, -0.7168241 ,  0.28280601,  0.38030279,  1.64801379,\n",
       "         0.1893707 , -0.45921835, -0.17020257,  0.68914057,  0.00491308,\n",
       "         0.32359849, -1.00289254, -0.1392367 ,  1.77710706,  1.10816584,\n",
       "        -1.92618606,  1.05299761, -0.57998488,  0.78610537, -0.26010744,\n",
       "         1.36145931, -0.8159669 ,  0.46025351, -2.69993242,  0.71162287,\n",
       "         0.51306981, -0.19739503,  1.33819673, -0.24423497, -0.01507904,\n",
       "        -1.36608943,  0.92809609, -0.76560628,  0.15499961, -0.6573878 ,\n",
       "        -0.58903442, -1.12297115, -0.91123345, -1.76689589,  1.05927942,\n",
       "         0.24032675, -0.39096943, -1.34194148, -2.7026002 , -0.98999454,\n",
       "         1.01168092,  0.82135737,  0.45518981,  0.65159326,  1.44634118,\n",
       "        -0.46801577, -1.04147819, -1.00750987,  0.90528421,  3.33239383,\n",
       "        -0.85880848,  2.42667968,  0.49763668,  0.23455972,  0.07403507,\n",
       "         2.04124872,  2.22149628,  0.41071538, -1.85077831, -0.52111654,\n",
       "         0.62793279,  0.89019234, -0.63620028,  0.75904142, -0.55970458,\n",
       "        -0.84663913, -0.90225586,  0.42224693,  0.61110538, -0.36868686,\n",
       "         1.26305762, -1.20166809,  0.96017316,  0.34941083, -1.36953374,\n",
       "        -0.18166328,  0.32143139,  0.49737884,  0.46034382, -1.55640155]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, (1, gan.latent_dim))\n",
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gan.generator.predict(noise).reshape((50, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-204.84389  , -245.66039  , -218.03993  , ..., -170.6331   ,\n",
       "        -242.9584   , -165.7793   ],\n",
       "       [-242.1954   , -160.17537  , -245.72745  , ...,   34.154728 ,\n",
       "        -251.46957  ,  242.0263   ],\n",
       "       [ 181.5327   , -229.34132  , -240.77367  , ...,  176.12054  ,\n",
       "         167.25343  , -222.35033  ],\n",
       "       ...,\n",
       "       [  26.234142 ,  -10.421611 , -186.59355  , ...,   64.00826  ,\n",
       "         -36.646202 ,  245.52577  ],\n",
       "       [ 195.11859  , -196.3196   , -171.58688  , ...,  181.82266  ,\n",
       "         138.03969  ,    2.1110933],\n",
       "       [-147.86777  ,  247.14143  , -240.64484  , ...,   57.83211  ,\n",
       "        -236.59052  ,   92.45815  ]], dtype=float32)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(pred*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ad2475a2c8>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
